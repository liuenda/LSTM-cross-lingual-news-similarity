{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Reading english Data:', 63386)\n",
      "('Reading english Data:', 63386)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    63340\n",
      "True         3\n",
      "Name: en_article, dtype: int64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main_keras.py:207: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_en'] = df_pairs_sample['en_article'].apply(doc2vec_en)\n",
      "main_keras.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_jp'] = df_pairs_sample['jp_article'].apply(doc2vec_jp)\n",
      "main_keras.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_en'] = df_pairs_sample['word2vec_en'].apply(padding)\n",
      "main_keras.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_jp'] = df_pairs_sample['word2vec_jp'].apply(padding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C value = 2 position: [983, 1229]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main_keras.py:269: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ma..., inputs=[<tf.Tenso...)`\n",
      "  model_lstm2 = Model(input=[input_1, input_2], output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 95s - loss: 0.6924 - acc: 0.5036    \n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 82s - loss: 0.6795 - acc: 0.5334    \n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 81s - loss: 0.6581 - acc: 0.5605    \n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 81s - loss: 0.6558 - acc: 0.5632    \n",
      "Epoch 5/50\n",
      "3072/8000 [==========>...................] - ETA: 48s - loss: 0.6316 - acc: 0.5895"
     ]
    }
   ],
   "source": [
    "run main_keras.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 300, 200)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 300, 200)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 50)            50200       main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 50)            50200       main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 100)           0           lstm_1[0][0]                     \n",
      "                                                                   lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 64)            6464        concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 64)            4160        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 64)            4160        dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             65          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 115,249\n",
      "Trainable params: 115,249\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_lstm2.save(filepath=\"dlmodel/model_lstm2_a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "filepath=\"dlmodel/model_lstm2_a\"\n",
    "model_lstm2 = keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"490pt\" viewBox=\"0.00 0.00 431.00 490.00\" width=\"431pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 486)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-486 427,-486 427,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140690896156368 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140690896156368</title>\n",
       "<polygon fill=\"none\" points=\"-0.5,-445 -0.5,-481 202.5,-481 202.5,-445 -0.5,-445\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-459.3\">main_input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140690896156816 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140690896156816</title>\n",
       "<polygon fill=\"none\" points=\"65,-371 65,-407 181,-407 181,-371 65,-371\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123\" y=\"-385.3\">lstm_1: LSTM</text>\n",
       "</g>\n",
       "<!-- 140690896156368&#45;&gt;140690896156816 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140690896156368-&gt;140690896156816</title>\n",
       "<path d=\"M106.214,-444.937C108.752,-436.63 111.864,-426.444 114.717,-417.108\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"118.096,-418.027 117.671,-407.441 111.401,-415.981 118.096,-418.027\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140690896156496 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140690896156496</title>\n",
       "<polygon fill=\"none\" points=\"220.5,-445 220.5,-481 423.5,-481 423.5,-445 220.5,-445\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322\" y=\"-459.3\">main_input_2: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140690484263696 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140690484263696</title>\n",
       "<polygon fill=\"none\" points=\"242,-371 242,-407 358,-407 358,-371 242,-371\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-385.3\">lstm_2: LSTM</text>\n",
       "</g>\n",
       "<!-- 140690896156496&#45;&gt;140690484263696 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140690896156496-&gt;140690484263696</title>\n",
       "<path d=\"M316.786,-444.937C314.248,-436.63 311.136,-426.444 308.283,-417.108\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"311.599,-415.981 305.329,-407.441 304.904,-418.027 311.599,-415.981\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140690484182224 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140690484182224</title>\n",
       "<polygon fill=\"none\" points=\"100.5,-297 100.5,-333 321.5,-333 321.5,-297 100.5,-297\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-311.3\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 140690896156816&#45;&gt;140690484182224 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140690896156816-&gt;140690484182224</title>\n",
       "<path d=\"M143.855,-370.937C155.279,-361.59 169.612,-349.863 182.1,-339.646\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"184.467,-342.231 189.99,-333.19 180.034,-336.814 184.467,-342.231\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140690484263696&#45;&gt;140690484182224 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140690484263696-&gt;140690484182224</title>\n",
       "<path d=\"M278.908,-370.937C267.355,-361.59 252.858,-349.863 240.229,-339.646\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"242.225,-336.758 232.249,-333.19 237.822,-342.201 242.225,-336.758\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140690484182992 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140690484182992</title>\n",
       "<polygon fill=\"none\" points=\"147,-223 147,-259 275,-259 275,-223 147,-223\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-237.3\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140690484182224&#45;&gt;140690484182992 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140690484182224-&gt;140690484182992</title>\n",
       "<path d=\"M211,-296.937C211,-288.807 211,-278.876 211,-269.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"214.5,-269.441 211,-259.441 207.5,-269.441 214.5,-269.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140690481769488 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140690481769488</title>\n",
       "<polygon fill=\"none\" points=\"147,-149 147,-185 275,-185 275,-149 147,-149\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-163.3\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 140690484182992&#45;&gt;140690481769488 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140690484182992-&gt;140690481769488</title>\n",
       "<path d=\"M211,-222.937C211,-214.807 211,-204.876 211,-195.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"214.5,-195.441 211,-185.441 207.5,-195.441 214.5,-195.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140690480697296 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140690480697296</title>\n",
       "<polygon fill=\"none\" points=\"147,-75 147,-111 275,-111 275,-75 147,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-89.3\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 140690481769488&#45;&gt;140690480697296 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140690481769488-&gt;140690480697296</title>\n",
       "<path d=\"M211,-148.937C211,-140.807 211,-130.876 211,-121.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"214.5,-121.441 211,-111.441 207.5,-121.441 214.5,-121.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140690480786000 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140690480786000</title>\n",
       "<polygon fill=\"none\" points=\"131,-1 131,-37 291,-37 291,-1 131,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-15.3\">main_output: Dense</text>\n",
       "</g>\n",
       "<!-- 140690480697296&#45;&gt;140690480786000 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140690480697296-&gt;140690480786000</title>\n",
       "<path d=\"M211,-74.937C211,-66.8072 211,-56.8761 211,-47.7047\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"214.5,-47.4406 211,-37.4407 207.5,-47.4407 214.5,-47.4406\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model_lstm2).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Reading english Data:', 63386)\n",
      "('Reading english Data:', 63386)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    63340\n",
      "True         3\n",
      "Name: en_article, dtype: int64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main_keras.py:207: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_en'] = df_pairs_sample['en_article'].apply(doc2vec_en)\n",
      "main_keras.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_jp'] = df_pairs_sample['jp_article'].apply(doc2vec_jp)\n",
      "main_keras.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_en'] = df_pairs_sample['word2vec_en'].apply(padding)\n",
      "main_keras.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_jp'] = df_pairs_sample['word2vec_jp'].apply(padding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C value = 1 position: [1181]\n"
     ]
    }
   ],
   "source": [
    "run main_keras.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([664])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model_lstm2.predict([X1_test, X2_test])>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\tX1_train1, X1_test_1, X1_train2, X1_train3_wrong, X1_test_0 = np.split(X_1, [2000, 3000, 5000, 9000])\n",
    "\tX2_train1, X2_test_1, X2_train2, X2_train3_wrong, X2_test_0 = np.split(X_2, [2000, 3000, 5000, 9000])\n",
    "\ty_train1, y_test, y_train2, y_train3_wrong, Y_o = np.split(y, [2000, 3000, 9000, 9000])\n",
    "\n",
    "\tX1_train = np.concatenate((X1_train1, X1_train2, X1_train3_wrong), axis = 0)\n",
    "\tX2_train = np.concatenate((X2_train1, X2_train2, X2_train3_wrong), axis = 0)\n",
    "\ty_train = np.concatenate((y_train1, y_train2, y_train3_wrong), axis = 0)\n",
    "\t# X_train_correct = np.concatenate((X_train1, X_train2), axis = 0)\n",
    "\t# y_train_correct = np.concatenate((y_train1, y_train2), axis = 0)\n",
    "\n",
    "\t# --- Generate balanced test data --- #\n",
    "\tX1_test = np.concatenate((X1_test_1, X1_test_0), axis=0)\n",
    "\tX2_test = np.concatenate((X2_test_1, X2_test_0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 300, 200)\n",
      "(2000, 300, 200)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "y_test = np.concatenate((np.ones(len(X1_test_1)), np.zeros(len(X1_test_0))), axis = 0)\n",
    "print(X1_test.shape)\n",
    "print(X2_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.49      0.32      0.39      1000\n",
      "        1.0       0.49      0.66      0.57      1000\n",
      "\n",
      "avg / total       0.49      0.49      0.48      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_eva_predict = model_lstm2.predict([X1_test, X2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test, y_eva_predict>.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Reading english Data:', 63386)\n",
      "('Reading english Data:', 63386)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    63340\n",
      "True         3\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main_keras.py:207: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_en'] = df_pairs_sample['en_article'].apply(doc2vec_en)\n",
      "main_keras.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_jp'] = df_pairs_sample['jp_article'].apply(doc2vec_jp)\n",
      "main_keras.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_en'] = df_pairs_sample['word2vec_en'].apply(padding)\n",
      "main_keras.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_jp'] = df_pairs_sample['word2vec_jp'].apply(padding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 1 position: [4868]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main_keras.py:273: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ma..., inputs=[<tf.Tenso...)`\n",
      "  model_lstm2 = Model(input=[input_1, input_2], output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 82s - loss: 0.6932 - acc: 0.4914 - val_loss: 0.7058 - val_acc: 0.4525\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 75s - loss: 0.6889 - acc: 0.5187 - val_loss: 0.7461 - val_acc: 0.4505\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 74s - loss: 0.6816 - acc: 0.5265 - val_loss: 0.7568 - val_acc: 0.4730\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 72s - loss: 0.6633 - acc: 0.5576 - val_loss: 0.8104 - val_acc: 0.4960\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 72s - loss: 0.6500 - acc: 0.5737 - val_loss: 0.7767 - val_acc: 0.4920\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 74s - loss: 0.6367 - acc: 0.5836 - val_loss: 0.8485 - val_acc: 0.4815\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6311 - acc: 0.5835 - val_loss: 0.8296 - val_acc: 0.4860\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6584 - acc: 0.5851 - val_loss: 0.7874 - val_acc: 0.4705\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6332 - acc: 0.5846 - val_loss: 0.8162 - val_acc: 0.4745\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6286 - acc: 0.5941 - val_loss: 0.8369 - val_acc: 0.4630\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 71s - loss: 0.6246 - acc: 0.5944 - val_loss: 0.8269 - val_acc: 0.4530\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6226 - acc: 0.5954 - val_loss: 0.9225 - val_acc: 0.4475\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6408 - acc: 0.5823 - val_loss: 0.7939 - val_acc: 0.4685\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6495 - acc: 0.5691 - val_loss: 0.9434 - val_acc: 0.4640\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6303 - acc: 0.5889 - val_loss: 0.9407 - val_acc: 0.4465\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6263 - acc: 0.5980 - val_loss: 0.9821 - val_acc: 0.4645\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6238 - acc: 0.5961 - val_loss: 0.9573 - val_acc: 0.4460\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6263 - acc: 0.5960 - val_loss: 0.9547 - val_acc: 0.4575\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6196 - acc: 0.6000 - val_loss: 1.0181 - val_acc: 0.4420\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6145 - acc: 0.6055 - val_loss: 1.0523 - val_acc: 0.4490\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6186 - acc: 0.6041 - val_loss: 0.9684 - val_acc: 0.4405\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6128 - acc: 0.6094 - val_loss: 1.0387 - val_acc: 0.4305\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6390 - acc: 0.5966 - val_loss: 0.9870 - val_acc: 0.4320\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6239 - acc: 0.5920 - val_loss: 0.9853 - val_acc: 0.4360\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6071 - acc: 0.6142 - val_loss: 1.0435 - val_acc: 0.4385\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6054 - acc: 0.6119 - val_loss: 1.0848 - val_acc: 0.4250\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6018 - acc: 0.6165 - val_loss: 1.2025 - val_acc: 0.3900\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5993 - acc: 0.6151 - val_loss: 1.2209 - val_acc: 0.4260\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5996 - acc: 0.6183 - val_loss: 1.2091 - val_acc: 0.4245\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 68s - loss: 0.5985 - acc: 0.6186 - val_loss: 1.2118 - val_acc: 0.4335\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5933 - acc: 0.6285 - val_loss: 1.3265 - val_acc: 0.4785\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6033 - acc: 0.6166 - val_loss: 1.1885 - val_acc: 0.4175\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6038 - acc: 0.6085 - val_loss: 1.2008 - val_acc: 0.4270\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5997 - acc: 0.6132 - val_loss: 1.2752 - val_acc: 0.4195\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6003 - acc: 0.6078 - val_loss: 1.2538 - val_acc: 0.4315\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6264 - acc: 0.5811 - val_loss: 1.2415 - val_acc: 0.4285\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 68s - loss: 0.6095 - acc: 0.5966 - val_loss: 1.3397 - val_acc: 0.4290\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.5954 - acc: 0.6154 - val_loss: 1.3541 - val_acc: 0.4145\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.5951 - acc: 0.6134 - val_loss: 1.2977 - val_acc: 0.4310\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 68s - loss: 0.5961 - acc: 0.6109 - val_loss: 1.3657 - val_acc: 0.4335\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6076 - acc: 0.5962 - val_loss: 1.3643 - val_acc: 0.4310\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6153 - acc: 0.5936 - val_loss: 1.3078 - val_acc: 0.4125\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5981 - acc: 0.6090 - val_loss: 1.4794 - val_acc: 0.4195\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5881 - acc: 0.6240 - val_loss: 1.3813 - val_acc: 0.4130\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 68s - loss: 0.5853 - acc: 0.6228 - val_loss: 1.5412 - val_acc: 0.4190\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 68s - loss: 0.5838 - acc: 0.6276 - val_loss: 1.6289 - val_acc: 0.4095\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.5838 - acc: 0.6275 - val_loss: 1.4332 - val_acc: 0.4320\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5751 - acc: 0.6429 - val_loss: 1.3026 - val_acc: 0.4210\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5853 - acc: 0.6260 - val_loss: 1.3486 - val_acc: 0.4105\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5821 - acc: 0.6329 - val_loss: 1.4713 - val_acc: 0.4330\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't pickle module objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/home/liuenda/Workspace/cas-keras/main_keras.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mpath_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hist_lstm2_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m     \u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROTO\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mListType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mListType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mListType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mListType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMARK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/copy_reg.pyc\u001b[0m in \u001b[0;36m_reduce_ex\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"can't pickle %s objects\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle module objects"
     ]
    }
   ],
   "source": [
    "run main_keras.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.40      0.28      0.33      1000\n",
      "        1.0       0.45      0.59      0.51      1000\n",
      "\n",
      "avg / total       0.43      0.43      0.42      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_eva_predict = model_lstm2.predict([X1_test, X2_test])\n",
    "print(classification_report(y_test, y_eva_predict>.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.43005243,  0.52353752,  0.52349687, ...,  0.52324378,\n",
       "        0.48257449,  0.1201562 ], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eva_predict[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.49137500000000001,\n",
       "  0.51875000000000004,\n",
       "  0.52649999999999997,\n",
       "  0.55762500000000004,\n",
       "  0.57374999999999998,\n",
       "  0.58362499999999995,\n",
       "  0.58350000000000002,\n",
       "  0.58512500000000001,\n",
       "  0.58462499999999995,\n",
       "  0.59412500000000001,\n",
       "  0.59437499999999999,\n",
       "  0.59537499999999999,\n",
       "  0.58225000000000005,\n",
       "  0.56912499999999999,\n",
       "  0.58887500000000004,\n",
       "  0.59799999999999998,\n",
       "  0.59612500000000002,\n",
       "  0.59599999999999997,\n",
       "  0.59999999999999998,\n",
       "  0.60550000000000004,\n",
       "  0.60412500000000002,\n",
       "  0.609375,\n",
       "  0.59662499999999996,\n",
       "  0.59199999999999997,\n",
       "  0.61424999999999996,\n",
       "  0.61187499999999995,\n",
       "  0.61650000000000005,\n",
       "  0.61512500000000003,\n",
       "  0.61824999999999997,\n",
       "  0.61862499999999998,\n",
       "  0.62849999999999995,\n",
       "  0.61662499999999998,\n",
       "  0.60850000000000004,\n",
       "  0.61324999999999996,\n",
       "  0.60775000000000001,\n",
       "  0.581125,\n",
       "  0.59662499999999996,\n",
       "  0.61537500000000001,\n",
       "  0.613375,\n",
       "  0.61087499999999995,\n",
       "  0.59624999999999995,\n",
       "  0.59362499999999996,\n",
       "  0.60899999999999999,\n",
       "  0.624,\n",
       "  0.62275000000000003,\n",
       "  0.62762499999999999,\n",
       "  0.62749999999999995,\n",
       "  0.64287499999999997,\n",
       "  0.626,\n",
       "  0.63287499999999997],\n",
       " 'loss': [0.69320144271850581,\n",
       "  0.68886063432693478,\n",
       "  0.68158361148834223,\n",
       "  0.6632558679580689,\n",
       "  0.64999859714508057,\n",
       "  0.63667856693267821,\n",
       "  0.6311110625267029,\n",
       "  0.65838728618621822,\n",
       "  0.63323669672012328,\n",
       "  0.62856693840026856,\n",
       "  0.6246405525207519,\n",
       "  0.62255440473556523,\n",
       "  0.64079170227050786,\n",
       "  0.64946638965606684,\n",
       "  0.63027391099929808,\n",
       "  0.62626634502410894,\n",
       "  0.62376322031021114,\n",
       "  0.62632727336883542,\n",
       "  0.6195556898117065,\n",
       "  0.6144901819229126,\n",
       "  0.61861417007446284,\n",
       "  0.61275748062133784,\n",
       "  0.63902948188781739,\n",
       "  0.62392177200317378,\n",
       "  0.60714437866210935,\n",
       "  0.60542545461654662,\n",
       "  0.60184864473342892,\n",
       "  0.59930062866210942,\n",
       "  0.5996273245811462,\n",
       "  0.59851735591888433,\n",
       "  0.5933008985519409,\n",
       "  0.60331707859039307,\n",
       "  0.60381507301330561,\n",
       "  0.59973499011993403,\n",
       "  0.60027404880523683,\n",
       "  0.62641422843933103,\n",
       "  0.60947470760345457,\n",
       "  0.59537311649322511,\n",
       "  0.59509035253524778,\n",
       "  0.59614702129364017,\n",
       "  0.60763711547851562,\n",
       "  0.61530770015716552,\n",
       "  0.59806580257415776,\n",
       "  0.58812296867370606,\n",
       "  0.58528755187988279,\n",
       "  0.58376430225372311,\n",
       "  0.58378804492950442,\n",
       "  0.57512019824981686,\n",
       "  0.58525325775146486,\n",
       "  0.58205349206924439],\n",
       " 'val_acc': [0.45249999904632571,\n",
       "  0.4505000014305115,\n",
       "  0.47300000405311582,\n",
       "  0.49600000357627871,\n",
       "  0.49200000047683717,\n",
       "  0.48150000143051147,\n",
       "  0.48600000238418578,\n",
       "  0.47050000131130221,\n",
       "  0.47449999952316285,\n",
       "  0.46300000238418582,\n",
       "  0.45300000166893006,\n",
       "  0.44750000023841857,\n",
       "  0.46849999952316285,\n",
       "  0.46400000238418582,\n",
       "  0.44650000095367431,\n",
       "  0.46450000095367433,\n",
       "  0.44600000143051149,\n",
       "  0.45750000000000002,\n",
       "  0.44200000131130218,\n",
       "  0.44900000274181368,\n",
       "  0.4405000023841858,\n",
       "  0.43050000047683717,\n",
       "  0.43200000190734861,\n",
       "  0.43600000011920931,\n",
       "  0.43850000238418579,\n",
       "  0.42499999988079074,\n",
       "  0.39000000000000001,\n",
       "  0.42600000429153445,\n",
       "  0.42450000166893004,\n",
       "  0.43350000131130217,\n",
       "  0.47850000381469726,\n",
       "  0.41750000095367434,\n",
       "  0.42700000143051148,\n",
       "  0.4195000002384186,\n",
       "  0.43149999952316287,\n",
       "  0.42850000476837158,\n",
       "  0.42900000119209292,\n",
       "  0.41450000238418577,\n",
       "  0.43100000405311584,\n",
       "  0.43350000286102297,\n",
       "  0.43100000154972079,\n",
       "  0.41250000214576721,\n",
       "  0.4195000002384186,\n",
       "  0.41300000190734865,\n",
       "  0.41900000202655791,\n",
       "  0.40950000190734864,\n",
       "  0.43200000083446505,\n",
       "  0.42099999928474424,\n",
       "  0.41050000143051146,\n",
       "  0.43300000047683718],\n",
       " 'val_loss': [0.70577453184127803,\n",
       "  0.74610202550888061,\n",
       "  0.75680347681045534,\n",
       "  0.81037764406204227,\n",
       "  0.77673555517196657,\n",
       "  0.84850609540939326,\n",
       "  0.82961297178268434,\n",
       "  0.78739346313476566,\n",
       "  0.8162432227134705,\n",
       "  0.83689403247833249,\n",
       "  0.82687836742401122,\n",
       "  0.92245899295806888,\n",
       "  0.79394653177261354,\n",
       "  0.94336384010314944,\n",
       "  0.94074716281890869,\n",
       "  0.98211404800415036,\n",
       "  0.95731424999237058,\n",
       "  0.95474103927612308,\n",
       "  1.0181064853668214,\n",
       "  1.0523095798492432,\n",
       "  0.9684078817367554,\n",
       "  1.0386735687255859,\n",
       "  0.98702313995361324,\n",
       "  0.98525243663787843,\n",
       "  1.0434988050460816,\n",
       "  1.0847878971099854,\n",
       "  1.2025455713272095,\n",
       "  1.2209227819442749,\n",
       "  1.2090815029144286,\n",
       "  1.2118327589035034,\n",
       "  1.3264845895767212,\n",
       "  1.1884630212783813,\n",
       "  1.2007983045578003,\n",
       "  1.2751914262771606,\n",
       "  1.2537969141006469,\n",
       "  1.2414872150421143,\n",
       "  1.3396885671615602,\n",
       "  1.3540934982299804,\n",
       "  1.2977121725082397,\n",
       "  1.3657266960144043,\n",
       "  1.3643183565139771,\n",
       "  1.3077669563293457,\n",
       "  1.4793569450378419,\n",
       "  1.3813088541030885,\n",
       "  1.5411620235443115,\n",
       "  1.628905460357666,\n",
       "  1.4331693029403687,\n",
       "  1.3026067991256713,\n",
       "  1.3486393251419067,\n",
       "  1.4713486671447753]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the ranking results with respect to real pairs\n",
    "Defaulty, projection1 should be JP\n",
    "Whiile, projection2 should be EN->JP\n",
    "\"\"\"\n",
    "def find_ranking(projection1, projection2, dlmodel):\n",
    "\tsim_results = []\n",
    "\trank_results = []\n",
    "\n",
    "\t# Iterate each of the ariticle from projection1 (999) as proj1\n",
    "\t# Calculate the simialrity of proj1 with all ariticles in projection2 (999)\n",
    "\tfor i, proj1 in enumerate(projection1):\n",
    "\t\tprint(\"Find answer for doc.\", i)\n",
    "\t\tproj1_tile = np.tile(proj1, (len(projection2),1,1))\n",
    "# \t\tprint proj1_tile.shape\n",
    "# \t\tprint proj1_tile\n",
    "# \t\tprint proj1.shape\n",
    "\t\tsim = dlmodel.predict([proj1_tile, projection2])[:,0]\n",
    "# \t\tprint sim\n",
    "\t\trank = pd.Series(sim).rank(ascending = False)[i]\n",
    "\t\tsim_results.append(sim)\n",
    "\t\trank_results.append(rank)\n",
    "\t\tprint rank\n",
    "\n",
    "\t# sim_results contains 999*999 similairty matrix\n",
    "\treturn sim_results, rank_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Find answer for doc.', 0)\n",
      "147.0\n",
      "('Find answer for doc.', 1)\n",
      "291.0\n",
      "('Find answer for doc.', 2)\n",
      "498.0\n",
      "('Find answer for doc.', 3)\n",
      "450.0\n",
      "('Find answer for doc.', 4)\n",
      "789.5\n",
      "('Find answer for doc.', 5)\n",
      "821.0\n",
      "('Find answer for doc.', 6)\n",
      "795.0\n",
      "('Find answer for doc.', 7)\n",
      "743.0\n",
      "('Find answer for doc.', 8)\n",
      "616.0\n",
      "('Find answer for doc.', 9)\n",
      "372.5\n",
      "('Find answer for doc.', 10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-f46e567c46f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_ranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_test_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_test_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_lstm2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-cf9c413c0c80>\u001b[0m in \u001b[0;36mfind_ranking\u001b[0;34m(projection1, projection2, dlmodel)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#               print proj1_tile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#               print proj1.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproj1_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#               print sim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1585\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1210\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a = find_ranking(X1_test_1[:,:,:], X2_test_1, model_lstm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09626271,  0.00656432, -0.20799024, ...,  0.07659759,\n",
       "        -0.13206814,  0.06503551],\n",
       "       [ 0.26123866,  0.01382056,  0.00648347, ...,  0.22894549,\n",
       "        -0.13786219, -0.12912716],\n",
       "       [ 0.03575521, -0.23474377, -0.02440281, ...,  0.09979937,\n",
       "        -0.06005824, -0.07902404],\n",
       "       ..., \n",
       "       [ 0.23872878,  0.06416631,  0.07533237, ...,  0.24324439,\n",
       "        -0.31456584, -0.49234882],\n",
       "       [ 0.20270877,  0.07590064,  0.03888318, ...,  0.26487142,\n",
       "         0.10724627, -0.11777702],\n",
       "       [ 0.09335291,  0.28491914, -0.0272277 , ...,  0.1573166 ,\n",
       "        -0.08874487,  0.14690572]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train[4001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.2035594 , -0.17032957,  0.13630773, ..., -0.15776674,\n",
       "         -0.05689833,  0.0529804 ],\n",
       "        [-0.12451203, -0.3213411 , -0.20498073, ...,  0.20521204,\n",
       "         -0.07325041,  0.27277657],\n",
       "        [-0.06744123, -0.16009675,  0.17753807, ..., -0.01309109,\n",
       "          0.04884958,  0.13856369],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.3649289 ,  0.02026587,  0.17083779, ...,  0.07582411,\n",
       "          0.04643445, -0.05549098],\n",
       "        [-0.05416851, -0.13047245,  0.0578197 , ..., -0.0097992 ,\n",
       "         -0.12715523, -0.60661757],\n",
       "        [-0.2792525 , -0.26107585, -0.02758151, ..., -0.04302026,\n",
       "         -0.35708189, -0.30353752],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.37992465, -0.16320978,  0.21647577, ..., -0.07380453,\n",
       "          0.2222032 ,  0.00801729],\n",
       "        [ 0.21176256, -0.23381241, -0.07060514, ..., -0.02609797,\n",
       "          0.03988031, -0.24141885],\n",
       "        [-0.46719864, -0.04468558, -0.2491429 , ...,  0.03507265,\n",
       "         -0.14025956,  0.08898471],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ..., \n",
       "       [[-0.08517134,  0.20535553,  0.12593433, ...,  0.07032266,\n",
       "          0.24877806, -0.00124323],\n",
       "        [ 0.16721793,  0.14109521, -0.0099226 , ..., -0.21902807,\n",
       "          0.02923114, -0.00869101],\n",
       "        [ 0.27545041,  0.0250656 ,  0.08259386, ...,  0.01894636,\n",
       "         -0.07830112,  0.01383533],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.2035594 , -0.17032957,  0.13630773, ..., -0.15776674,\n",
       "         -0.05689833,  0.0529804 ],\n",
       "        [-0.07113036, -0.37713   ,  0.07353979, ..., -0.06985579,\n",
       "          0.09448376,  0.17041913],\n",
       "        [ 0.14587575, -0.03462216,  0.05109059, ...,  0.19641764,\n",
       "         -0.28392082,  0.08958188],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.2035594 , -0.17032957,  0.13630773, ..., -0.15776674,\n",
       "         -0.05689833,  0.0529804 ],\n",
       "        [ 0.2765663 , -0.09103319,  0.25488484, ...,  0.26420298,\n",
       "         -0.07610356, -0.03254816],\n",
       "        [ 0.15495408, -0.58930755,  0.30961218, ...,  0.27981713,\n",
       "          0.06970363, -0.20249979],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[3999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.46130753e-02,   9.54257995e-02,   2.01974958e-01,\n",
       "        -1.88879788e-01,   1.49911344e-01,   7.41543472e-02,\n",
       "         2.80297130e-01,   2.06199691e-01,   1.05131559e-01,\n",
       "        -2.28328779e-01,  -1.71689972e-01,  -1.40397131e-01,\n",
       "         1.43209575e-02,  -1.47004157e-01,   4.54984196e-02,\n",
       "        -2.13625193e-01,  -9.76795554e-02,   4.28388566e-01,\n",
       "        -8.19410384e-02,  -8.34822282e-02,  -1.17317043e-01,\n",
       "         3.29226926e-02,   5.09187579e-02,   7.38451853e-02,\n",
       "        -3.33025306e-02,  -4.29547042e-01,  -7.40184113e-02,\n",
       "        -2.97672898e-01,  -1.95241719e-01,  -1.98570509e-02,\n",
       "         5.34500889e-02,  -1.96851701e-01,   1.98751673e-01,\n",
       "         1.33167773e-01,   1.65657312e-01,   3.39270979e-02,\n",
       "         2.12546214e-01,  -6.87375665e-02,   1.09114878e-01,\n",
       "         2.53317505e-01,   3.50452997e-02,   1.12259544e-01,\n",
       "        -2.83444434e-01,   2.62120292e-02,   3.69520895e-02,\n",
       "         1.59424357e-02,  -2.65563745e-02,  -1.95016041e-01,\n",
       "        -2.47364923e-01,  -4.62418385e-02,   8.00507069e-02,\n",
       "        -2.52563566e-01,  -5.62832616e-02,  -6.78401589e-02,\n",
       "        -2.08042502e-01,   1.66517884e-01,   1.11643799e-01,\n",
       "         2.54404962e-01,   1.22635894e-01,   2.80075341e-01,\n",
       "        -3.41233285e-03,  -2.43205056e-01,   1.08223647e-01,\n",
       "        -9.83586758e-02,  -2.12439269e-01,   4.17900970e-03,\n",
       "        -2.77497172e-01,   1.07707947e-01,  -1.28009647e-01,\n",
       "        -6.65610731e-02,   2.13050097e-01,  -1.15425296e-01,\n",
       "        -3.26132625e-01,  -6.32183701e-02,  -1.13583468e-01,\n",
       "        -2.16432601e-01,  -2.07547560e-01,   8.61282349e-02,\n",
       "        -2.32072785e-01,  -8.21935385e-02,  -3.34710032e-02,\n",
       "        -4.15929817e-02,  -8.09755176e-02,  -1.35908425e-01,\n",
       "         2.19252571e-01,   1.74458608e-01,  -4.01258357e-02,\n",
       "         4.40933816e-02,  -2.63489723e-01,  -6.49405494e-02,\n",
       "         9.06346962e-02,   8.32978934e-02,  -4.21618760e-01,\n",
       "        -5.55608794e-02,  -1.32004455e-01,   8.07709321e-02,\n",
       "        -1.25579834e-01,  -2.57528543e-01,   8.09331909e-02,\n",
       "         2.11322248e-01,  -2.38200352e-02,   1.16971225e-01,\n",
       "         1.43899858e-01,   7.31083937e-03,  -3.14066969e-02,\n",
       "         2.37127952e-02,  -1.52738735e-01,  -1.00707710e-01,\n",
       "         2.15320778e-03,   2.11684421e-01,  -2.46896088e-01,\n",
       "         2.53208522e-02,  -3.82295668e-01,   1.94371995e-02,\n",
       "        -2.38617629e-01,  -1.69273302e-01,   1.02492638e-01,\n",
       "         5.49611524e-02,   4.65595052e-02,  -1.89020962e-01,\n",
       "         1.66469961e-01,   1.75267041e-01,  -3.65577079e-02,\n",
       "        -1.49122793e-02,   7.74850976e-03,   1.15291931e-01,\n",
       "        -1.76123723e-01,  -1.18053012e-01,  -5.47455437e-03,\n",
       "        -1.23924553e-01,  -2.09526554e-01,  -1.53991152e-02,\n",
       "        -1.71262071e-01,  -2.92435378e-01,   8.77041742e-02,\n",
       "        -1.82932645e-01,   5.62726753e-03,  -3.13690484e-01,\n",
       "         1.69287011e-01,  -1.88464597e-01,  -1.44499674e-01,\n",
       "         1.03135288e-01,   1.13957837e-01,  -9.31097046e-02,\n",
       "         2.45047554e-01,   4.10623429e-03,  -1.65068492e-01,\n",
       "        -6.49256334e-02,  -3.47099006e-02,   1.45082802e-01,\n",
       "        -1.02479771e-01,   1.98218673e-01,   2.01275691e-01,\n",
       "        -5.79555444e-02,  -4.03605402e-02,  -3.28151248e-02,\n",
       "        -2.43347108e-01,  -1.96908303e-02,   5.80059886e-02,\n",
       "         2.27364346e-01,   1.76700242e-02,   8.12432822e-03,\n",
       "         1.52011350e-01,   1.19443178e-01,  -8.04160386e-02,\n",
       "         9.82611924e-02,  -1.28491372e-02,  -3.82230669e-01,\n",
       "        -8.61649960e-02,   5.95518854e-03,  -2.43256941e-01,\n",
       "         1.02265468e-02,   8.65914579e-03,   4.22651917e-02,\n",
       "        -1.07977241e-01,   1.35203823e-01,  -2.04340950e-01,\n",
       "        -1.08679496e-01,  -1.65501405e-02,   1.54196754e-01,\n",
       "        -3.68039869e-02,   9.16271061e-02,   2.00911507e-01,\n",
       "         2.85099477e-01,  -2.16426104e-01,   3.26648429e-02,\n",
       "        -3.95247400e-01,  -2.10846588e-01,  -7.35367835e-02,\n",
       "        -2.61756610e-02,   2.65215002e-02,   9.04486701e-02,\n",
       "         2.79559374e-01,  -1.60725415e-01,   1.72031313e-01,\n",
       "        -4.21598088e-04,  -1.80436552e-01,   1.02300756e-01,\n",
       "        -1.00897588e-01,  -1.65765255e-03], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en[\"chinese\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>en_article</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>jp_article</th>\n",
       "      <th>similarity</th>\n",
       "      <th>dis_similarity</th>\n",
       "      <th>en_article_wrong</th>\n",
       "      <th>word2vec_en</th>\n",
       "      <th>word2vec_jp</th>\n",
       "      <th>padding_en</th>\n",
       "      <th>padding_jp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>u.s. commerce department seasonal adjust annua...</td>\n",
       "      <td>0</td>\n",
       "      <td>              ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>philippine will offer tender next year airport...</td>\n",
       "      <td>[[0.079418, -0.0698862, 0.0105229, 0.0433305, ...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.0794180035591, -0.0698861926794, 0.0105229...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>chinese budget smartphone maker xiaomi plan se...</td>\n",
       "      <td>1</td>\n",
       "      <td>     ()       ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>taiwanese bank have exposure loan company chin...</td>\n",
       "      <td>[[0.0946131, 0.0954258, 0.201975, -0.18888, 0....</td>\n",
       "      <td>[[0.364929, 0.0202659, 0.170838, 0.0298371, -0...</td>\n",
       "      <td>[[0.0946130752563, 0.095425799489, 0.201974958...</td>\n",
       "      <td>[[0.364928901196, 0.0202658716589, 0.170837789...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>samsung electronics co ltd fell more percent t...</td>\n",
       "      <td>2</td>\n",
       "      <td>           ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bank canada should keep it key interest rate h...</td>\n",
       "      <td>[[0.111116, 0.163467, 0.173304, -0.21241, 0.19...</td>\n",
       "      <td>[[0.379925, -0.16321, 0.216476, -0.00105682, -...</td>\n",
       "      <td>[[0.111115589738, 0.163467362523, 0.1733036488...</td>\n",
       "      <td>[[0.379924654961, -0.163209781051, 0.216475769...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fiat deal gain full control chrysler group llc...</td>\n",
       "      <td>3</td>\n",
       "      <td>     FIAT     8   ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>brazil incoming finance minister joaquim levy ...</td>\n",
       "      <td>[[0.252217, -0.149704, -0.000305933, 0.335273,...</td>\n",
       "      <td>[[0.27545, 0.0250656, 0.0825939, 0.136058, -0....</td>\n",
       "      <td>[[0.252217, -0.149704, -0.000305933, 0.335273,...</td>\n",
       "      <td>[[0.275450408459, 0.0250655952841, 0.082593858...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fiat share jump thursday it strike deal gain f...</td>\n",
       "      <td>4</td>\n",
       "      <td>     FIAT     8   ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>u.s. employer add large number worker nearly y...</td>\n",
       "      <td>[[0.252217, -0.149704, -0.000305933, 0.335273,...</td>\n",
       "      <td>[[0.27545, 0.0250656, 0.0825939, 0.136058, -0....</td>\n",
       "      <td>[[0.252217, -0.149704, -0.000305933, 0.335273,...</td>\n",
       "      <td>[[0.275450408459, 0.0250655952841, 0.082593858...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>u.s. treasuries price rise thursday benchmark ...</td>\n",
       "      <td>5</td>\n",
       "      <td>               ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>india central bank keep it key policy repo rat...</td>\n",
       "      <td>[[0.079418, -0.0698862, 0.0105229, 0.0433305, ...</td>\n",
       "      <td>[[-0.401097, -0.568938, -0.155227, 0.434545, -...</td>\n",
       "      <td>[[0.079418, -0.0698862, 0.0105229, 0.0433305, ...</td>\n",
       "      <td>[[-0.401097238064, -0.56893825531, -0.15522733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>auction detail see 3-year note</td>\n",
       "      <td>6</td>\n",
       "      <td>           1 11 11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sweden central bank keep it key interest rate ...</td>\n",
       "      <td>[[0.145339, 0.0967358, -0.290555, -0.157721, 0...</td>\n",
       "      <td>[[-0.440666, 0.610078, -0.0983196, 0.801558, 0...</td>\n",
       "      <td>[[0.145339399576, 0.0967358276248, -0.29055538...</td>\n",
       "      <td>[[-0.440665841103, 0.610077679157, -0.09831961...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>brent crude sink barrel thursday libya prepare...</td>\n",
       "      <td>7</td>\n",
       "      <td>              ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>asset manager credit suisse hedging griffo be ...</td>\n",
       "      <td>[[-0.00470701, -0.396765, -0.322486, -0.53076,...</td>\n",
       "      <td>[[0.00253854, -0.129143, -0.126948, 0.0700992,...</td>\n",
       "      <td>[[-0.00470701, -0.396765, -0.322486, -0.53076,...</td>\n",
       "      <td>[[0.00253854179755, -0.129142984748, -0.126948...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>gauge u.s. factory activity hold 2-1/2-year hi...</td>\n",
       "      <td>8</td>\n",
       "      <td>    12          ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>* usd/cnh close ny trade 6.1370-6.1450 offshor...</td>\n",
       "      <td>[[0.258893, -0.240117, -0.39061, -0.180771, 0....</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.258893, -0.240117, -0.39061, -0.180771, 0....</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>work massive panama canal extension project ma...</td>\n",
       "      <td>9</td>\n",
       "      <td>          PC  ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chipmaker altera corp be work intel corp combi...</td>\n",
       "      <td>[[-0.246409, -0.300402, 0.0540296, 0.0361169, ...</td>\n",
       "      <td>[[0.0367229, 0.154389, -0.430821, 0.336414, -0...</td>\n",
       "      <td>[[-0.246409475803, -0.300402313471, 0.05402963...</td>\n",
       "      <td>[[0.0367229022086, 0.154389277101, -0.43082135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>increase december car sale france spain prompt...</td>\n",
       "      <td>10</td>\n",
       "      <td>12           ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>president francois hollande brush aside questi...</td>\n",
       "      <td>[[0.0325002, 0.110915, -0.126051, -0.221096, 0...</td>\n",
       "      <td>[[-0.47501, 0.0407163, 0.111163, 0.451794, -0....</td>\n",
       "      <td>[[0.0325002, 0.110915, -0.126051, -0.221096, 0...</td>\n",
       "      <td>[[-0.475010246038, 0.0407162643969, 0.11116266...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>federal reserve provide liquidity foreign cent...</td>\n",
       "      <td>11</td>\n",
       "      <td>  FRB         ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>share italy third-biggest bank monte dei pasch...</td>\n",
       "      <td>[[0.0761386, 0.273143, -0.42036, -0.0670243, -...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.0761386305094, 0.27314338088, -0.420359730...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>new car sale spain rise percent year early car...</td>\n",
       "      <td>12</td>\n",
       "      <td>             ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>seoul share rebound thursday snap day lose str...</td>\n",
       "      <td>[[-0.0148091, 0.0937563, -0.266831, -0.100736,...</td>\n",
       "      <td>[[-0.101784, 0.297449, -0.0359539, -0.183187, ...</td>\n",
       "      <td>[[-0.0148091288283, 0.0937562733889, -0.266831...</td>\n",
       "      <td>[[-0.10178424418, 0.297449380159, -0.035953946...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>south korean auto maker hyundai motor co kia m...</td>\n",
       "      <td>13</td>\n",
       "      <td>           ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>average new home price china major city drop p...</td>\n",
       "      <td>[[-0.0864343, -0.392118, -0.265892, 0.0306064,...</td>\n",
       "      <td>[[-0.133516, -0.0476626, -0.0501251, -0.141976...</td>\n",
       "      <td>[[-0.0864343, -0.392118, -0.265892, 0.0306064,...</td>\n",
       "      <td>[[-0.133516088128, -0.0476626008749, -0.050125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>u.s. manufacturing end year high note grow dec...</td>\n",
       "      <td>14</td>\n",
       "      <td>Markit   12    PM  1  ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greece economy shrank annual pace percent seco...</td>\n",
       "      <td>[[0.079418, -0.0698862, 0.0105229, 0.0433305, ...</td>\n",
       "      <td>[[-0.129796, 0.467595, -0.160948, 0.13798, -0....</td>\n",
       "      <td>[[0.0794180035591, -0.0698861926794, 0.0105229...</td>\n",
       "      <td>[[-0.12979593873, 0.467594563961, -0.160947903...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>oil price fell more thursday libya prepare res...</td>\n",
       "      <td>15</td>\n",
       "      <td>              ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>turkish prime minister tayyip erdogan accuse p...</td>\n",
       "      <td>[[-0.122633, -0.213171, -0.236308, -0.440996, ...</td>\n",
       "      <td>[[0.00253854, -0.129143, -0.126948, 0.0700992,...</td>\n",
       "      <td>[[-0.122633, -0.213171, -0.236308, -0.440996, ...</td>\n",
       "      <td>[[0.00253854179755, -0.129142984748, -0.126948...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>freddie mac average u.s. mortgage rate percent...</td>\n",
       "      <td>16</td>\n",
       "      <td>            ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>be discussion high level u.s. government how u...</td>\n",
       "      <td>[[0.348366, -0.0344246, -0.0886954, -0.606096,...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.348365992308, -0.034424636513, -0.08869536...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>u.s. construction spending rise it high level ...</td>\n",
       "      <td>17</td>\n",
       "      <td>    11      3     ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>australian share rise percent wednesday hover ...</td>\n",
       "      <td>[[0.079418, -0.0698862, 0.0105229, 0.0433305, ...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.0794180035591, -0.0698861926794, 0.0105229...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>russia world big oil producer raise output pos...</td>\n",
       "      <td>18</td>\n",
       "      <td>            ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>canadian have die avian influenza return trip ...</td>\n",
       "      <td>[[0.0481659, -0.0320038, 0.00198885, -0.044975...</td>\n",
       "      <td>[[0.17937, 0.0217469, -0.00774201, -0.275233, ...</td>\n",
       "      <td>[[0.0481659, -0.0320038, 0.00198885, -0.044975...</td>\n",
       "      <td>[[0.179370418191, 0.0217469427735, -0.00774200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>morning fix</td>\n",
       "      <td>19</td>\n",
       "      <td>            </td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>former french president nicolas sarkozy be pla...</td>\n",
       "      <td>[[0.0178536, -0.137507, -0.101738, -0.0816501,...</td>\n",
       "      <td>[[-0.0987584, -0.130326, 0.000382429, 0.453031...</td>\n",
       "      <td>[[0.0178535878658, -0.137506857514, -0.1017375...</td>\n",
       "      <td>[[-0.09875844419, -0.130326345563, 0.000382429...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>premium italian spanish bond offer benchmark g...</td>\n",
       "      <td>20</td>\n",
       "      <td>              ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>crude price plunge further monday opec once ag...</td>\n",
       "      <td>[[0.172091, -0.28611, 0.0797486, -0.0987142, 0...</td>\n",
       "      <td>[[-0.401097, -0.568938, -0.155227, 0.434545, -...</td>\n",
       "      <td>[[0.172091, -0.28611, 0.0797486, -0.0987142, 0...</td>\n",
       "      <td>[[-0.401097238064, -0.56893825531, -0.15522733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>china yuan pull back slightly record high doll...</td>\n",
       "      <td>21</td>\n",
       "      <td>        12    ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>european stock fell early trade monday resume ...</td>\n",
       "      <td>[[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...</td>\n",
       "      <td>[[-0.0356909, 0.0368742, -0.210699, -0.0758654...</td>\n",
       "      <td>[[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...</td>\n",
       "      <td>[[-0.0356909483671, 0.0368741899729, -0.210698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>italian carmaker fiat spa say wednesday it hav...</td>\n",
       "      <td>22</td>\n",
       "      <td>   FIAT        ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pro-russian separatist ukraine have agree prov...</td>\n",
       "      <td>[[0.14417, -0.206665, -0.0273102, 0.378012, 0....</td>\n",
       "      <td>[[0.0566944, 0.221398, -0.105711, -0.144083, -...</td>\n",
       "      <td>[[0.144170120358, -0.206664994359, -0.02731021...</td>\n",
       "      <td>[[0.0566943995655, 0.221398234367, -0.10571137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>brent crude rise barrel thursday decline oil s...</td>\n",
       "      <td>23</td>\n",
       "      <td>              ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>* share india essar oil ltd astrazeneca pharma...</td>\n",
       "      <td>[[-0.00470701, -0.396765, -0.322486, -0.53076,...</td>\n",
       "      <td>[[0.00253854, -0.129143, -0.126948, 0.0700992,...</td>\n",
       "      <td>[[-0.00470701325685, -0.396764904261, -0.32248...</td>\n",
       "      <td>[[0.00253854179755, -0.129142984748, -0.126948...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>china have approve more company list mainland ...</td>\n",
       "      <td>24</td>\n",
       "      <td>             ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>european central bank keep interest rate recor...</td>\n",
       "      <td>[[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...</td>\n",
       "      <td>[[0.364929, 0.0202659, 0.170838, 0.0298371, -0...</td>\n",
       "      <td>[[-0.0418512448668, 0.0643166452646, 0.1977352...</td>\n",
       "      <td>[[0.364928901196, 0.0202658716589, 0.170837789...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>janet yellen come step close final approval fe...</td>\n",
       "      <td>25</td>\n",
       "      <td>   FRB         ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>time warner inc break financials it premium mo...</td>\n",
       "      <td>[[0.237401, 0.362354, -0.204507, -0.237838, 0....</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.237400531769, 0.362354069948, -0.204507112...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>libya hop resume oil production it large oilfi...</td>\n",
       "      <td>26</td>\n",
       "      <td>             ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mcdonald corp say it business have be hurt chi...</td>\n",
       "      <td>[[0.178806, 0.105778, -0.390584, 0.0331697, -0...</td>\n",
       "      <td>[[0.41208, -0.134387, -0.464477, -0.0422248, 0...</td>\n",
       "      <td>[[0.178805798292, 0.105777747929, -0.390584498...</td>\n",
       "      <td>[[0.412079721689, -0.134387344122, -0.46447741...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>italian carmaker fiat spa strike deal gain ful...</td>\n",
       "      <td>27</td>\n",
       "      <td>   FIAT        ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spec flip usd net long vs bln small net short ...</td>\n",
       "      <td>[[0.14417, -0.206665, -0.0273102, 0.378012, 0....</td>\n",
       "      <td>[[0.0566944, 0.221398, -0.105711, -0.144083, -...</td>\n",
       "      <td>[[0.14417, -0.206665, -0.0273102, 0.378012, 0....</td>\n",
       "      <td>[[0.0566943995655, 0.221398234367, -0.10571137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>number american file new claim unemployment be...</td>\n",
       "      <td>28</td>\n",
       "      <td>    12          ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nokia surprise investor strong quarterly earni...</td>\n",
       "      <td>[[-0.0908237, 0.126889, -0.305503, -0.0270881,...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[-0.0908236578107, 0.126888975501, -0.3055031...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>britain top share index fell first trading day...</td>\n",
       "      <td>29</td>\n",
       "      <td>           ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>burger king be talk acquire canadian coffee do...</td>\n",
       "      <td>[[-0.137006, 0.105725, 0.115759, 0.41086, 0.34...</td>\n",
       "      <td>[[-0.401097, -0.568938, -0.155227, 0.434545, -...</td>\n",
       "      <td>[[-0.137006, 0.105725, 0.115759, 0.41086, 0.34...</td>\n",
       "      <td>[[-0.401097238064, -0.56893825531, -0.15522733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>4973</td>\n",
       "      <td>sharp emerge market sell-off appear subside th...</td>\n",
       "      <td>4973</td>\n",
       "      <td>            ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>quota allocate china dollar-dominated qualifie...</td>\n",
       "      <td>[[-0.181887, 0.187679, -0.0888446, -0.284644, ...</td>\n",
       "      <td>[[0.405083, 0.0932307, 0.823482, -0.377643, -0...</td>\n",
       "      <td>[[-0.181887, 0.187679, -0.0888446, -0.284644, ...</td>\n",
       "      <td>[[0.405083149672, 0.0932307168841, 0.823481857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>4974</td>\n",
       "      <td>taiwan financial market be closed jan feb chin...</td>\n",
       "      <td>4974</td>\n",
       "      <td>             1 2...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>european central bank leave interest rate unch...</td>\n",
       "      <td>[[0.140891, 0.133389, -0.259482, -0.045965, 0....</td>\n",
       "      <td>[[0.232547, -0.519346, -0.280419, 0.204819, -0...</td>\n",
       "      <td>[[0.140890628099, 0.133389428258, -0.259482234...</td>\n",
       "      <td>[[0.232547223568, -0.519345581532, -0.28041857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>4975</td>\n",
       "      <td>wall street rebound open thursday previous ses...</td>\n",
       "      <td>4975</td>\n",
       "      <td>               ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>european central bank keep interest rate stead...</td>\n",
       "      <td>[[0.261115, 0.322767, -0.0312655, -0.031369, 0...</td>\n",
       "      <td>[[-0.401097, -0.568938, -0.155227, 0.434545, -...</td>\n",
       "      <td>[[0.26111510396, 0.322767198086, -0.0312655344...</td>\n",
       "      <td>[[-0.401097238064, -0.56893825531, -0.15522733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>4976</td>\n",
       "      <td>dollar rise basket currency thursday data show...</td>\n",
       "      <td>4976</td>\n",
       "      <td>               ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hundred hong kong police forcible remove kicki...</td>\n",
       "      <td>[[0.0591501, -0.00193826, -0.357213, 0.115154,...</td>\n",
       "      <td>[[0.0464822, -0.0669743, 0.123004, -0.122508, ...</td>\n",
       "      <td>[[0.0591500923038, -0.00193826400209, -0.35721...</td>\n",
       "      <td>[[0.046482168138, -0.0669743493199, 0.12300406...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>4977</td>\n",
       "      <td>amazon.com inc report close-to-expected sale c...</td>\n",
       "      <td>4977</td>\n",
       "      <td>            ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>india market regulator monday partial reverse ...</td>\n",
       "      <td>[[-0.44227, 0.342926, 0.8082, -0.0856614, 0.25...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[-0.442269712687, 0.342925727367, 0.808200478...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>4978</td>\n",
       "      <td>jetblue airway wednesday report higher-than-ex...</td>\n",
       "      <td>4978</td>\n",
       "      <td>  JetBlue  Waze       ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>european central bank leave interest rate unch...</td>\n",
       "      <td>[[0.0560445, -0.0741857, -0.169413, 0.207105, ...</td>\n",
       "      <td>[[0.162483, -0.0885207, -0.177669, 0.0562228, ...</td>\n",
       "      <td>[[0.0560445040464, -0.0741856694221, -0.169412...</td>\n",
       "      <td>[[0.162483349442, -0.0885207280517, -0.1776690...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>4979</td>\n",
       "      <td>* custody holding treasury fell bln-ifr* large...</td>\n",
       "      <td>4979</td>\n",
       "      <td>         FRB   FRB ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>britain first increase interest rate financial...</td>\n",
       "      <td>[[0.060403, -0.21116, -0.112524, 0.418048, -0....</td>\n",
       "      <td>[[-0.448259, 0.418138, -0.0675213, 0.173515, -...</td>\n",
       "      <td>[[0.0604030229151, -0.211159676313, -0.1125241...</td>\n",
       "      <td>[[-0.448258966208, 0.418137580156, -0.06752131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>4980</td>\n",
       "      <td>swiss drugmaker roche report full-year profit ...</td>\n",
       "      <td>4980</td>\n",
       "      <td>            ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>* stop channel resistance trip close rally tow...</td>\n",
       "      <td>[[0.531755, 0.0465069, -0.280278, 0.0207437, -...</td>\n",
       "      <td>[[0.0230546, 0.134405, 0.276877, -0.215977, -0...</td>\n",
       "      <td>[[0.531755208969, 0.0465068519115, -0.28027793...</td>\n",
       "      <td>[[0.0230546388775, 0.134404763579, 0.276877105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>4981</td>\n",
       "      <td>u.s. president barack obama nod trade his annu...</td>\n",
       "      <td>4981</td>\n",
       "      <td>             ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>u.s. house price rise will probable slow furth...</td>\n",
       "      <td>[[0.079418, -0.0698862, 0.0105229, 0.0433305, ...</td>\n",
       "      <td>[[0.393028, 0.0563531, -0.249674, -0.0347517, ...</td>\n",
       "      <td>[[0.079418, -0.0698862, 0.0105229, 0.0433305, ...</td>\n",
       "      <td>[[0.393028, 0.0563531, -0.249674, -0.0347517, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>4982</td>\n",
       "      <td>starbucks corp chief executive officer howard ...</td>\n",
       "      <td>4982</td>\n",
       "      <td>        ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>federal reserve wednesday end it monthly bond ...</td>\n",
       "      <td>[[-0.0383446, 0.155325, 0.62502, 0.152943, 0.0...</td>\n",
       "      <td>[[0.386177, -0.115329, 0.18794, -0.0113484, -0...</td>\n",
       "      <td>[[-0.0383446030319, 0.155325382948, 0.62501972...</td>\n",
       "      <td>[[0.386177003384, -0.115329496562, 0.187939628...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>4983</td>\n",
       "      <td>china lenovo group be near deal buy google inc...</td>\n",
       "      <td>4983</td>\n",
       "      <td>  PC     Google Inc. ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>follow be highlight remark economy monetary po...</td>\n",
       "      <td>[[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...</td>\n",
       "      <td>[[0.364929, 0.0202659, 0.170838, 0.0298371, -0...</td>\n",
       "      <td>[[-0.0418512448668, 0.0643166452646, 0.1977352...</td>\n",
       "      <td>[[0.364928901196, 0.0202658716589, 0.170837789...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>4984</td>\n",
       "      <td>detail u.s. treasury auction 13-week 26-week 5...</td>\n",
       "      <td>4984</td>\n",
       "      <td> 2          </td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bank england be not close raise interest rate ...</td>\n",
       "      <td>[[0.141714, 0.116061, -0.0546338, -0.234393, -...</td>\n",
       "      <td>[[-0.440666, 0.610078, -0.0983196, 0.801558, 0...</td>\n",
       "      <td>[[0.14171436429, 0.116061158478, -0.0546337664...</td>\n",
       "      <td>[[-0.440665841103, 0.610077679157, -0.09831961...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>4985</td>\n",
       "      <td>infineon expect demand microchip use car smart...</td>\n",
       "      <td>4985</td>\n",
       "      <td>       12 ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mexican economic growth will accelerate percen...</td>\n",
       "      <td>[[0.161593, 0.154688, 0.199677, 0.0963585, 0.1...</td>\n",
       "      <td>[[-0.0851713, 0.205356, 0.125934, -0.069173, -...</td>\n",
       "      <td>[[0.161593, 0.154688, 0.199677, 0.0963585, 0.1...</td>\n",
       "      <td>[[-0.0851713418961, 0.205355525017, 0.12593433...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>4986</td>\n",
       "      <td>reverse wednesday loss em pressure dissipated*...</td>\n",
       "      <td>4986</td>\n",
       "      <td>            ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hong kong justice department hand investigatio...</td>\n",
       "      <td>[[-0.0972391, -0.0130996, 0.0103848, 0.196479,...</td>\n",
       "      <td>[[0.0193808, -0.0897314, 0.0394857, 0.224606, ...</td>\n",
       "      <td>[[-0.097239099443, -0.0130996406078, 0.0103847...</td>\n",
       "      <td>[[0.0193807650357, -0.0897313952446, 0.0394856...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>4987</td>\n",
       "      <td>amazon.com inc miss wall street profit estimat...</td>\n",
       "      <td>4987</td>\n",
       "      <td>             ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>congressional negotiator race tuesday wrap fin...</td>\n",
       "      <td>[[-0.44227, 0.342926, 0.8082, -0.0856614, 0.25...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[-0.442269712687, 0.342925727367, 0.808200478...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>4988</td>\n",
       "      <td>turkey be not consider sort capital control it...</td>\n",
       "      <td>4988</td>\n",
       "      <td>            ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>following bid merger acquisition disposal be r...</td>\n",
       "      <td>[[0.205812, -0.0776789, -0.0100262, 0.0848734,...</td>\n",
       "      <td>[[0.489795, -0.096977, -0.235068, -0.26358, 0....</td>\n",
       "      <td>[[0.205812335014, -0.0776788592339, -0.0100261...</td>\n",
       "      <td>[[0.489795058966, -0.096977032721, -0.23506839...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>4989</td>\n",
       "      <td>australian share fell percent thursday wall st...</td>\n",
       "      <td>4989</td>\n",
       "      <td>P AS    GM         ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fiat say late wednesday it have call sharehold...</td>\n",
       "      <td>[[0.229783, 0.0867598, -0.154559, -0.0812089, ...</td>\n",
       "      <td>[[-0.308348, -0.29255, -0.608433, 0.365757, -0...</td>\n",
       "      <td>[[0.229783073068, 0.0867598429322, -0.15455880...</td>\n",
       "      <td>[[-0.308347702026, -0.292549997568, -0.6084330...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>4990</td>\n",
       "      <td>massive rate hike may have stall turkish lira ...</td>\n",
       "      <td>4990</td>\n",
       "      <td>            ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>china key money rate slump four-month low week...</td>\n",
       "      <td>[[0.323224, 0.0206201, 0.0343361, -0.0548864, ...</td>\n",
       "      <td>[[0.489795, -0.096977, -0.235068, -0.26358, 0....</td>\n",
       "      <td>[[0.323224, 0.0206201, 0.0343361, -0.0548864, ...</td>\n",
       "      <td>[[0.489795058966, -0.096977032721, -0.23506839...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>4991</td>\n",
       "      <td>thailand army will increase number troop capit...</td>\n",
       "      <td>4991</td>\n",
       "      <td>             ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>european central bank unexpected cut interest ...</td>\n",
       "      <td>[[-0.00144556, -0.080357, -0.164071, 0.396402,...</td>\n",
       "      <td>[[-0.0549502, -0.123358, -0.252149, -0.161471,...</td>\n",
       "      <td>[[-0.00144556, -0.080357, -0.164071, 0.396402,...</td>\n",
       "      <td>[[-0.054950222373, -0.123358346522, -0.2521488...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>4992</td>\n",
       "      <td>recent outbreak bird flu china have cost poult...</td>\n",
       "      <td>4992</td>\n",
       "      <td>             ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>u.s. federal reserve be widely expect chop it ...</td>\n",
       "      <td>[[-0.0184049, -0.11853, -0.113298, -0.102021, ...</td>\n",
       "      <td>[[0.307846, 0.304336, -0.384274, 0.275885, -0....</td>\n",
       "      <td>[[-0.0184048675001, -0.118529520929, -0.113297...</td>\n",
       "      <td>[[0.307845532894, 0.30433639884, -0.3842737972...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>4993</td>\n",
       "      <td>italy benchmark 10-year debt cost fell their l...</td>\n",
       "      <td>4993</td>\n",
       "      <td>      8        ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>president vladimir putin say wednesday it will...</td>\n",
       "      <td>[[-0.0289411, -0.00576493, -0.0602972, 0.43231...</td>\n",
       "      <td>[[0.0566944, 0.221398, -0.105711, -0.144083, -...</td>\n",
       "      <td>[[-0.0289410501719, -0.00576493237168, -0.0602...</td>\n",
       "      <td>[[0.0566943995655, 0.221398234367, -0.10571137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>4994</td>\n",
       "      <td>china ruling communist party have expel former...</td>\n",
       "      <td>4994</td>\n",
       "      <td>              ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>china share end down slightly wednesday bevera...</td>\n",
       "      <td>[[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...</td>\n",
       "      <td>[[-0.264259, -0.00900147, 0.236856, 0.181937, ...</td>\n",
       "      <td>[[-0.0418512448668, 0.0643166452646, 0.1977352...</td>\n",
       "      <td>[[-0.264258921146, -0.00900147110224, 0.236855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>google inc quarterly revenue beat wall street ...</td>\n",
       "      <td>4995</td>\n",
       "      <td>    Google Inc.      ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sprint corp have drop it bid acquire no u.s. c...</td>\n",
       "      <td>[[-0.184489, 0.108974, 0.432585, -0.259388, 0....</td>\n",
       "      <td>[[-0.073621, -0.46774, -0.243989, 0.10658, -0....</td>\n",
       "      <td>[[-0.184488818049, 0.108973585069, 0.432584911...</td>\n",
       "      <td>[[-0.0736210420728, -0.467739701271, -0.243988...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>turkey lira weaken dollar thursday late trade ...</td>\n",
       "      <td>4996</td>\n",
       "      <td>TRY             ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>federal reserve be risk it credibility not act...</td>\n",
       "      <td>[[0.205812, -0.0776789, -0.0100262, 0.0848734,...</td>\n",
       "      <td>[[-0.0531319, 0.0673207, 0.207877, 0.0881506, ...</td>\n",
       "      <td>[[0.205812335014, -0.0776788592339, -0.0100261...</td>\n",
       "      <td>[[-0.0531319342554, 0.067320741713, 0.20787686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>exxon mobil corp world large public trade oil ...</td>\n",
       "      <td>4997</td>\n",
       "      <td>             ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>russia qualify next month soccer world cup hos...</td>\n",
       "      <td>[[0.0399386, 0.127008, -0.189544, -0.172313, -...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.0399386, 0.127008, -0.189544, -0.172313, -...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>visa inc chief executive urge u.s. merchant ba...</td>\n",
       "      <td>4998</td>\n",
       "      <td>       12    ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>china create new job city first month year bri...</td>\n",
       "      <td>[[-0.383909, 0.376686, 0.0438472, 0.0146235, -...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[-0.383908867836, 0.376686453819, 0.043847214...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>singapore share hit five-month low thursday po...</td>\n",
       "      <td>4999</td>\n",
       "      <td>            ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>u.s. company pick pace hiring march signal dam...</td>\n",
       "      <td>[[-0.00751844, -0.0674906, -0.356288, 0.060561...</td>\n",
       "      <td>[[0.261055, -0.130575, -0.261364, 0.0722576, 0...</td>\n",
       "      <td>[[-0.00751843955368, -0.0674905627966, -0.3562...</td>\n",
       "      <td>[[0.261055022478, -0.130575269461, -0.26136353...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>5000</td>\n",
       "      <td>symantec corp report percent fall quarterly re...</td>\n",
       "      <td>5000</td>\n",
       "      <td>    Symantec    12  ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>china have exclude u.s.-based symantec corp ru...</td>\n",
       "      <td>[[0.211295, 0.339492, 0.265527, 0.210434, 0.02...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.211294844747, 0.339491575956, 0.2655267417...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>5001</td>\n",
       "      <td>northrop grumman corp maker surveillance drone...</td>\n",
       "      <td>5001</td>\n",
       "      <td>           ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nissan motor co unveil it new taxi london mond...</td>\n",
       "      <td>[[0.313289, 0.0940975, -0.0294598, 0.110512, 0...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.313289284706, 0.094097495079, -0.029459763...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>5002</td>\n",
       "      <td>author be reuters breakingviews columnist opin...</td>\n",
       "      <td>5002</td>\n",
       "      <td>   Google Inc.       ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>singapore-listed frasers centrepoint ltd make ...</td>\n",
       "      <td>[[0.0817824, -0.07372, -0.377568, 0.0546247, -...</td>\n",
       "      <td>[[-0.728102, 0.445352, -0.220505, 0.212112, -0...</td>\n",
       "      <td>[[0.0817824, -0.07372, -0.377568, 0.0546247, -...</td>\n",
       "      <td>[[-0.728102147579, 0.445351630449, -0.22050540...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                         en_article  \\\n",
       "0              0  u.s. commerce department seasonal adjust annua...   \n",
       "1              1  chinese budget smartphone maker xiaomi plan se...   \n",
       "2              2  samsung electronics co ltd fell more percent t...   \n",
       "3              3  fiat deal gain full control chrysler group llc...   \n",
       "4              4  fiat share jump thursday it strike deal gain f...   \n",
       "5              5  u.s. treasuries price rise thursday benchmark ...   \n",
       "6              6                     auction detail see 3-year note   \n",
       "7              7  brent crude sink barrel thursday libya prepare...   \n",
       "8              8  gauge u.s. factory activity hold 2-1/2-year hi...   \n",
       "9              9  work massive panama canal extension project ma...   \n",
       "10            10  increase december car sale france spain prompt...   \n",
       "11            11  federal reserve provide liquidity foreign cent...   \n",
       "12            12  new car sale spain rise percent year early car...   \n",
       "13            13  south korean auto maker hyundai motor co kia m...   \n",
       "14            14  u.s. manufacturing end year high note grow dec...   \n",
       "15            15  oil price fell more thursday libya prepare res...   \n",
       "16            16  freddie mac average u.s. mortgage rate percent...   \n",
       "17            17  u.s. construction spending rise it high level ...   \n",
       "18            18  russia world big oil producer raise output pos...   \n",
       "19            19                                        morning fix   \n",
       "20            20  premium italian spanish bond offer benchmark g...   \n",
       "21            21  china yuan pull back slightly record high doll...   \n",
       "22            22  italian carmaker fiat spa say wednesday it hav...   \n",
       "23            23  brent crude rise barrel thursday decline oil s...   \n",
       "24            24  china have approve more company list mainland ...   \n",
       "25            25  janet yellen come step close final approval fe...   \n",
       "26            26  libya hop resume oil production it large oilfi...   \n",
       "27            27  italian carmaker fiat spa strike deal gain ful...   \n",
       "28            28  number american file new claim unemployment be...   \n",
       "29            29  britain top share index fell first trading day...   \n",
       "...          ...                                                ...   \n",
       "4973        4973  sharp emerge market sell-off appear subside th...   \n",
       "4974        4974  taiwan financial market be closed jan feb chin...   \n",
       "4975        4975  wall street rebound open thursday previous ses...   \n",
       "4976        4976  dollar rise basket currency thursday data show...   \n",
       "4977        4977  amazon.com inc report close-to-expected sale c...   \n",
       "4978        4978  jetblue airway wednesday report higher-than-ex...   \n",
       "4979        4979  * custody holding treasury fell bln-ifr* large...   \n",
       "4980        4980  swiss drugmaker roche report full-year profit ...   \n",
       "4981        4981  u.s. president barack obama nod trade his annu...   \n",
       "4982        4982  starbucks corp chief executive officer howard ...   \n",
       "4983        4983  china lenovo group be near deal buy google inc...   \n",
       "4984        4984  detail u.s. treasury auction 13-week 26-week 5...   \n",
       "4985        4985  infineon expect demand microchip use car smart...   \n",
       "4986        4986  reverse wednesday loss em pressure dissipated*...   \n",
       "4987        4987  amazon.com inc miss wall street profit estimat...   \n",
       "4988        4988  turkey be not consider sort capital control it...   \n",
       "4989        4989  australian share fell percent thursday wall st...   \n",
       "4990        4990  massive rate hike may have stall turkish lira ...   \n",
       "4991        4991  thailand army will increase number troop capit...   \n",
       "4992        4992  recent outbreak bird flu china have cost poult...   \n",
       "4993        4993  italy benchmark 10-year debt cost fell their l...   \n",
       "4994        4994  china ruling communist party have expel former...   \n",
       "4995        4995  google inc quarterly revenue beat wall street ...   \n",
       "4996        4996  turkey lira weaken dollar thursday late trade ...   \n",
       "4997        4997  exxon mobil corp world large public trade oil ...   \n",
       "4998        4998  visa inc chief executive urge u.s. merchant ba...   \n",
       "4999        4999  singapore share hit five-month low thursday po...   \n",
       "5000        5000  symantec corp report percent fall quarterly re...   \n",
       "5001        5001  northrop grumman corp maker surveillance drone...   \n",
       "5002        5002  author be reuters breakingviews columnist opin...   \n",
       "\n",
       "      Unnamed: 0                                         jp_article  \\\n",
       "0              0                ...   \n",
       "1              1       ()       ...   \n",
       "2              2             ...   \n",
       "3              3       FIAT     8   ...   \n",
       "4              4       FIAT     8   ...   \n",
       "5              5                 ...   \n",
       "6              6                1 11 11   \n",
       "7              7                ...   \n",
       "8              8      12          ...   \n",
       "9              9            PC  ...   \n",
       "10            10  12           ...   \n",
       "11            11    FRB         ...   \n",
       "12            12               ...   \n",
       "13            13             ...   \n",
       "14            14  Markit   12    PM  1  ...   \n",
       "15            15                ...   \n",
       "16            16              ...   \n",
       "17            17      11      3     ...   \n",
       "18            18              ...   \n",
       "19            19                          \n",
       "20            20                ...   \n",
       "21            21          12    ...   \n",
       "22            22     FIAT        ...   \n",
       "23            23                ...   \n",
       "24            24               ...   \n",
       "25            25     FRB         ...   \n",
       "26            26               ...   \n",
       "27            27     FIAT        ...   \n",
       "28            28      12          ...   \n",
       "29            29             ...   \n",
       "...          ...                                                ...   \n",
       "4973        4973              ...   \n",
       "4974        4974               1 2...   \n",
       "4975        4975                 ...   \n",
       "4976        4976                 ...   \n",
       "4977        4977              ...   \n",
       "4978        4978    JetBlue  Waze       ...   \n",
       "4979        4979           FRB   FRB ...   \n",
       "4980        4980              ...   \n",
       "4981        4981               ...   \n",
       "4982        4982          ...   \n",
       "4983        4983    PC     Google Inc. ...   \n",
       "4984        4984              2              \n",
       "4985        4985         12 ...   \n",
       "4986        4986              ...   \n",
       "4987        4987               ...   \n",
       "4988        4988              ...   \n",
       "4989        4989  P AS    GM         ...   \n",
       "4990        4990              ...   \n",
       "4991        4991               ...   \n",
       "4992        4992               ...   \n",
       "4993        4993        8        ...   \n",
       "4994        4994                ...   \n",
       "4995        4995      Google Inc.      ...   \n",
       "4996        4996  TRY             ...   \n",
       "4997        4997               ...   \n",
       "4998        4998         12    ...   \n",
       "4999        4999              ...   \n",
       "5000        5000      Symantec    12  ...   \n",
       "5001        5001             ...   \n",
       "5002        5002     Google Inc.       ...   \n",
       "\n",
       "      similarity  dis_similarity  \\\n",
       "0            5.0             1.0   \n",
       "1            5.0             1.0   \n",
       "2            5.0             1.0   \n",
       "3            5.0             1.0   \n",
       "4            5.0             1.0   \n",
       "5            5.0             1.0   \n",
       "6            5.0             1.0   \n",
       "7            5.0             1.0   \n",
       "8            5.0             1.0   \n",
       "9            5.0             1.0   \n",
       "10           5.0             1.0   \n",
       "11           5.0             1.0   \n",
       "12           5.0             1.0   \n",
       "13           5.0             1.0   \n",
       "14           5.0             1.0   \n",
       "15           5.0             1.0   \n",
       "16           5.0             1.0   \n",
       "17           5.0             1.0   \n",
       "18           5.0             1.0   \n",
       "19           5.0             1.0   \n",
       "20           5.0             1.0   \n",
       "21           5.0             1.0   \n",
       "22           5.0             1.0   \n",
       "23           5.0             1.0   \n",
       "24           5.0             1.0   \n",
       "25           5.0             1.0   \n",
       "26           5.0             1.0   \n",
       "27           5.0             1.0   \n",
       "28           5.0             1.0   \n",
       "29           5.0             1.0   \n",
       "...          ...             ...   \n",
       "4973         5.0             1.0   \n",
       "4974         5.0             1.0   \n",
       "4975         5.0             1.0   \n",
       "4976         5.0             1.0   \n",
       "4977         5.0             1.0   \n",
       "4978         5.0             1.0   \n",
       "4979         5.0             1.0   \n",
       "4980         5.0             1.0   \n",
       "4981         5.0             1.0   \n",
       "4982         5.0             1.0   \n",
       "4983         5.0             1.0   \n",
       "4984         5.0             1.0   \n",
       "4985         5.0             1.0   \n",
       "4986         5.0             1.0   \n",
       "4987         5.0             1.0   \n",
       "4988         5.0             1.0   \n",
       "4989         5.0             1.0   \n",
       "4990         5.0             1.0   \n",
       "4991         5.0             1.0   \n",
       "4992         5.0             1.0   \n",
       "4993         5.0             1.0   \n",
       "4994         5.0             1.0   \n",
       "4995         5.0             1.0   \n",
       "4996         5.0             1.0   \n",
       "4997         5.0             1.0   \n",
       "4998         5.0             1.0   \n",
       "4999         5.0             1.0   \n",
       "5000         5.0             1.0   \n",
       "5001         5.0             1.0   \n",
       "5002         5.0             1.0   \n",
       "\n",
       "                                       en_article_wrong  \\\n",
       "0     philippine will offer tender next year airport...   \n",
       "1     taiwanese bank have exposure loan company chin...   \n",
       "2     bank canada should keep it key interest rate h...   \n",
       "3     brazil incoming finance minister joaquim levy ...   \n",
       "4     u.s. employer add large number worker nearly y...   \n",
       "5     india central bank keep it key policy repo rat...   \n",
       "6     sweden central bank keep it key interest rate ...   \n",
       "7     asset manager credit suisse hedging griffo be ...   \n",
       "8     * usd/cnh close ny trade 6.1370-6.1450 offshor...   \n",
       "9     chipmaker altera corp be work intel corp combi...   \n",
       "10    president francois hollande brush aside questi...   \n",
       "11    share italy third-biggest bank monte dei pasch...   \n",
       "12    seoul share rebound thursday snap day lose str...   \n",
       "13    average new home price china major city drop p...   \n",
       "14    greece economy shrank annual pace percent seco...   \n",
       "15    turkish prime minister tayyip erdogan accuse p...   \n",
       "16    be discussion high level u.s. government how u...   \n",
       "17    australian share rise percent wednesday hover ...   \n",
       "18    canadian have die avian influenza return trip ...   \n",
       "19    former french president nicolas sarkozy be pla...   \n",
       "20    crude price plunge further monday opec once ag...   \n",
       "21    european stock fell early trade monday resume ...   \n",
       "22    pro-russian separatist ukraine have agree prov...   \n",
       "23    * share india essar oil ltd astrazeneca pharma...   \n",
       "24    european central bank keep interest rate recor...   \n",
       "25    time warner inc break financials it premium mo...   \n",
       "26    mcdonald corp say it business have be hurt chi...   \n",
       "27    spec flip usd net long vs bln small net short ...   \n",
       "28    nokia surprise investor strong quarterly earni...   \n",
       "29    burger king be talk acquire canadian coffee do...   \n",
       "...                                                 ...   \n",
       "4973  quota allocate china dollar-dominated qualifie...   \n",
       "4974  european central bank leave interest rate unch...   \n",
       "4975  european central bank keep interest rate stead...   \n",
       "4976  hundred hong kong police forcible remove kicki...   \n",
       "4977  india market regulator monday partial reverse ...   \n",
       "4978  european central bank leave interest rate unch...   \n",
       "4979  britain first increase interest rate financial...   \n",
       "4980  * stop channel resistance trip close rally tow...   \n",
       "4981  u.s. house price rise will probable slow furth...   \n",
       "4982  federal reserve wednesday end it monthly bond ...   \n",
       "4983  follow be highlight remark economy monetary po...   \n",
       "4984  bank england be not close raise interest rate ...   \n",
       "4985  mexican economic growth will accelerate percen...   \n",
       "4986  hong kong justice department hand investigatio...   \n",
       "4987  congressional negotiator race tuesday wrap fin...   \n",
       "4988  following bid merger acquisition disposal be r...   \n",
       "4989  fiat say late wednesday it have call sharehold...   \n",
       "4990  china key money rate slump four-month low week...   \n",
       "4991  european central bank unexpected cut interest ...   \n",
       "4992  u.s. federal reserve be widely expect chop it ...   \n",
       "4993  president vladimir putin say wednesday it will...   \n",
       "4994  china share end down slightly wednesday bevera...   \n",
       "4995  sprint corp have drop it bid acquire no u.s. c...   \n",
       "4996  federal reserve be risk it credibility not act...   \n",
       "4997  russia qualify next month soccer world cup hos...   \n",
       "4998  china create new job city first month year bri...   \n",
       "4999  u.s. company pick pace hiring march signal dam...   \n",
       "5000  china have exclude u.s.-based symantec corp ru...   \n",
       "5001  nissan motor co unveil it new taxi london mond...   \n",
       "5002  singapore-listed frasers centrepoint ltd make ...   \n",
       "\n",
       "                                            word2vec_en  \\\n",
       "0     [[0.079418, -0.0698862, 0.0105229, 0.0433305, ...   \n",
       "1     [[0.0946131, 0.0954258, 0.201975, -0.18888, 0....   \n",
       "2     [[0.111116, 0.163467, 0.173304, -0.21241, 0.19...   \n",
       "3     [[0.252217, -0.149704, -0.000305933, 0.335273,...   \n",
       "4     [[0.252217, -0.149704, -0.000305933, 0.335273,...   \n",
       "5     [[0.079418, -0.0698862, 0.0105229, 0.0433305, ...   \n",
       "6     [[0.145339, 0.0967358, -0.290555, -0.157721, 0...   \n",
       "7     [[-0.00470701, -0.396765, -0.322486, -0.53076,...   \n",
       "8     [[0.258893, -0.240117, -0.39061, -0.180771, 0....   \n",
       "9     [[-0.246409, -0.300402, 0.0540296, 0.0361169, ...   \n",
       "10    [[0.0325002, 0.110915, -0.126051, -0.221096, 0...   \n",
       "11    [[0.0761386, 0.273143, -0.42036, -0.0670243, -...   \n",
       "12    [[-0.0148091, 0.0937563, -0.266831, -0.100736,...   \n",
       "13    [[-0.0864343, -0.392118, -0.265892, 0.0306064,...   \n",
       "14    [[0.079418, -0.0698862, 0.0105229, 0.0433305, ...   \n",
       "15    [[-0.122633, -0.213171, -0.236308, -0.440996, ...   \n",
       "16    [[0.348366, -0.0344246, -0.0886954, -0.606096,...   \n",
       "17    [[0.079418, -0.0698862, 0.0105229, 0.0433305, ...   \n",
       "18    [[0.0481659, -0.0320038, 0.00198885, -0.044975...   \n",
       "19    [[0.0178536, -0.137507, -0.101738, -0.0816501,...   \n",
       "20    [[0.172091, -0.28611, 0.0797486, -0.0987142, 0...   \n",
       "21    [[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...   \n",
       "22    [[0.14417, -0.206665, -0.0273102, 0.378012, 0....   \n",
       "23    [[-0.00470701, -0.396765, -0.322486, -0.53076,...   \n",
       "24    [[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...   \n",
       "25    [[0.237401, 0.362354, -0.204507, -0.237838, 0....   \n",
       "26    [[0.178806, 0.105778, -0.390584, 0.0331697, -0...   \n",
       "27    [[0.14417, -0.206665, -0.0273102, 0.378012, 0....   \n",
       "28    [[-0.0908237, 0.126889, -0.305503, -0.0270881,...   \n",
       "29    [[-0.137006, 0.105725, 0.115759, 0.41086, 0.34...   \n",
       "...                                                 ...   \n",
       "4973  [[-0.181887, 0.187679, -0.0888446, -0.284644, ...   \n",
       "4974  [[0.140891, 0.133389, -0.259482, -0.045965, 0....   \n",
       "4975  [[0.261115, 0.322767, -0.0312655, -0.031369, 0...   \n",
       "4976  [[0.0591501, -0.00193826, -0.357213, 0.115154,...   \n",
       "4977  [[-0.44227, 0.342926, 0.8082, -0.0856614, 0.25...   \n",
       "4978  [[0.0560445, -0.0741857, -0.169413, 0.207105, ...   \n",
       "4979  [[0.060403, -0.21116, -0.112524, 0.418048, -0....   \n",
       "4980  [[0.531755, 0.0465069, -0.280278, 0.0207437, -...   \n",
       "4981  [[0.079418, -0.0698862, 0.0105229, 0.0433305, ...   \n",
       "4982  [[-0.0383446, 0.155325, 0.62502, 0.152943, 0.0...   \n",
       "4983  [[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...   \n",
       "4984  [[0.141714, 0.116061, -0.0546338, -0.234393, -...   \n",
       "4985  [[0.161593, 0.154688, 0.199677, 0.0963585, 0.1...   \n",
       "4986  [[-0.0972391, -0.0130996, 0.0103848, 0.196479,...   \n",
       "4987  [[-0.44227, 0.342926, 0.8082, -0.0856614, 0.25...   \n",
       "4988  [[0.205812, -0.0776789, -0.0100262, 0.0848734,...   \n",
       "4989  [[0.229783, 0.0867598, -0.154559, -0.0812089, ...   \n",
       "4990  [[0.323224, 0.0206201, 0.0343361, -0.0548864, ...   \n",
       "4991  [[-0.00144556, -0.080357, -0.164071, 0.396402,...   \n",
       "4992  [[-0.0184049, -0.11853, -0.113298, -0.102021, ...   \n",
       "4993  [[-0.0289411, -0.00576493, -0.0602972, 0.43231...   \n",
       "4994  [[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...   \n",
       "4995  [[-0.184489, 0.108974, 0.432585, -0.259388, 0....   \n",
       "4996  [[0.205812, -0.0776789, -0.0100262, 0.0848734,...   \n",
       "4997  [[0.0399386, 0.127008, -0.189544, -0.172313, -...   \n",
       "4998  [[-0.383909, 0.376686, 0.0438472, 0.0146235, -...   \n",
       "4999  [[-0.00751844, -0.0674906, -0.356288, 0.060561...   \n",
       "5000  [[0.211295, 0.339492, 0.265527, 0.210434, 0.02...   \n",
       "5001  [[0.313289, 0.0940975, -0.0294598, 0.110512, 0...   \n",
       "5002  [[0.0817824, -0.07372, -0.377568, 0.0546247, -...   \n",
       "\n",
       "                                            word2vec_jp  \\\n",
       "0     [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "1     [[0.364929, 0.0202659, 0.170838, 0.0298371, -0...   \n",
       "2     [[0.379925, -0.16321, 0.216476, -0.00105682, -...   \n",
       "3     [[0.27545, 0.0250656, 0.0825939, 0.136058, -0....   \n",
       "4     [[0.27545, 0.0250656, 0.0825939, 0.136058, -0....   \n",
       "5     [[-0.401097, -0.568938, -0.155227, 0.434545, -...   \n",
       "6     [[-0.440666, 0.610078, -0.0983196, 0.801558, 0...   \n",
       "7     [[0.00253854, -0.129143, -0.126948, 0.0700992,...   \n",
       "8     [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "9     [[0.0367229, 0.154389, -0.430821, 0.336414, -0...   \n",
       "10    [[-0.47501, 0.0407163, 0.111163, 0.451794, -0....   \n",
       "11    [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "12    [[-0.101784, 0.297449, -0.0359539, -0.183187, ...   \n",
       "13    [[-0.133516, -0.0476626, -0.0501251, -0.141976...   \n",
       "14    [[-0.129796, 0.467595, -0.160948, 0.13798, -0....   \n",
       "15    [[0.00253854, -0.129143, -0.126948, 0.0700992,...   \n",
       "16    [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "17    [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "18    [[0.17937, 0.0217469, -0.00774201, -0.275233, ...   \n",
       "19    [[-0.0987584, -0.130326, 0.000382429, 0.453031...   \n",
       "20    [[-0.401097, -0.568938, -0.155227, 0.434545, -...   \n",
       "21    [[-0.0356909, 0.0368742, -0.210699, -0.0758654...   \n",
       "22    [[0.0566944, 0.221398, -0.105711, -0.144083, -...   \n",
       "23    [[0.00253854, -0.129143, -0.126948, 0.0700992,...   \n",
       "24    [[0.364929, 0.0202659, 0.170838, 0.0298371, -0...   \n",
       "25    [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "26    [[0.41208, -0.134387, -0.464477, -0.0422248, 0...   \n",
       "27    [[0.0566944, 0.221398, -0.105711, -0.144083, -...   \n",
       "28    [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "29    [[-0.401097, -0.568938, -0.155227, 0.434545, -...   \n",
       "...                                                 ...   \n",
       "4973  [[0.405083, 0.0932307, 0.823482, -0.377643, -0...   \n",
       "4974  [[0.232547, -0.519346, -0.280419, 0.204819, -0...   \n",
       "4975  [[-0.401097, -0.568938, -0.155227, 0.434545, -...   \n",
       "4976  [[0.0464822, -0.0669743, 0.123004, -0.122508, ...   \n",
       "4977  [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "4978  [[0.162483, -0.0885207, -0.177669, 0.0562228, ...   \n",
       "4979  [[-0.448259, 0.418138, -0.0675213, 0.173515, -...   \n",
       "4980  [[0.0230546, 0.134405, 0.276877, -0.215977, -0...   \n",
       "4981  [[0.393028, 0.0563531, -0.249674, -0.0347517, ...   \n",
       "4982  [[0.386177, -0.115329, 0.18794, -0.0113484, -0...   \n",
       "4983  [[0.364929, 0.0202659, 0.170838, 0.0298371, -0...   \n",
       "4984  [[-0.440666, 0.610078, -0.0983196, 0.801558, 0...   \n",
       "4985  [[-0.0851713, 0.205356, 0.125934, -0.069173, -...   \n",
       "4986  [[0.0193808, -0.0897314, 0.0394857, 0.224606, ...   \n",
       "4987  [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "4988  [[0.489795, -0.096977, -0.235068, -0.26358, 0....   \n",
       "4989  [[-0.308348, -0.29255, -0.608433, 0.365757, -0...   \n",
       "4990  [[0.489795, -0.096977, -0.235068, -0.26358, 0....   \n",
       "4991  [[-0.0549502, -0.123358, -0.252149, -0.161471,...   \n",
       "4992  [[0.307846, 0.304336, -0.384274, 0.275885, -0....   \n",
       "4993  [[0.0566944, 0.221398, -0.105711, -0.144083, -...   \n",
       "4994  [[-0.264259, -0.00900147, 0.236856, 0.181937, ...   \n",
       "4995  [[-0.073621, -0.46774, -0.243989, 0.10658, -0....   \n",
       "4996  [[-0.0531319, 0.0673207, 0.207877, 0.0881506, ...   \n",
       "4997  [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "4998  [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "4999  [[0.261055, -0.130575, -0.261364, 0.0722576, 0...   \n",
       "5000  [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "5001  [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "5002  [[-0.728102, 0.445352, -0.220505, 0.212112, -0...   \n",
       "\n",
       "                                             padding_en  \\\n",
       "0     [[0.0794180035591, -0.0698861926794, 0.0105229...   \n",
       "1     [[0.0946130752563, 0.095425799489, 0.201974958...   \n",
       "2     [[0.111115589738, 0.163467362523, 0.1733036488...   \n",
       "3     [[0.252217, -0.149704, -0.000305933, 0.335273,...   \n",
       "4     [[0.252217, -0.149704, -0.000305933, 0.335273,...   \n",
       "5     [[0.079418, -0.0698862, 0.0105229, 0.0433305, ...   \n",
       "6     [[0.145339399576, 0.0967358276248, -0.29055538...   \n",
       "7     [[-0.00470701, -0.396765, -0.322486, -0.53076,...   \n",
       "8     [[0.258893, -0.240117, -0.39061, -0.180771, 0....   \n",
       "9     [[-0.246409475803, -0.300402313471, 0.05402963...   \n",
       "10    [[0.0325002, 0.110915, -0.126051, -0.221096, 0...   \n",
       "11    [[0.0761386305094, 0.27314338088, -0.420359730...   \n",
       "12    [[-0.0148091288283, 0.0937562733889, -0.266831...   \n",
       "13    [[-0.0864343, -0.392118, -0.265892, 0.0306064,...   \n",
       "14    [[0.0794180035591, -0.0698861926794, 0.0105229...   \n",
       "15    [[-0.122633, -0.213171, -0.236308, -0.440996, ...   \n",
       "16    [[0.348365992308, -0.034424636513, -0.08869536...   \n",
       "17    [[0.0794180035591, -0.0698861926794, 0.0105229...   \n",
       "18    [[0.0481659, -0.0320038, 0.00198885, -0.044975...   \n",
       "19    [[0.0178535878658, -0.137506857514, -0.1017375...   \n",
       "20    [[0.172091, -0.28611, 0.0797486, -0.0987142, 0...   \n",
       "21    [[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...   \n",
       "22    [[0.144170120358, -0.206664994359, -0.02731021...   \n",
       "23    [[-0.00470701325685, -0.396764904261, -0.32248...   \n",
       "24    [[-0.0418512448668, 0.0643166452646, 0.1977352...   \n",
       "25    [[0.237400531769, 0.362354069948, -0.204507112...   \n",
       "26    [[0.178805798292, 0.105777747929, -0.390584498...   \n",
       "27    [[0.14417, -0.206665, -0.0273102, 0.378012, 0....   \n",
       "28    [[-0.0908236578107, 0.126888975501, -0.3055031...   \n",
       "29    [[-0.137006, 0.105725, 0.115759, 0.41086, 0.34...   \n",
       "...                                                 ...   \n",
       "4973  [[-0.181887, 0.187679, -0.0888446, -0.284644, ...   \n",
       "4974  [[0.140890628099, 0.133389428258, -0.259482234...   \n",
       "4975  [[0.26111510396, 0.322767198086, -0.0312655344...   \n",
       "4976  [[0.0591500923038, -0.00193826400209, -0.35721...   \n",
       "4977  [[-0.442269712687, 0.342925727367, 0.808200478...   \n",
       "4978  [[0.0560445040464, -0.0741856694221, -0.169412...   \n",
       "4979  [[0.0604030229151, -0.211159676313, -0.1125241...   \n",
       "4980  [[0.531755208969, 0.0465068519115, -0.28027793...   \n",
       "4981  [[0.079418, -0.0698862, 0.0105229, 0.0433305, ...   \n",
       "4982  [[-0.0383446030319, 0.155325382948, 0.62501972...   \n",
       "4983  [[-0.0418512448668, 0.0643166452646, 0.1977352...   \n",
       "4984  [[0.14171436429, 0.116061158478, -0.0546337664...   \n",
       "4985  [[0.161593, 0.154688, 0.199677, 0.0963585, 0.1...   \n",
       "4986  [[-0.097239099443, -0.0130996406078, 0.0103847...   \n",
       "4987  [[-0.442269712687, 0.342925727367, 0.808200478...   \n",
       "4988  [[0.205812335014, -0.0776788592339, -0.0100261...   \n",
       "4989  [[0.229783073068, 0.0867598429322, -0.15455880...   \n",
       "4990  [[0.323224, 0.0206201, 0.0343361, -0.0548864, ...   \n",
       "4991  [[-0.00144556, -0.080357, -0.164071, 0.396402,...   \n",
       "4992  [[-0.0184048675001, -0.118529520929, -0.113297...   \n",
       "4993  [[-0.0289410501719, -0.00576493237168, -0.0602...   \n",
       "4994  [[-0.0418512448668, 0.0643166452646, 0.1977352...   \n",
       "4995  [[-0.184488818049, 0.108973585069, 0.432584911...   \n",
       "4996  [[0.205812335014, -0.0776788592339, -0.0100261...   \n",
       "4997  [[0.0399386, 0.127008, -0.189544, -0.172313, -...   \n",
       "4998  [[-0.383908867836, 0.376686453819, 0.043847214...   \n",
       "4999  [[-0.00751843955368, -0.0674905627966, -0.3562...   \n",
       "5000  [[0.211294844747, 0.339491575956, 0.2655267417...   \n",
       "5001  [[0.313289284706, 0.094097495079, -0.029459763...   \n",
       "5002  [[0.0817824, -0.07372, -0.377568, 0.0546247, -...   \n",
       "\n",
       "                                             padding_jp  \n",
       "0     [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "1     [[0.364928901196, 0.0202658716589, 0.170837789...  \n",
       "2     [[0.379924654961, -0.163209781051, 0.216475769...  \n",
       "3     [[0.275450408459, 0.0250655952841, 0.082593858...  \n",
       "4     [[0.275450408459, 0.0250655952841, 0.082593858...  \n",
       "5     [[-0.401097238064, -0.56893825531, -0.15522733...  \n",
       "6     [[-0.440665841103, 0.610077679157, -0.09831961...  \n",
       "7     [[0.00253854179755, -0.129142984748, -0.126948...  \n",
       "8     [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "9     [[0.0367229022086, 0.154389277101, -0.43082135...  \n",
       "10    [[-0.475010246038, 0.0407162643969, 0.11116266...  \n",
       "11    [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "12    [[-0.10178424418, 0.297449380159, -0.035953946...  \n",
       "13    [[-0.133516088128, -0.0476626008749, -0.050125...  \n",
       "14    [[-0.12979593873, 0.467594563961, -0.160947903...  \n",
       "15    [[0.00253854179755, -0.129142984748, -0.126948...  \n",
       "16    [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "17    [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "18    [[0.179370418191, 0.0217469427735, -0.00774200...  \n",
       "19    [[-0.09875844419, -0.130326345563, 0.000382429...  \n",
       "20    [[-0.401097238064, -0.56893825531, -0.15522733...  \n",
       "21    [[-0.0356909483671, 0.0368741899729, -0.210698...  \n",
       "22    [[0.0566943995655, 0.221398234367, -0.10571137...  \n",
       "23    [[0.00253854179755, -0.129142984748, -0.126948...  \n",
       "24    [[0.364928901196, 0.0202658716589, 0.170837789...  \n",
       "25    [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "26    [[0.412079721689, -0.134387344122, -0.46447741...  \n",
       "27    [[0.0566943995655, 0.221398234367, -0.10571137...  \n",
       "28    [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "29    [[-0.401097238064, -0.56893825531, -0.15522733...  \n",
       "...                                                 ...  \n",
       "4973  [[0.405083149672, 0.0932307168841, 0.823481857...  \n",
       "4974  [[0.232547223568, -0.519345581532, -0.28041857...  \n",
       "4975  [[-0.401097238064, -0.56893825531, -0.15522733...  \n",
       "4976  [[0.046482168138, -0.0669743493199, 0.12300406...  \n",
       "4977  [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "4978  [[0.162483349442, -0.0885207280517, -0.1776690...  \n",
       "4979  [[-0.448258966208, 0.418137580156, -0.06752131...  \n",
       "4980  [[0.0230546388775, 0.134404763579, 0.276877105...  \n",
       "4981  [[0.393028, 0.0563531, -0.249674, -0.0347517, ...  \n",
       "4982  [[0.386177003384, -0.115329496562, 0.187939628...  \n",
       "4983  [[0.364928901196, 0.0202658716589, 0.170837789...  \n",
       "4984  [[-0.440665841103, 0.610077679157, -0.09831961...  \n",
       "4985  [[-0.0851713418961, 0.205355525017, 0.12593433...  \n",
       "4986  [[0.0193807650357, -0.0897313952446, 0.0394856...  \n",
       "4987  [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "4988  [[0.489795058966, -0.096977032721, -0.23506839...  \n",
       "4989  [[-0.308347702026, -0.292549997568, -0.6084330...  \n",
       "4990  [[0.489795058966, -0.096977032721, -0.23506839...  \n",
       "4991  [[-0.054950222373, -0.123358346522, -0.2521488...  \n",
       "4992  [[0.307845532894, 0.30433639884, -0.3842737972...  \n",
       "4993  [[0.0566943995655, 0.221398234367, -0.10571137...  \n",
       "4994  [[-0.264258921146, -0.00900147110224, 0.236855...  \n",
       "4995  [[-0.0736210420728, -0.467739701271, -0.243988...  \n",
       "4996  [[-0.0531319342554, 0.067320741713, 0.20787686...  \n",
       "4997  [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "4998  [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "4999  [[0.261055022478, -0.130575269461, -0.26136353...  \n",
       "5000  [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "5001  [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "5002  [[-0.728102147579, 0.445351630449, -0.22050540...  \n",
       "\n",
       "[5000 rows x 11 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pairs_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unrecognized keyword arguments: {'go_backwards': True}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-f3a604c6a43a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model_lstm2.fit([X1_train, X2_train], [y_train], go_backwards=True,\n\u001b[0;32m----> 2\u001b[0;31m                        validation_data=([X1_test, X2_test], y_test), epochs=50, batch_size=256)\n\u001b[0m",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nb_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized keyword arguments: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized keyword arguments: {'go_backwards': True}"
     ]
    }
   ],
   "source": [
    "hist = model_lstm2.fit([X1_train, X2_train], [y_train], go_backwards=True,\n",
    "                       validation_data=([X1_test, X2_test], y_test), epochs=50, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ma..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.6337 - acc: 0.6641 - val_loss: 0.5705 - val_acc: 0.7120\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 44s - loss: 0.4121 - acc: 0.8139 - val_loss: 0.4276 - val_acc: 0.8045\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.2964 - acc: 0.8811 - val_loss: 0.3740 - val_acc: 0.8475\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.2400 - acc: 0.9083 - val_loss: 0.3988 - val_acc: 0.8440\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 43s - loss: 0.2042 - acc: 0.9263 - val_loss: 0.4031 - val_acc: 0.8375\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 43s - loss: 0.1665 - acc: 0.9404 - val_loss: 0.4219 - val_acc: 0.8495\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 43s - loss: 0.1463 - acc: 0.9506 - val_loss: 0.4112 - val_acc: 0.8590\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.1213 - acc: 0.9590 - val_loss: 0.4353 - val_acc: 0.8510\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 46s - loss: 0.0984 - acc: 0.9693 - val_loss: 0.4692 - val_acc: 0.8525\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 44s - loss: 0.0768 - acc: 0.9768 - val_loss: 0.5122 - val_acc: 0.8550\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 44s - loss: 0.0689 - acc: 0.9785 - val_loss: 0.5768 - val_acc: 0.8415\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.0551 - acc: 0.9850 - val_loss: 0.6299 - val_acc: 0.8255\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.0505 - acc: 0.9864 - val_loss: 0.6526 - val_acc: 0.8435\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.0562 - acc: 0.9821 - val_loss: 0.6089 - val_acc: 0.8580\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 44s - loss: 0.0421 - acc: 0.9888 - val_loss: 0.6459 - val_acc: 0.8550\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 44s - loss: 0.0434 - acc: 0.9881 - val_loss: 0.6481 - val_acc: 0.8485\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.0367 - acc: 0.9904 - val_loss: 0.7227 - val_acc: 0.8520\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.0297 - acc: 0.9925 - val_loss: 0.7390 - val_acc: 0.8545\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 46s - loss: 0.0289 - acc: 0.9920 - val_loss: 0.7331 - val_acc: 0.8530\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 46s - loss: 0.0271 - acc: 0.9920 - val_loss: 0.7866 - val_acc: 0.8430\n",
      "Epoch 21/50\n",
      "1536/8000 [====>.........................] - ETA: 33s - loss: 0.0374 - acc: 0.9889"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-c799418741a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Fit the training model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m hist = model_lstm2.fit([X1_train, X2_train], [y_train],\n\u001b[0;32m---> 30\u001b[0;31m                        validation_data=([X1_test, X2_test], y_test), epochs=50, batch_size=256)\n\u001b[0m",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\t# Input layer\n",
    "\tinput_1 = Input(shape=(maxlen,200), dtype='float32', name='main_input_1')\n",
    "\tinput_2 = Input(shape=(maxlen,200), dtype='float32', name='main_input_2')\n",
    "\n",
    "\t# LSTM layer\n",
    "\t# lstm_out_1 = LSTM(50)(input_1)\n",
    "\t# lstm_out_1 = LSTM(50)(input_1)\n",
    "\tlstm_out_1 = LSTM(50, go_backwards = True)(input_1)\n",
    "\tlstm_out_2 = LSTM(50, go_backwards = True)(input_2)\n",
    "\n",
    "\t# Merge layer\n",
    "\tmerged_vector = keras.layers.concatenate([lstm_out_1, lstm_out_2], axis=-1)\n",
    "\n",
    "\t# (Dense 1) * 3\n",
    "\tx1 = Dense(64, activation='relu')(merged_vector)\n",
    "\tx1 = Dense(64, activation='relu')(x1)\n",
    "\tx1 = Dense(64, activation='relu')(x1)\n",
    "\tmain_output = Dense(1, activation='sigmoid', name='main_output')(x1)\n",
    "\n",
    "\t# Model definition\n",
    "\tmodel_lstm2 = Model(input=[input_1, input_2], output=main_output)\n",
    "\n",
    "\t# Compile the model\n",
    "\tmodel_lstm2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\t# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\t# Fit the training model\n",
    "\thist = model_lstm2.fit([X1_train, X2_train], [y_train],\n",
    "\t                       validation_data=([X1_test, X2_test], y_test), epochs=50, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.87      0.86      1000\n",
      "        1.0       0.87      0.86      0.86      1000\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_eva_predict = model_lstm2.predict([X1_test, X2_test])\n",
    "print(classification_report(y_test, y_eva_predict>.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Find answer for doc.', 0)\n",
      "7.0\n",
      "('Find answer for doc.', 1)\n",
      "1.0\n",
      "('Find answer for doc.', 2)\n",
      "1.0\n",
      "('Find answer for doc.', 3)\n",
      "58.0\n",
      "('Find answer for doc.', 4)\n",
      "84.5\n",
      "('Find answer for doc.', 5)\n",
      "13.0\n",
      "('Find answer for doc.', 6)\n",
      "195.0\n",
      "('Find answer for doc.', 7)\n",
      "6.0\n",
      "('Find answer for doc.', 8)\n",
      "6.0\n",
      "('Find answer for doc.', 9)\n",
      "34.5\n",
      "('Find answer for doc.', 10)\n",
      "3.0\n",
      "('Find answer for doc.', 11)\n",
      "37.0\n",
      "('Find answer for doc.', 12)\n",
      "25.0\n",
      "('Find answer for doc.', 13)\n",
      "1.0\n",
      "('Find answer for doc.', 14)\n",
      "25.5\n",
      "('Find answer for doc.', 15)\n",
      "53.0\n",
      "('Find answer for doc.', 16)\n",
      "29.5\n",
      "('Find answer for doc.', 17)\n",
      "73.0\n",
      "('Find answer for doc.', 18)\n",
      "13.0\n",
      "('Find answer for doc.', 19)\n",
      "15.5\n",
      "('Find answer for doc.', 20)\n",
      "30.0\n",
      "('Find answer for doc.', 21)\n",
      "19.0\n",
      "('Find answer for doc.', 22)\n",
      "73.0\n",
      "('Find answer for doc.', 23)\n",
      "1.0\n",
      "('Find answer for doc.', 24)\n",
      "24.0\n",
      "('Find answer for doc.', 25)\n",
      "8.5\n",
      "('Find answer for doc.', 26)\n",
      "62.0\n",
      "('Find answer for doc.', 27)\n",
      "35.5\n",
      "('Find answer for doc.', 28)\n",
      "1.0\n",
      "('Find answer for doc.', 29)\n",
      "5.0\n",
      "('Find answer for doc.', 30)\n",
      "5.0\n",
      "('Find answer for doc.', 31)\n",
      "6.0\n",
      "('Find answer for doc.', 32)\n",
      "19.0\n",
      "('Find answer for doc.', 33)\n",
      "82.5\n",
      "('Find answer for doc.', 34)\n",
      "6.0\n",
      "('Find answer for doc.', 35)\n",
      "7.0\n",
      "('Find answer for doc.', 36)\n",
      "3.5\n",
      "('Find answer for doc.', 37)\n",
      "62.0\n",
      "('Find answer for doc.', 38)\n",
      "18.0\n",
      "('Find answer for doc.', 39)\n",
      "110.0\n",
      "('Find answer for doc.', 40)\n",
      "10.0\n",
      "('Find answer for doc.', 41)\n",
      "18.5\n",
      "('Find answer for doc.', 42)\n",
      "51.0\n",
      "('Find answer for doc.', 43)\n",
      "14.0\n",
      "('Find answer for doc.', 44)\n",
      "29.0\n",
      "('Find answer for doc.', 45)\n",
      "123.0\n",
      "('Find answer for doc.', 46)\n",
      "4.0\n",
      "('Find answer for doc.', 47)\n",
      "9.0\n",
      "('Find answer for doc.', 48)\n",
      "77.0\n",
      "('Find answer for doc.', 49)\n",
      "199.0\n",
      "('Find answer for doc.', 50)\n",
      "6.0\n",
      "('Find answer for doc.', 51)\n",
      "8.0\n",
      "('Find answer for doc.', 52)\n",
      "32.0\n",
      "('Find answer for doc.', 53)\n",
      "76.0\n",
      "('Find answer for doc.', 54)\n",
      "29.5\n",
      "('Find answer for doc.', 55)\n",
      "28.0\n",
      "('Find answer for doc.', 56)\n",
      "26.0\n",
      "('Find answer for doc.', 57)\n",
      "18.0\n",
      "('Find answer for doc.', 58)\n",
      "29.0\n",
      "('Find answer for doc.', 59)\n",
      "7.0\n",
      "('Find answer for doc.', 60)\n",
      "17.0\n",
      "('Find answer for doc.', 61)\n",
      "16.0\n",
      "('Find answer for doc.', 62)\n",
      "14.0\n",
      "('Find answer for doc.', 63)\n",
      "2.0\n",
      "('Find answer for doc.', 64)\n",
      "38.0\n",
      "('Find answer for doc.', 65)\n",
      "20.0\n",
      "('Find answer for doc.', 66)\n",
      "93.0\n",
      "('Find answer for doc.', 67)\n",
      "16.0\n",
      "('Find answer for doc.', 68)\n",
      "15.0\n",
      "('Find answer for doc.', 69)\n",
      "21.0\n",
      "('Find answer for doc.', 70)\n",
      "80.0\n",
      "('Find answer for doc.', 71)\n",
      "58.0\n",
      "('Find answer for doc.', 72)\n",
      "7.5\n",
      "('Find answer for doc.', 73)\n",
      "2.0\n",
      "('Find answer for doc.', 74)\n",
      "8.0\n",
      "('Find answer for doc.', 75)\n",
      "7.5\n",
      "('Find answer for doc.', 76)\n",
      "18.0\n",
      "('Find answer for doc.', 77)\n",
      "24.5\n",
      "('Find answer for doc.', 78)\n",
      "205.0\n",
      "('Find answer for doc.', 79)\n",
      "1.0\n",
      "('Find answer for doc.', 80)\n",
      "82.5\n",
      "('Find answer for doc.', 81)\n",
      "2.5\n",
      "('Find answer for doc.', 82)\n",
      "5.5\n",
      "('Find answer for doc.', 83)\n",
      "65.0\n",
      "('Find answer for doc.', 84)\n",
      "19.0\n",
      "('Find answer for doc.', 85)\n",
      "2.0\n",
      "('Find answer for doc.', 86)\n",
      "13.5\n",
      "('Find answer for doc.', 87)\n",
      "41.0\n",
      "('Find answer for doc.', 88)\n",
      "21.5\n",
      "('Find answer for doc.', 89)\n",
      "34.5\n",
      "('Find answer for doc.', 90)\n",
      "3.0\n",
      "('Find answer for doc.', 91)\n",
      "1.0\n",
      "('Find answer for doc.', 92)\n",
      "8.0\n",
      "('Find answer for doc.', 93)\n",
      "117.0\n",
      "('Find answer for doc.', 94)\n",
      "5.0\n",
      "('Find answer for doc.', 95)\n",
      "26.0\n",
      "('Find answer for doc.', 96)\n",
      "19.0\n",
      "('Find answer for doc.', 97)\n",
      "79.0\n",
      "('Find answer for doc.', 98)\n",
      "28.0\n",
      "('Find answer for doc.', 99)\n",
      "119.0\n",
      "('Find answer for doc.', 100)\n",
      "8.5\n",
      "('Find answer for doc.', 101)\n",
      "30.0\n",
      "('Find answer for doc.', 102)\n",
      "23.0\n",
      "('Find answer for doc.', 103)\n",
      "30.0\n",
      "('Find answer for doc.', 104)\n",
      "7.5\n",
      "('Find answer for doc.', 105)\n",
      "37.0\n",
      "('Find answer for doc.', 106)\n",
      "2.5\n",
      "('Find answer for doc.', 107)\n",
      "22.5\n",
      "('Find answer for doc.', 108)\n",
      "82.0\n",
      "('Find answer for doc.', 109)\n",
      "15.5\n",
      "('Find answer for doc.', 110)\n",
      "2.0\n",
      "('Find answer for doc.', 111)\n",
      "88.5\n",
      "('Find answer for doc.', 112)\n",
      "46.0\n",
      "('Find answer for doc.', 113)\n",
      "16.0\n",
      "('Find answer for doc.', 114)\n",
      "13.0\n",
      "('Find answer for doc.', 115)\n",
      "82.5\n",
      "('Find answer for doc.', 116)\n",
      "24.0\n",
      "('Find answer for doc.', 117)\n",
      "11.0\n",
      "('Find answer for doc.', 118)\n",
      "78.0\n",
      "('Find answer for doc.', 119)\n",
      "32.0\n",
      "('Find answer for doc.', 120)\n",
      "29.5\n",
      "('Find answer for doc.', 121)\n",
      "15.5\n",
      "('Find answer for doc.', 122)\n",
      "44.0\n",
      "('Find answer for doc.', 123)\n",
      "2.0\n",
      "('Find answer for doc.', 124)\n",
      "12.0\n",
      "('Find answer for doc.', 125)\n",
      "98.0\n",
      "('Find answer for doc.', 126)\n",
      "12.0\n",
      "('Find answer for doc.', 127)\n",
      "7.5\n",
      "('Find answer for doc.', 128)\n",
      "6.5\n",
      "('Find answer for doc.', 129)\n",
      "13.0\n",
      "('Find answer for doc.', 130)\n",
      "2.0\n",
      "('Find answer for doc.', 131)\n",
      "3.0\n",
      "('Find answer for doc.', 132)\n",
      "12.0\n",
      "('Find answer for doc.', 133)\n",
      "18.0\n",
      "('Find answer for doc.', 134)\n",
      "47.0\n",
      "('Find answer for doc.', 135)\n",
      "4.0\n",
      "('Find answer for doc.', 136)\n",
      "24.0\n",
      "('Find answer for doc.', 137)\n",
      "347.0\n",
      "('Find answer for doc.', 138)\n",
      "77.0\n",
      "('Find answer for doc.', 139)\n",
      "115.0\n",
      "('Find answer for doc.', 140)\n",
      "165.0\n",
      "('Find answer for doc.', 141)\n",
      "21.5\n",
      "('Find answer for doc.', 142)\n",
      "2.0\n",
      "('Find answer for doc.', 143)\n",
      "14.0\n",
      "('Find answer for doc.', 144)\n",
      "254.0\n",
      "('Find answer for doc.', 145)\n",
      "8.0\n",
      "('Find answer for doc.', 146)\n",
      "469.0\n",
      "('Find answer for doc.', 147)\n",
      "46.5\n",
      "('Find answer for doc.', 148)\n",
      "14.0\n",
      "('Find answer for doc.', 149)\n",
      "9.0\n",
      "('Find answer for doc.', 150)\n",
      "236.5\n",
      "('Find answer for doc.', 151)\n",
      "4.5\n",
      "('Find answer for doc.', 152)\n",
      "42.0\n",
      "('Find answer for doc.', 153)\n",
      "91.5\n",
      "('Find answer for doc.', 154)\n",
      "1.5\n",
      "('Find answer for doc.', 155)\n",
      "104.5\n",
      "('Find answer for doc.', 156)\n",
      "23.0\n",
      "('Find answer for doc.', 157)\n",
      "283.0\n",
      "('Find answer for doc.', 158)\n",
      "9.5\n",
      "('Find answer for doc.', 159)\n",
      "246.0\n",
      "('Find answer for doc.', 160)\n",
      "25.5\n",
      "('Find answer for doc.', 161)\n",
      "25.0\n",
      "('Find answer for doc.', 162)\n",
      "2.0\n",
      "('Find answer for doc.', 163)\n",
      "6.0\n",
      "('Find answer for doc.', 164)\n",
      "4.0\n",
      "('Find answer for doc.', 165)\n",
      "13.0\n",
      "('Find answer for doc.', 166)\n",
      "106.0\n",
      "('Find answer for doc.', 167)\n",
      "273.5\n",
      "('Find answer for doc.', 168)\n",
      "77.5\n",
      "('Find answer for doc.', 169)\n",
      "14.5\n",
      "('Find answer for doc.', 170)\n",
      "25.0\n",
      "('Find answer for doc.', 171)\n",
      "32.0\n",
      "('Find answer for doc.', 172)\n",
      "58.5\n",
      "('Find answer for doc.', 173)\n",
      "10.0\n",
      "('Find answer for doc.', 174)\n",
      "17.0\n",
      "('Find answer for doc.', 175)\n",
      "3.0\n",
      "('Find answer for doc.', 176)\n",
      "17.0\n",
      "('Find answer for doc.', 177)\n",
      "7.0\n",
      "('Find answer for doc.', 178)\n",
      "47.5\n",
      "('Find answer for doc.', 179)\n",
      "20.0\n",
      "('Find answer for doc.', 180)\n",
      "1.5\n",
      "('Find answer for doc.', 181)\n",
      "25.0\n",
      "('Find answer for doc.', 182)\n",
      "5.0\n",
      "('Find answer for doc.', 183)\n",
      "33.0\n",
      "('Find answer for doc.', 184)\n",
      "139.0\n",
      "('Find answer for doc.', 185)\n",
      "3.0\n",
      "('Find answer for doc.', 186)\n",
      "35.0\n",
      "('Find answer for doc.', 187)\n",
      "2.0\n",
      "('Find answer for doc.', 188)\n",
      "54.0\n",
      "('Find answer for doc.', 189)\n",
      "67.5\n",
      "('Find answer for doc.', 190)\n",
      "25.5\n",
      "('Find answer for doc.', 191)\n",
      "17.0\n",
      "('Find answer for doc.', 192)\n",
      "23.0\n",
      "('Find answer for doc.', 193)\n",
      "317.0\n",
      "('Find answer for doc.', 194)\n",
      "111.0\n",
      "('Find answer for doc.', 195)\n",
      "3.0\n",
      "('Find answer for doc.', 196)\n",
      "18.5\n",
      "('Find answer for doc.', 197)\n",
      "251.0\n",
      "('Find answer for doc.', 198)\n",
      "91.5\n",
      "('Find answer for doc.', 199)\n",
      "12.5\n",
      "('Find answer for doc.', 200)\n",
      "242.0\n",
      "('Find answer for doc.', 201)\n",
      "6.0\n",
      "('Find answer for doc.', 202)\n",
      "46.0\n",
      "('Find answer for doc.', 203)\n",
      "14.5\n",
      "('Find answer for doc.', 204)\n",
      "14.0\n",
      "('Find answer for doc.', 205)\n",
      "16.5\n",
      "('Find answer for doc.', 206)\n",
      "5.0\n",
      "('Find answer for doc.', 207)\n",
      "47.0\n",
      "('Find answer for doc.', 208)\n",
      "24.0\n",
      "('Find answer for doc.', 209)\n",
      "123.0\n",
      "('Find answer for doc.', 210)\n",
      "104.5\n",
      "('Find answer for doc.', 211)\n",
      "59.0\n",
      "('Find answer for doc.', 212)\n",
      "289.0\n",
      "('Find answer for doc.', 213)\n",
      "4.0\n",
      "('Find answer for doc.', 214)\n",
      "37.0\n",
      "('Find answer for doc.', 215)\n",
      "146.0\n",
      "('Find answer for doc.', 216)\n",
      "279.0\n",
      "('Find answer for doc.', 217)\n",
      "301.5\n",
      "('Find answer for doc.', 218)\n",
      "91.5\n",
      "('Find answer for doc.', 219)\n",
      "22.0\n",
      "('Find answer for doc.', 220)\n",
      "1.0\n",
      "('Find answer for doc.', 221)\n",
      "54.0\n",
      "('Find answer for doc.', 222)\n",
      "249.0\n",
      "('Find answer for doc.', 223)\n",
      "29.0\n",
      "('Find answer for doc.', 224)\n",
      "3.0\n",
      "('Find answer for doc.', 225)\n",
      "91.5\n",
      "('Find answer for doc.', 226)\n",
      "4.0\n",
      "('Find answer for doc.', 227)\n",
      "39.0\n",
      "('Find answer for doc.', 228)\n",
      "79.0\n",
      "('Find answer for doc.', 229)\n",
      "23.0\n",
      "('Find answer for doc.', 230)\n",
      "8.0\n",
      "('Find answer for doc.', 231)\n",
      "134.0\n",
      "('Find answer for doc.', 232)\n",
      "21.0\n",
      "('Find answer for doc.', 233)\n",
      "17.0\n",
      "('Find answer for doc.', 234)\n",
      "444.0\n",
      "('Find answer for doc.', 235)\n",
      "20.0\n",
      "('Find answer for doc.', 236)\n",
      "101.5\n",
      "('Find answer for doc.', 237)\n",
      "7.5\n",
      "('Find answer for doc.', 238)\n",
      "3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Find answer for doc.', 239)\n",
      "214.0\n",
      "('Find answer for doc.', 240)\n",
      "30.0\n",
      "('Find answer for doc.', 241)\n",
      "36.0\n",
      "('Find answer for doc.', 242)\n",
      "25.0\n",
      "('Find answer for doc.', 243)\n",
      "108.5\n",
      "('Find answer for doc.', 244)\n",
      "8.0\n",
      "('Find answer for doc.', 245)\n",
      "14.5\n",
      "('Find answer for doc.', 246)\n",
      "242.0\n",
      "('Find answer for doc.', 247)\n",
      "10.5\n",
      "('Find answer for doc.', 248)\n",
      "5.5\n",
      "('Find answer for doc.', 249)\n",
      "49.0\n",
      "('Find answer for doc.', 250)\n",
      "82.0\n",
      "('Find answer for doc.', 251)\n",
      "14.0\n",
      "('Find answer for doc.', 252)\n",
      "56.0\n",
      "('Find answer for doc.', 253)\n",
      "108.5\n",
      "('Find answer for doc.', 254)\n",
      "25.0\n",
      "('Find answer for doc.', 255)\n",
      "172.0\n",
      "('Find answer for doc.', 256)\n",
      "16.0\n",
      "('Find answer for doc.', 257)\n",
      "85.5\n",
      "('Find answer for doc.', 258)\n",
      "3.0\n",
      "('Find answer for doc.', 259)\n",
      "15.5\n",
      "('Find answer for doc.', 260)\n",
      "8.0\n",
      "('Find answer for doc.', 261)\n",
      "213.0\n",
      "('Find answer for doc.', 262)\n",
      "20.0\n",
      "('Find answer for doc.', 263)\n",
      "22.0\n",
      "('Find answer for doc.', 264)\n",
      "10.5\n",
      "('Find answer for doc.', 265)\n",
      "242.0\n",
      "('Find answer for doc.', 266)\n",
      "159.0\n",
      "('Find answer for doc.', 267)\n",
      "49.5\n",
      "('Find answer for doc.', 268)\n",
      "94.0\n",
      "('Find answer for doc.', 269)\n",
      "5.0\n",
      "('Find answer for doc.', 270)\n",
      "81.0\n",
      "('Find answer for doc.', 271)\n",
      "9.0\n",
      "('Find answer for doc.', 272)\n",
      "273.5\n",
      "('Find answer for doc.', 273)\n",
      "2.0\n",
      "('Find answer for doc.', 274)\n",
      "49.5\n",
      "('Find answer for doc.', 275)\n",
      "89.0\n",
      "('Find answer for doc.', 276)\n",
      "20.5\n",
      "('Find answer for doc.', 277)\n",
      "2.0\n",
      "('Find answer for doc.', 278)\n",
      "10.5\n",
      "('Find answer for doc.', 279)\n",
      "165.0\n",
      "('Find answer for doc.', 280)\n",
      "38.0\n",
      "('Find answer for doc.', 281)\n",
      "111.0\n",
      "('Find answer for doc.', 282)\n",
      "62.5\n",
      "('Find answer for doc.', 283)\n",
      "14.5\n",
      "('Find answer for doc.', 284)\n",
      "91.5\n",
      "('Find answer for doc.', 285)\n",
      "46.5\n",
      "('Find answer for doc.', 286)\n",
      "7.5\n",
      "('Find answer for doc.', 287)\n",
      "3.0\n",
      "('Find answer for doc.', 288)\n",
      "111.0\n",
      "('Find answer for doc.', 289)\n",
      "12.0\n",
      "('Find answer for doc.', 290)\n",
      "1.0\n",
      "('Find answer for doc.', 291)\n",
      "25.5\n",
      "('Find answer for doc.', 292)\n",
      "7.0\n",
      "('Find answer for doc.', 293)\n",
      "397.0\n",
      "('Find answer for doc.', 294)\n",
      "16.0\n",
      "('Find answer for doc.', 295)\n",
      "14.0\n",
      "('Find answer for doc.', 296)\n",
      "1.0\n",
      "('Find answer for doc.', 297)\n",
      "4.5\n",
      "('Find answer for doc.', 298)\n",
      "3.0\n",
      "('Find answer for doc.', 299)\n",
      "28.5\n",
      "('Find answer for doc.', 300)\n",
      "14.0\n",
      "('Find answer for doc.', 301)\n",
      "7.5\n",
      "('Find answer for doc.', 302)\n",
      "11.0\n",
      "('Find answer for doc.', 303)\n",
      "137.0\n",
      "('Find answer for doc.', 304)\n",
      "60.0\n",
      "('Find answer for doc.', 305)\n",
      "5.5\n",
      "('Find answer for doc.', 306)\n",
      "29.0\n",
      "('Find answer for doc.', 307)\n",
      "20.0\n",
      "('Find answer for doc.', 308)\n",
      "12.0\n",
      "('Find answer for doc.', 309)\n",
      "23.0\n",
      "('Find answer for doc.', 310)\n",
      "53.0\n",
      "('Find answer for doc.', 311)\n",
      "23.5\n",
      "('Find answer for doc.', 312)\n",
      "91.5\n",
      "('Find answer for doc.', 313)\n",
      "9.0\n",
      "('Find answer for doc.', 314)\n",
      "88.0\n",
      "('Find answer for doc.', 315)\n",
      "25.0\n",
      "('Find answer for doc.', 316)\n",
      "77.0\n",
      "('Find answer for doc.', 317)\n",
      "25.0\n",
      "('Find answer for doc.', 318)\n",
      "2.0\n",
      "('Find answer for doc.', 319)\n",
      "51.0\n",
      "('Find answer for doc.', 320)\n",
      "75.0\n",
      "('Find answer for doc.', 321)\n",
      "40.0\n",
      "('Find answer for doc.', 322)\n",
      "48.0\n",
      "('Find answer for doc.', 323)\n",
      "23.5\n",
      "('Find answer for doc.', 324)\n",
      "11.0\n",
      "('Find answer for doc.', 325)\n",
      "5.5\n",
      "('Find answer for doc.', 326)\n",
      "23.0\n",
      "('Find answer for doc.', 327)\n",
      "9.0\n",
      "('Find answer for doc.', 328)\n",
      "3.5\n",
      "('Find answer for doc.', 329)\n",
      "91.5\n",
      "('Find answer for doc.', 330)\n",
      "5.0\n",
      "('Find answer for doc.', 331)\n",
      "5.5\n",
      "('Find answer for doc.', 332)\n",
      "87.0\n",
      "('Find answer for doc.', 333)\n",
      "10.5\n",
      "('Find answer for doc.', 334)\n",
      "15.0\n",
      "('Find answer for doc.', 335)\n",
      "20.0\n",
      "('Find answer for doc.', 336)\n",
      "12.5\n",
      "('Find answer for doc.', 337)\n",
      "39.0\n",
      "('Find answer for doc.', 338)\n",
      "14.0\n",
      "('Find answer for doc.', 339)\n",
      "22.0\n",
      "('Find answer for doc.', 340)\n",
      "1.0\n",
      "('Find answer for doc.', 341)\n",
      "50.5\n",
      "('Find answer for doc.', 342)\n",
      "28.5\n",
      "('Find answer for doc.', 343)\n",
      "301.5\n",
      "('Find answer for doc.', 344)\n",
      "21.5\n",
      "('Find answer for doc.', 345)\n",
      "105.5\n",
      "('Find answer for doc.', 346)\n",
      "43.0\n",
      "('Find answer for doc.', 347)\n",
      "7.0\n",
      "('Find answer for doc.', 348)\n",
      "111.0\n",
      "('Find answer for doc.', 349)\n",
      "17.0\n",
      "('Find answer for doc.', 350)\n",
      "33.0\n",
      "('Find answer for doc.', 351)\n",
      "41.0\n",
      "('Find answer for doc.', 352)\n",
      "56.5\n",
      "('Find answer for doc.', 353)\n",
      "7.0\n",
      "('Find answer for doc.', 354)\n",
      "12.0\n",
      "('Find answer for doc.', 355)\n",
      "92.0\n",
      "('Find answer for doc.', 356)\n",
      "5.0\n",
      "('Find answer for doc.', 357)\n",
      "39.0\n",
      "('Find answer for doc.', 358)\n",
      "16.0\n",
      "('Find answer for doc.', 359)\n",
      "1.5\n",
      "('Find answer for doc.', 360)\n",
      "93.0\n",
      "('Find answer for doc.', 361)\n",
      "342.5\n",
      "('Find answer for doc.', 362)\n",
      "8.5\n",
      "('Find answer for doc.', 363)\n",
      "156.0\n",
      "('Find answer for doc.', 364)\n",
      "14.0\n",
      "('Find answer for doc.', 365)\n",
      "21.5\n",
      "('Find answer for doc.', 366)\n",
      "19.0\n",
      "('Find answer for doc.', 367)\n",
      "70.0\n",
      "('Find answer for doc.', 368)\n",
      "35.5\n",
      "('Find answer for doc.', 369)\n",
      "55.5\n",
      "('Find answer for doc.', 370)\n",
      "19.0\n",
      "('Find answer for doc.', 371)\n",
      "12.0\n",
      "('Find answer for doc.', 372)\n",
      "55.0\n",
      "('Find answer for doc.', 373)\n",
      "37.5\n",
      "('Find answer for doc.', 374)\n",
      "185.0\n",
      "('Find answer for doc.', 375)\n",
      "20.0\n",
      "('Find answer for doc.', 376)\n",
      "27.0\n",
      "('Find answer for doc.', 377)\n",
      "31.0\n",
      "('Find answer for doc.', 378)\n",
      "21.5\n",
      "('Find answer for doc.', 379)\n",
      "231.0\n",
      "('Find answer for doc.', 380)\n",
      "6.0\n",
      "('Find answer for doc.', 381)\n",
      "118.0\n",
      "('Find answer for doc.', 382)\n",
      "2.0\n",
      "('Find answer for doc.', 383)\n",
      "28.0\n",
      "('Find answer for doc.', 384)\n",
      "1.0\n",
      "('Find answer for doc.', 385)\n",
      "21.0\n",
      "('Find answer for doc.', 386)\n",
      "155.5\n",
      "('Find answer for doc.', 387)\n",
      "7.0\n",
      "('Find answer for doc.', 388)\n",
      "12.0\n",
      "('Find answer for doc.', 389)\n",
      "44.0\n",
      "('Find answer for doc.', 390)\n",
      "9.0\n",
      "('Find answer for doc.', 391)\n",
      "35.0\n",
      "('Find answer for doc.', 392)\n",
      "7.0\n",
      "('Find answer for doc.', 393)\n",
      "23.0\n",
      "('Find answer for doc.', 394)\n",
      "43.5\n",
      "('Find answer for doc.', 395)\n",
      "24.0\n",
      "('Find answer for doc.', 396)\n",
      "242.5\n",
      "('Find answer for doc.', 397)\n",
      "2.0\n",
      "('Find answer for doc.', 398)\n",
      "63.0\n",
      "('Find answer for doc.', 399)\n",
      "12.0\n",
      "('Find answer for doc.', 400)\n",
      "3.0\n",
      "('Find answer for doc.', 401)\n",
      "7.0\n",
      "('Find answer for doc.', 402)\n",
      "16.0\n",
      "('Find answer for doc.', 403)\n",
      "37.5\n",
      "('Find answer for doc.', 404)\n",
      "5.5\n",
      "('Find answer for doc.', 405)\n",
      "4.5\n",
      "('Find answer for doc.', 406)\n",
      "13.0\n",
      "('Find answer for doc.', 407)\n",
      "10.5\n",
      "('Find answer for doc.', 408)\n",
      "17.5\n",
      "('Find answer for doc.', 409)\n",
      "70.5\n",
      "('Find answer for doc.', 410)\n",
      "24.0\n",
      "('Find answer for doc.', 411)\n",
      "20.0\n",
      "('Find answer for doc.', 412)\n",
      "15.5\n",
      "('Find answer for doc.', 413)\n",
      "2.0\n",
      "('Find answer for doc.', 414)\n",
      "23.0\n",
      "('Find answer for doc.', 415)\n",
      "21.5\n",
      "('Find answer for doc.', 416)\n",
      "6.0\n",
      "('Find answer for doc.', 417)\n",
      "45.5\n",
      "('Find answer for doc.', 418)\n",
      "20.0\n",
      "('Find answer for doc.', 419)\n",
      "45.5\n",
      "('Find answer for doc.', 420)\n",
      "17.5\n",
      "('Find answer for doc.', 421)\n",
      "105.0\n",
      "('Find answer for doc.', 422)\n",
      "4.0\n",
      "('Find answer for doc.', 423)\n",
      "8.0\n",
      "('Find answer for doc.', 424)\n",
      "335.5\n",
      "('Find answer for doc.', 425)\n",
      "5.0\n",
      "('Find answer for doc.', 426)\n",
      "41.0\n",
      "('Find answer for doc.', 427)\n",
      "40.5\n",
      "('Find answer for doc.', 428)\n",
      "24.5\n",
      "('Find answer for doc.', 429)\n",
      "35.5\n",
      "('Find answer for doc.', 430)\n",
      "39.5\n",
      "('Find answer for doc.', 431)\n",
      "11.0\n",
      "('Find answer for doc.', 432)\n",
      "2.0\n",
      "('Find answer for doc.', 433)\n",
      "4.5\n",
      "('Find answer for doc.', 434)\n",
      "37.0\n",
      "('Find answer for doc.', 435)\n",
      "12.0\n",
      "('Find answer for doc.', 436)\n",
      "9.0\n",
      "('Find answer for doc.', 437)\n",
      "104.0\n",
      "('Find answer for doc.', 438)\n",
      "41.5\n",
      "('Find answer for doc.', 439)\n",
      "13.0\n",
      "('Find answer for doc.', 440)\n",
      "35.0\n",
      "('Find answer for doc.', 441)\n",
      "55.0\n",
      "('Find answer for doc.', 442)\n",
      "54.5\n",
      "('Find answer for doc.', 443)\n",
      "19.0\n",
      "('Find answer for doc.', 444)\n",
      "26.0\n",
      "('Find answer for doc.', 445)\n",
      "19.5\n",
      "('Find answer for doc.', 446)\n",
      "8.5\n",
      "('Find answer for doc.', 447)\n",
      "5.0\n",
      "('Find answer for doc.', 448)\n",
      "17.0\n",
      "('Find answer for doc.', 449)\n",
      "10.0\n",
      "('Find answer for doc.', 450)\n",
      "19.0\n",
      "('Find answer for doc.', 451)\n",
      "67.0\n",
      "('Find answer for doc.', 452)\n",
      "147.0\n",
      "('Find answer for doc.', 453)\n",
      "72.5\n",
      "('Find answer for doc.', 454)\n",
      "8.0\n",
      "('Find answer for doc.', 455)\n",
      "2.0\n",
      "('Find answer for doc.', 456)\n",
      "23.0\n",
      "('Find answer for doc.', 457)\n",
      "1.5\n",
      "('Find answer for doc.', 458)\n",
      "28.0\n",
      "('Find answer for doc.', 459)\n",
      "17.0\n",
      "('Find answer for doc.', 460)\n",
      "7.0\n",
      "('Find answer for doc.', 461)\n",
      "46.0\n",
      "('Find answer for doc.', 462)\n",
      "52.0\n",
      "('Find answer for doc.', 463)\n",
      "24.0\n",
      "('Find answer for doc.', 464)\n",
      "3.0\n",
      "('Find answer for doc.', 465)\n",
      "19.5\n",
      "('Find answer for doc.', 466)\n",
      "12.0\n",
      "('Find answer for doc.', 467)\n",
      "32.0\n",
      "('Find answer for doc.', 468)\n",
      "238.5\n",
      "('Find answer for doc.', 469)\n",
      "8.5\n",
      "('Find answer for doc.', 470)\n",
      "18.0\n",
      "('Find answer for doc.', 471)\n",
      "32.0\n",
      "('Find answer for doc.', 472)\n",
      "34.0\n",
      "('Find answer for doc.', 473)\n",
      "2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Find answer for doc.', 474)\n",
      "22.0\n",
      "('Find answer for doc.', 475)\n",
      "55.0\n",
      "('Find answer for doc.', 476)\n",
      "7.0\n",
      "('Find answer for doc.', 477)\n",
      "12.0\n",
      "('Find answer for doc.', 478)\n",
      "92.0\n",
      "('Find answer for doc.', 479)\n",
      "1.0\n",
      "('Find answer for doc.', 480)\n",
      "12.0\n",
      "('Find answer for doc.', 481)\n",
      "104.5\n",
      "('Find answer for doc.', 482)\n",
      "12.0\n",
      "('Find answer for doc.', 483)\n",
      "18.0\n",
      "('Find answer for doc.', 484)\n",
      "3.0\n",
      "('Find answer for doc.', 485)\n",
      "23.5\n",
      "('Find answer for doc.', 486)\n",
      "11.0\n",
      "('Find answer for doc.', 487)\n",
      "46.0\n",
      "('Find answer for doc.', 488)\n",
      "5.5\n",
      "('Find answer for doc.', 489)\n",
      "32.0\n",
      "('Find answer for doc.', 490)\n",
      "8.0\n",
      "('Find answer for doc.', 491)\n",
      "156.5\n",
      "('Find answer for doc.', 492)\n",
      "14.0\n",
      "('Find answer for doc.', 493)\n",
      "70.5\n",
      "('Find answer for doc.', 494)\n",
      "10.5\n",
      "('Find answer for doc.', 495)\n",
      "37.0\n",
      "('Find answer for doc.', 496)\n",
      "5.5\n",
      "('Find answer for doc.', 497)\n",
      "25.5\n",
      "('Find answer for doc.', 498)\n",
      "4.0\n",
      "('Find answer for doc.', 499)\n",
      "7.0\n",
      "('Find answer for doc.', 500)\n",
      "49.5\n",
      "('Find answer for doc.', 501)\n",
      "8.5\n",
      "('Find answer for doc.', 502)\n",
      "69.0\n",
      "('Find answer for doc.', 503)\n",
      "1.0\n",
      "('Find answer for doc.', 504)\n",
      "13.0\n",
      "('Find answer for doc.', 505)\n",
      "26.0\n",
      "('Find answer for doc.', 506)\n",
      "2.0\n",
      "('Find answer for doc.', 507)\n",
      "1.0\n",
      "('Find answer for doc.', 508)\n",
      "6.5\n",
      "('Find answer for doc.', 509)\n",
      "13.0\n",
      "('Find answer for doc.', 510)\n",
      "14.0\n",
      "('Find answer for doc.', 511)\n",
      "30.0\n",
      "('Find answer for doc.', 512)\n",
      "18.0\n",
      "('Find answer for doc.', 513)\n",
      "5.5\n",
      "('Find answer for doc.', 514)\n",
      "8.0\n",
      "('Find answer for doc.', 515)\n",
      "17.5\n",
      "('Find answer for doc.', 516)\n",
      "43.5\n",
      "('Find answer for doc.', 517)\n",
      "60.0\n",
      "('Find answer for doc.', 518)\n",
      "136.0\n",
      "('Find answer for doc.', 519)\n",
      "2.0\n",
      "('Find answer for doc.', 520)\n",
      "99.0\n",
      "('Find answer for doc.', 521)\n",
      "2.0\n",
      "('Find answer for doc.', 522)\n",
      "59.5\n",
      "('Find answer for doc.', 523)\n",
      "32.5\n",
      "('Find answer for doc.', 524)\n",
      "144.0\n",
      "('Find answer for doc.', 525)\n",
      "25.0\n",
      "('Find answer for doc.', 526)\n",
      "14.0\n",
      "('Find answer for doc.', 527)\n",
      "16.0\n",
      "('Find answer for doc.', 528)\n",
      "19.0\n",
      "('Find answer for doc.', 529)\n",
      "150.0\n",
      "('Find answer for doc.', 530)\n",
      "23.5\n",
      "('Find answer for doc.', 531)\n",
      "52.0\n",
      "('Find answer for doc.', 532)\n",
      "2.0\n",
      "('Find answer for doc.', 533)\n",
      "21.0\n",
      "('Find answer for doc.', 534)\n",
      "6.0\n",
      "('Find answer for doc.', 535)\n",
      "7.0\n",
      "('Find answer for doc.', 536)\n",
      "56.5\n",
      "('Find answer for doc.', 537)\n",
      "35.0\n",
      "('Find answer for doc.', 538)\n",
      "41.5\n",
      "('Find answer for doc.', 539)\n",
      "31.0\n",
      "('Find answer for doc.', 540)\n",
      "13.0\n",
      "('Find answer for doc.', 541)\n",
      "69.5\n",
      "('Find answer for doc.', 542)\n",
      "196.5\n",
      "('Find answer for doc.', 543)\n",
      "81.0\n",
      "('Find answer for doc.', 544)\n",
      "35.0\n",
      "('Find answer for doc.', 545)\n",
      "5.0\n",
      "('Find answer for doc.', 546)\n",
      "42.0\n",
      "('Find answer for doc.', 547)\n",
      "21.5\n",
      "('Find answer for doc.', 548)\n",
      "37.5\n",
      "('Find answer for doc.', 549)\n",
      "36.0\n",
      "('Find answer for doc.', 550)\n",
      "30.0\n",
      "('Find answer for doc.', 551)\n",
      "18.0\n",
      "('Find answer for doc.', 552)\n",
      "70.0\n",
      "('Find answer for doc.', 553)\n",
      "31.5\n",
      "('Find answer for doc.', 554)\n",
      "1.5\n",
      "('Find answer for doc.', 555)\n",
      "1.0\n",
      "('Find answer for doc.', 556)\n",
      "1.5\n",
      "('Find answer for doc.', 557)\n",
      "15.0\n",
      "('Find answer for doc.', 558)\n",
      "108.0\n",
      "('Find answer for doc.', 559)\n",
      "196.5\n",
      "('Find answer for doc.', 560)\n",
      "36.0\n",
      "('Find answer for doc.', 561)\n",
      "10.0\n",
      "('Find answer for doc.', 562)\n",
      "1.5\n",
      "('Find answer for doc.', 563)\n",
      "9.0\n",
      "('Find answer for doc.', 564)\n",
      "24.5\n",
      "('Find answer for doc.', 565)\n",
      "83.0\n",
      "('Find answer for doc.', 566)\n",
      "83.0\n",
      "('Find answer for doc.', 567)\n",
      "9.0\n",
      "('Find answer for doc.', 568)\n",
      "16.0\n",
      "('Find answer for doc.', 569)\n",
      "8.0\n",
      "('Find answer for doc.', 570)\n",
      "25.5\n",
      "('Find answer for doc.', 571)\n",
      "9.0\n",
      "('Find answer for doc.', 572)\n",
      "4.0\n",
      "('Find answer for doc.', 573)\n",
      "58.0\n",
      "('Find answer for doc.', 574)\n",
      "17.5\n",
      "('Find answer for doc.', 575)\n",
      "59.0\n",
      "('Find answer for doc.', 576)\n",
      "40.5\n",
      "('Find answer for doc.', 577)\n",
      "9.0\n",
      "('Find answer for doc.', 578)\n",
      "23.0\n",
      "('Find answer for doc.', 579)\n",
      "34.0\n",
      "('Find answer for doc.', 580)\n",
      "5.0\n",
      "('Find answer for doc.', 581)\n",
      "19.0\n",
      "('Find answer for doc.', 582)\n",
      "28.0\n",
      "('Find answer for doc.', 583)\n",
      "2.0\n",
      "('Find answer for doc.', 584)\n",
      "49.0\n",
      "('Find answer for doc.', 585)\n",
      "1.5\n",
      "('Find answer for doc.', 586)\n",
      "17.0\n",
      "('Find answer for doc.', 587)\n",
      "32.0\n",
      "('Find answer for doc.', 588)\n",
      "327.0\n",
      "('Find answer for doc.', 589)\n",
      "17.0\n",
      "('Find answer for doc.', 590)\n",
      "4.0\n",
      "('Find answer for doc.', 591)\n",
      "514.5\n",
      "('Find answer for doc.', 592)\n",
      "16.0\n",
      "('Find answer for doc.', 593)\n",
      "502.5\n",
      "('Find answer for doc.', 594)\n",
      "61.5\n",
      "('Find answer for doc.', 595)\n",
      "85.0\n",
      "('Find answer for doc.', 596)\n",
      "3.0\n",
      "('Find answer for doc.', 597)\n",
      "28.5\n",
      "('Find answer for doc.', 598)\n",
      "2.0\n",
      "('Find answer for doc.', 599)\n",
      "23.5\n",
      "('Find answer for doc.', 600)\n",
      "28.5\n",
      "('Find answer for doc.', 601)\n",
      "50.0\n",
      "('Find answer for doc.', 602)\n",
      "6.0\n",
      "('Find answer for doc.', 603)\n",
      "19.0\n",
      "('Find answer for doc.', 604)\n",
      "19.0\n",
      "('Find answer for doc.', 605)\n",
      "75.5\n",
      "('Find answer for doc.', 606)\n",
      "14.0\n",
      "('Find answer for doc.', 607)\n",
      "37.0\n",
      "('Find answer for doc.', 608)\n",
      "29.0\n",
      "('Find answer for doc.', 609)\n",
      "37.0\n",
      "('Find answer for doc.', 610)\n",
      "18.0\n",
      "('Find answer for doc.', 611)\n",
      "57.0\n",
      "('Find answer for doc.', 612)\n",
      "12.0\n",
      "('Find answer for doc.', 613)\n",
      "28.5\n",
      "('Find answer for doc.', 614)\n",
      "60.5\n",
      "('Find answer for doc.', 615)\n",
      "3.0\n",
      "('Find answer for doc.', 616)\n",
      "91.0\n",
      "('Find answer for doc.', 617)\n",
      "27.5\n",
      "('Find answer for doc.', 618)\n",
      "23.0\n",
      "('Find answer for doc.', 619)\n",
      "2.0\n",
      "('Find answer for doc.', 620)\n",
      "6.0\n",
      "('Find answer for doc.', 621)\n",
      "55.0\n",
      "('Find answer for doc.', 622)\n",
      "85.0\n",
      "('Find answer for doc.', 623)\n",
      "4.0\n",
      "('Find answer for doc.', 624)\n",
      "12.0\n",
      "('Find answer for doc.', 625)\n",
      "70.0\n",
      "('Find answer for doc.', 626)\n",
      "1.5\n",
      "('Find answer for doc.', 627)\n",
      "13.5\n",
      "('Find answer for doc.', 628)\n",
      "8.5\n",
      "('Find answer for doc.', 629)\n",
      "27.0\n",
      "('Find answer for doc.', 630)\n",
      "137.0\n",
      "('Find answer for doc.', 631)\n",
      "148.0\n",
      "('Find answer for doc.', 632)\n",
      "45.5\n",
      "('Find answer for doc.', 633)\n",
      "5.5\n",
      "('Find answer for doc.', 634)\n",
      "11.0\n",
      "('Find answer for doc.', 635)\n",
      "47.0\n",
      "('Find answer for doc.', 636)\n",
      "235.0\n",
      "('Find answer for doc.', 637)\n",
      "30.5\n",
      "('Find answer for doc.', 638)\n",
      "1.0\n",
      "('Find answer for doc.', 639)\n",
      "2.0\n",
      "('Find answer for doc.', 640)\n",
      "3.0\n",
      "('Find answer for doc.', 641)\n",
      "32.0\n",
      "('Find answer for doc.', 642)\n",
      "1.0\n",
      "('Find answer for doc.', 643)\n",
      "84.5\n",
      "('Find answer for doc.', 644)\n",
      "93.0\n",
      "('Find answer for doc.', 645)\n",
      "39.5\n",
      "('Find answer for doc.', 646)\n",
      "30.0\n",
      "('Find answer for doc.', 647)\n",
      "21.5\n",
      "('Find answer for doc.', 648)\n",
      "27.0\n",
      "('Find answer for doc.', 649)\n",
      "29.5\n",
      "('Find answer for doc.', 650)\n",
      "12.0\n",
      "('Find answer for doc.', 651)\n",
      "5.5\n",
      "('Find answer for doc.', 652)\n",
      "15.0\n",
      "('Find answer for doc.', 653)\n",
      "85.5\n",
      "('Find answer for doc.', 654)\n",
      "52.0\n",
      "('Find answer for doc.', 655)\n",
      "9.5\n",
      "('Find answer for doc.', 656)\n",
      "35.0\n",
      "('Find answer for doc.', 657)\n",
      "14.0\n",
      "('Find answer for doc.', 658)\n",
      "3.0\n",
      "('Find answer for doc.', 659)\n",
      "7.0\n",
      "('Find answer for doc.', 660)\n",
      "153.0\n",
      "('Find answer for doc.', 661)\n",
      "22.0\n",
      "('Find answer for doc.', 662)\n",
      "73.0\n",
      "('Find answer for doc.', 663)\n",
      "77.5\n",
      "('Find answer for doc.', 664)\n",
      "32.0\n",
      "('Find answer for doc.', 665)\n",
      "88.0\n",
      "('Find answer for doc.', 666)\n",
      "211.5\n",
      "('Find answer for doc.', 667)\n",
      "50.5\n",
      "('Find answer for doc.', 668)\n",
      "117.0\n",
      "('Find answer for doc.', 669)\n",
      "1.0\n",
      "('Find answer for doc.', 670)\n",
      "84.0\n",
      "('Find answer for doc.', 671)\n",
      "4.0\n",
      "('Find answer for doc.', 672)\n",
      "1.0\n",
      "('Find answer for doc.', 673)\n",
      "197.0\n",
      "('Find answer for doc.', 674)\n",
      "2.0\n",
      "('Find answer for doc.', 675)\n",
      "14.0\n",
      "('Find answer for doc.', 676)\n",
      "11.0\n",
      "('Find answer for doc.', 677)\n",
      "69.5\n",
      "('Find answer for doc.', 678)\n",
      "21.5\n",
      "('Find answer for doc.', 679)\n",
      "44.0\n",
      "('Find answer for doc.', 680)\n",
      "13.5\n",
      "('Find answer for doc.', 681)\n",
      "106.0\n",
      "('Find answer for doc.', 682)\n",
      "5.0\n",
      "('Find answer for doc.', 683)\n",
      "31.0\n",
      "('Find answer for doc.', 684)\n",
      "34.0\n",
      "('Find answer for doc.', 685)\n",
      "41.0\n",
      "('Find answer for doc.', 686)\n",
      "54.5\n",
      "('Find answer for doc.', 687)\n",
      "36.5\n",
      "('Find answer for doc.', 688)\n",
      "21.5\n",
      "('Find answer for doc.', 689)\n",
      "46.0\n",
      "('Find answer for doc.', 690)\n",
      "35.0\n",
      "('Find answer for doc.', 691)\n",
      "11.0\n",
      "('Find answer for doc.', 692)\n",
      "7.0\n",
      "('Find answer for doc.', 693)\n",
      "10.5\n",
      "('Find answer for doc.', 694)\n",
      "111.5\n",
      "('Find answer for doc.', 695)\n",
      "9.5\n",
      "('Find answer for doc.', 696)\n",
      "9.0\n",
      "('Find answer for doc.', 697)\n",
      "72.0\n",
      "('Find answer for doc.', 698)\n",
      "52.5\n",
      "('Find answer for doc.', 699)\n",
      "20.0\n",
      "('Find answer for doc.', 700)\n",
      "223.5\n",
      "('Find answer for doc.', 701)\n",
      "15.0\n",
      "('Find answer for doc.', 702)\n",
      "15.0\n",
      "('Find answer for doc.', 703)\n",
      "83.5\n",
      "('Find answer for doc.', 704)\n",
      "77.5\n",
      "('Find answer for doc.', 705)\n",
      "6.0\n",
      "('Find answer for doc.', 706)\n",
      "88.0\n",
      "('Find answer for doc.', 707)\n",
      "27.0\n",
      "('Find answer for doc.', 708)\n",
      "16.5\n",
      "('Find answer for doc.', 709)\n",
      "37.5\n",
      "('Find answer for doc.', 710)\n",
      "73.0\n",
      "('Find answer for doc.', 711)\n",
      "11.0\n",
      "('Find answer for doc.', 712)\n",
      "1.5\n",
      "('Find answer for doc.', 713)\n",
      "39.5\n",
      "('Find answer for doc.', 714)\n",
      "83.5\n",
      "('Find answer for doc.', 715)\n",
      "8.0\n",
      "('Find answer for doc.', 716)\n",
      "36.0\n",
      "('Find answer for doc.', 717)\n",
      "37.0\n",
      "('Find answer for doc.', 718)\n",
      "5.0\n",
      "('Find answer for doc.', 719)\n",
      "76.5\n",
      "('Find answer for doc.', 720)\n",
      "28.5\n",
      "('Find answer for doc.', 721)\n",
      "17.0\n",
      "('Find answer for doc.', 722)\n",
      "17.0\n",
      "('Find answer for doc.', 723)\n",
      "11.0\n",
      "('Find answer for doc.', 724)\n",
      "35.0\n",
      "('Find answer for doc.', 725)\n",
      "85.5\n",
      "('Find answer for doc.', 726)\n",
      "65.5\n",
      "('Find answer for doc.', 727)\n",
      "59.0\n",
      "('Find answer for doc.', 728)\n",
      "44.0\n",
      "('Find answer for doc.', 729)\n",
      "47.0\n",
      "('Find answer for doc.', 730)\n",
      "3.0\n",
      "('Find answer for doc.', 731)\n",
      "30.0\n",
      "('Find answer for doc.', 732)\n",
      "15.5\n",
      "('Find answer for doc.', 733)\n",
      "6.5\n",
      "('Find answer for doc.', 734)\n",
      "8.0\n",
      "('Find answer for doc.', 735)\n",
      "32.0\n",
      "('Find answer for doc.', 736)\n",
      "10.0\n",
      "('Find answer for doc.', 737)\n",
      "103.0\n",
      "('Find answer for doc.', 738)\n",
      "9.0\n",
      "('Find answer for doc.', 739)\n",
      "12.5\n",
      "('Find answer for doc.', 740)\n",
      "5.0\n",
      "('Find answer for doc.', 741)\n",
      "8.0\n",
      "('Find answer for doc.', 742)\n",
      "107.5\n",
      "('Find answer for doc.', 743)\n",
      "143.5\n",
      "('Find answer for doc.', 744)\n",
      "29.5\n",
      "('Find answer for doc.', 745)\n",
      "92.5\n",
      "('Find answer for doc.', 746)\n",
      "2.0\n",
      "('Find answer for doc.', 747)\n",
      "11.5\n",
      "('Find answer for doc.', 748)\n",
      "15.5\n",
      "('Find answer for doc.', 749)\n",
      "67.0\n",
      "('Find answer for doc.', 750)\n",
      "213.5\n",
      "('Find answer for doc.', 751)\n",
      "19.0\n",
      "('Find answer for doc.', 752)\n",
      "2.0\n",
      "('Find answer for doc.', 753)\n",
      "28.5\n",
      "('Find answer for doc.', 754)\n",
      "13.5\n",
      "('Find answer for doc.', 755)\n",
      "4.0\n",
      "('Find answer for doc.', 756)\n",
      "60.5\n",
      "('Find answer for doc.', 757)\n",
      "51.0\n",
      "('Find answer for doc.', 758)\n",
      "20.0\n",
      "('Find answer for doc.', 759)\n",
      "140.5\n",
      "('Find answer for doc.', 760)\n",
      "12.5\n",
      "('Find answer for doc.', 761)\n",
      "133.5\n",
      "('Find answer for doc.', 762)\n",
      "25.0\n",
      "('Find answer for doc.', 763)\n",
      "23.5\n",
      "('Find answer for doc.', 764)\n",
      "2.0\n",
      "('Find answer for doc.', 765)\n",
      "54.0\n",
      "('Find answer for doc.', 766)\n",
      "4.0\n",
      "('Find answer for doc.', 767)\n",
      "21.5\n",
      "('Find answer for doc.', 768)\n",
      "16.0\n",
      "('Find answer for doc.', 769)\n",
      "9.5\n",
      "('Find answer for doc.', 770)\n",
      "2.0\n",
      "('Find answer for doc.', 771)\n",
      "1.0\n",
      "('Find answer for doc.', 772)\n",
      "7.0\n",
      "('Find answer for doc.', 773)\n",
      "8.0\n",
      "('Find answer for doc.', 774)\n",
      "51.0\n",
      "('Find answer for doc.', 775)\n",
      "11.0\n",
      "('Find answer for doc.', 776)\n",
      "235.0\n",
      "('Find answer for doc.', 777)\n",
      "85.5\n",
      "('Find answer for doc.', 778)\n",
      "4.0\n",
      "('Find answer for doc.', 779)\n",
      "13.5\n",
      "('Find answer for doc.', 780)\n",
      "9.5\n",
      "('Find answer for doc.', 781)\n",
      "73.5\n",
      "('Find answer for doc.', 782)\n",
      "59.0\n",
      "('Find answer for doc.', 783)\n",
      "19.0\n",
      "('Find answer for doc.', 784)\n",
      "145.0\n",
      "('Find answer for doc.', 785)\n",
      "19.0\n",
      "('Find answer for doc.', 786)\n",
      "12.0\n",
      "('Find answer for doc.', 787)\n",
      "92.0\n",
      "('Find answer for doc.', 788)\n",
      "152.5\n",
      "('Find answer for doc.', 789)\n",
      "33.5\n",
      "('Find answer for doc.', 790)\n",
      "91.0\n",
      "('Find answer for doc.', 791)\n",
      "156.5\n",
      "('Find answer for doc.', 792)\n",
      "77.5\n",
      "('Find answer for doc.', 793)\n",
      "123.0\n",
      "('Find answer for doc.', 794)\n",
      "30.0\n",
      "('Find answer for doc.', 795)\n",
      "379.5\n",
      "('Find answer for doc.', 796)\n",
      "308.5\n",
      "('Find answer for doc.', 797)\n",
      "171.0\n",
      "('Find answer for doc.', 798)\n",
      "160.0\n",
      "('Find answer for doc.', 799)\n",
      "216.5\n",
      "('Find answer for doc.', 800)\n",
      "67.5\n",
      "('Find answer for doc.', 801)\n",
      "248.5\n",
      "('Find answer for doc.', 802)\n",
      "189.5\n",
      "('Find answer for doc.', 803)\n",
      "377.5\n",
      "('Find answer for doc.', 804)\n",
      "233.5\n",
      "('Find answer for doc.', 805)\n",
      "219.5\n",
      "('Find answer for doc.', 806)\n",
      "306.5\n",
      "('Find answer for doc.', 807)\n",
      "13.0\n",
      "('Find answer for doc.', 808)\n",
      "199.0\n",
      "('Find answer for doc.', 809)\n",
      "67.5\n",
      "('Find answer for doc.', 810)\n",
      "201.5\n",
      "('Find answer for doc.', 811)\n",
      "377.5\n",
      "('Find answer for doc.', 812)\n",
      "379.5\n",
      "('Find answer for doc.', 813)\n",
      "27.0\n",
      "('Find answer for doc.', 814)\n",
      "25.0\n",
      "('Find answer for doc.', 815)\n",
      "4.0\n",
      "('Find answer for doc.', 816)\n",
      "129.5\n",
      "('Find answer for doc.', 817)\n",
      "34.0\n",
      "('Find answer for doc.', 818)\n",
      "16.0\n",
      "('Find answer for doc.', 819)\n",
      "4.0\n",
      "('Find answer for doc.', 820)\n",
      "200.5\n",
      "('Find answer for doc.', 821)\n",
      "140.5\n",
      "('Find answer for doc.', 822)\n",
      "197.5\n",
      "('Find answer for doc.', 823)\n",
      "160.0\n",
      "('Find answer for doc.', 824)\n",
      "205.0\n",
      "('Find answer for doc.', 825)\n",
      "218.5\n",
      "('Find answer for doc.', 826)\n",
      "3.0\n",
      "('Find answer for doc.', 827)\n",
      "199.0\n",
      "('Find answer for doc.', 828)\n",
      "200.0\n",
      "('Find answer for doc.', 829)\n",
      "254.5\n",
      "('Find answer for doc.', 830)\n",
      "5.0\n",
      "('Find answer for doc.', 831)\n",
      "109.0\n",
      "('Find answer for doc.', 832)\n",
      "110.0\n",
      "('Find answer for doc.', 833)\n",
      "18.5\n",
      "('Find answer for doc.', 834)\n",
      "7.0\n",
      "('Find answer for doc.', 835)\n",
      "36.5\n",
      "('Find answer for doc.', 836)\n",
      "109.0\n",
      "('Find answer for doc.', 837)\n",
      "192.0\n",
      "('Find answer for doc.', 838)\n",
      "15.5\n",
      "('Find answer for doc.', 839)\n",
      "34.0\n",
      "('Find answer for doc.', 840)\n",
      "79.0\n",
      "('Find answer for doc.', 841)\n",
      "8.5\n",
      "('Find answer for doc.', 842)\n",
      "96.0\n",
      "('Find answer for doc.', 843)\n",
      "18.5\n",
      "('Find answer for doc.', 844)\n",
      "8.0\n",
      "('Find answer for doc.', 845)\n",
      "9.5\n",
      "('Find answer for doc.', 846)\n",
      "16.0\n",
      "('Find answer for doc.', 847)\n",
      "116.5\n",
      "('Find answer for doc.', 848)\n",
      "10.5\n",
      "('Find answer for doc.', 849)\n",
      "35.0\n",
      "('Find answer for doc.', 850)\n",
      "20.5\n",
      "('Find answer for doc.', 851)\n",
      "34.0\n",
      "('Find answer for doc.', 852)\n",
      "108.0\n",
      "('Find answer for doc.', 853)\n",
      "10.0\n",
      "('Find answer for doc.', 854)\n",
      "7.0\n",
      "('Find answer for doc.', 855)\n",
      "68.0\n",
      "('Find answer for doc.', 856)\n",
      "33.5\n",
      "('Find answer for doc.', 857)\n",
      "22.0\n",
      "('Find answer for doc.', 858)\n",
      "10.5\n",
      "('Find answer for doc.', 859)\n",
      "37.0\n",
      "('Find answer for doc.', 860)\n",
      "18.5\n",
      "('Find answer for doc.', 861)\n",
      "22.0\n",
      "('Find answer for doc.', 862)\n",
      "24.0\n",
      "('Find answer for doc.', 863)\n",
      "156.0\n",
      "('Find answer for doc.', 864)\n",
      "2.0\n",
      "('Find answer for doc.', 865)\n",
      "66.0\n",
      "('Find answer for doc.', 866)\n",
      "21.0\n",
      "('Find answer for doc.', 867)\n",
      "9.0\n",
      "('Find answer for doc.', 868)\n",
      "7.0\n",
      "('Find answer for doc.', 869)\n",
      "48.5\n",
      "('Find answer for doc.', 870)\n",
      "3.0\n",
      "('Find answer for doc.', 871)\n",
      "3.0\n",
      "('Find answer for doc.', 872)\n",
      "58.0\n",
      "('Find answer for doc.', 873)\n",
      "43.0\n",
      "('Find answer for doc.', 874)\n",
      "25.0\n",
      "('Find answer for doc.', 875)\n",
      "10.0\n",
      "('Find answer for doc.', 876)\n",
      "33.5\n",
      "('Find answer for doc.', 877)\n",
      "52.0\n",
      "('Find answer for doc.', 878)\n",
      "61.0\n",
      "('Find answer for doc.', 879)\n",
      "26.0\n",
      "('Find answer for doc.', 880)\n",
      "4.0\n",
      "('Find answer for doc.', 881)\n",
      "81.0\n",
      "('Find answer for doc.', 882)\n",
      "41.5\n",
      "('Find answer for doc.', 883)\n",
      "9.0\n",
      "('Find answer for doc.', 884)\n",
      "119.0\n",
      "('Find answer for doc.', 885)\n",
      "16.0\n",
      "('Find answer for doc.', 886)\n",
      "6.0\n",
      "('Find answer for doc.', 887)\n",
      "121.5\n",
      "('Find answer for doc.', 888)\n",
      "1.0\n",
      "('Find answer for doc.', 889)\n",
      "2.0\n",
      "('Find answer for doc.', 890)\n",
      "71.5\n",
      "('Find answer for doc.', 891)\n",
      "19.5\n",
      "('Find answer for doc.', 892)\n",
      "13.0\n",
      "('Find answer for doc.', 893)\n",
      "12.0\n",
      "('Find answer for doc.', 894)\n",
      "2.0\n",
      "('Find answer for doc.', 895)\n",
      "27.0\n",
      "('Find answer for doc.', 896)\n",
      "21.0\n",
      "('Find answer for doc.', 897)\n",
      "21.5\n",
      "('Find answer for doc.', 898)\n",
      "20.5\n",
      "('Find answer for doc.', 899)\n",
      "9.0\n",
      "('Find answer for doc.', 900)\n",
      "3.5\n",
      "('Find answer for doc.', 901)\n",
      "51.5\n",
      "('Find answer for doc.', 902)\n",
      "1.0\n",
      "('Find answer for doc.', 903)\n",
      "31.5\n",
      "('Find answer for doc.', 904)\n",
      "13.0\n",
      "('Find answer for doc.', 905)\n",
      "43.0\n",
      "('Find answer for doc.', 906)\n",
      "5.0\n",
      "('Find answer for doc.', 907)\n",
      "23.5\n",
      "('Find answer for doc.', 908)\n",
      "29.0\n",
      "('Find answer for doc.', 909)\n",
      "22.5\n",
      "('Find answer for doc.', 910)\n",
      "7.0\n",
      "('Find answer for doc.', 911)\n",
      "50.0\n",
      "('Find answer for doc.', 912)\n",
      "38.5\n",
      "('Find answer for doc.', 913)\n",
      "41.0\n",
      "('Find answer for doc.', 914)\n",
      "2.0\n",
      "('Find answer for doc.', 915)\n",
      "3.0\n",
      "('Find answer for doc.', 916)\n",
      "30.0\n",
      "('Find answer for doc.', 917)\n",
      "2.0\n",
      "('Find answer for doc.', 918)\n",
      "4.5\n",
      "('Find answer for doc.', 919)\n",
      "8.5\n",
      "('Find answer for doc.', 920)\n",
      "199.5\n",
      "('Find answer for doc.', 921)\n",
      "157.0\n",
      "('Find answer for doc.', 922)\n",
      "53.5\n",
      "('Find answer for doc.', 923)\n",
      "115.5\n",
      "('Find answer for doc.', 924)\n",
      "11.0\n",
      "('Find answer for doc.', 925)\n",
      "9.5\n",
      "('Find answer for doc.', 926)\n",
      "6.0\n",
      "('Find answer for doc.', 927)\n",
      "2.0\n",
      "('Find answer for doc.', 928)\n",
      "293.0\n",
      "('Find answer for doc.', 929)\n",
      "2.0\n",
      "('Find answer for doc.', 930)\n",
      "12.0\n",
      "('Find answer for doc.', 931)\n",
      "51.5\n",
      "('Find answer for doc.', 932)\n",
      "11.5\n",
      "('Find answer for doc.', 933)\n",
      "12.0\n",
      "('Find answer for doc.', 934)\n",
      "25.0\n",
      "('Find answer for doc.', 935)\n",
      "10.5\n",
      "('Find answer for doc.', 936)\n",
      "19.0\n",
      "('Find answer for doc.', 937)\n",
      "80.0\n",
      "('Find answer for doc.', 938)\n",
      "22.0\n",
      "('Find answer for doc.', 939)\n",
      "31.0\n",
      "('Find answer for doc.', 940)\n",
      "63.0\n",
      "('Find answer for doc.', 941)\n",
      "134.5\n",
      "('Find answer for doc.', 942)\n",
      "24.0\n",
      "('Find answer for doc.', 943)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0\n",
      "('Find answer for doc.', 944)\n",
      "3.0\n",
      "('Find answer for doc.', 945)\n",
      "27.0\n",
      "('Find answer for doc.', 946)\n",
      "30.0\n",
      "('Find answer for doc.', 947)\n",
      "10.0\n",
      "('Find answer for doc.', 948)\n",
      "60.5\n",
      "('Find answer for doc.', 949)\n",
      "15.0\n",
      "('Find answer for doc.', 950)\n",
      "74.0\n",
      "('Find answer for doc.', 951)\n",
      "103.0\n",
      "('Find answer for doc.', 952)\n",
      "23.5\n",
      "('Find answer for doc.', 953)\n",
      "34.0\n",
      "('Find answer for doc.', 954)\n",
      "49.5\n",
      "('Find answer for doc.', 955)\n",
      "6.0\n",
      "('Find answer for doc.', 956)\n",
      "9.5\n",
      "('Find answer for doc.', 957)\n",
      "60.5\n",
      "('Find answer for doc.', 958)\n",
      "206.5\n",
      "('Find answer for doc.', 959)\n",
      "54.5\n",
      "('Find answer for doc.', 960)\n",
      "22.0\n",
      "('Find answer for doc.', 961)\n",
      "71.0\n",
      "('Find answer for doc.', 962)\n",
      "21.5\n",
      "('Find answer for doc.', 963)\n",
      "41.5\n",
      "('Find answer for doc.', 964)\n",
      "28.0\n",
      "('Find answer for doc.', 965)\n",
      "7.0\n",
      "('Find answer for doc.', 966)\n",
      "5.0\n",
      "('Find answer for doc.', 967)\n",
      "98.5\n",
      "('Find answer for doc.', 968)\n",
      "2.0\n",
      "('Find answer for doc.', 969)\n",
      "47.0\n",
      "('Find answer for doc.', 970)\n",
      "4.0\n",
      "('Find answer for doc.', 971)\n",
      "109.0\n",
      "('Find answer for doc.', 972)\n",
      "4.0\n",
      "('Find answer for doc.', 973)\n",
      "2.0\n",
      "('Find answer for doc.', 974)\n",
      "13.0\n",
      "('Find answer for doc.', 975)\n",
      "34.0\n",
      "('Find answer for doc.', 976)\n",
      "11.5\n",
      "('Find answer for doc.', 977)\n",
      "12.0\n",
      "('Find answer for doc.', 978)\n",
      "2.0\n",
      "('Find answer for doc.', 979)\n",
      "19.0\n",
      "('Find answer for doc.', 980)\n",
      "57.0\n",
      "('Find answer for doc.', 981)\n",
      "20.0\n",
      "('Find answer for doc.', 982)\n",
      "3.0\n",
      "('Find answer for doc.', 983)\n",
      "27.0\n",
      "('Find answer for doc.', 984)\n",
      "37.0\n",
      "('Find answer for doc.', 985)\n",
      "21.0\n",
      "('Find answer for doc.', 986)\n",
      "20.5\n",
      "('Find answer for doc.', 987)\n",
      "5.5\n",
      "('Find answer for doc.', 988)\n",
      "140.0\n",
      "('Find answer for doc.', 989)\n",
      "89.0\n",
      "('Find answer for doc.', 990)\n",
      "5.5\n",
      "('Find answer for doc.', 991)\n",
      "8.0\n",
      "('Find answer for doc.', 992)\n",
      "17.0\n",
      "('Find answer for doc.', 993)\n",
      "3.0\n",
      "('Find answer for doc.', 994)\n",
      "1.5\n",
      "('Find answer for doc.', 995)\n",
      "20.5\n",
      "('Find answer for doc.', 996)\n",
      "21.0\n",
      "('Find answer for doc.', 997)\n",
      "7.5\n",
      "('Find answer for doc.', 998)\n",
      "4.5\n",
      "('Find answer for doc.', 999)\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# 1 \n",
    "# 2 epoch\n",
    "# 3 cosine similarity\n",
    "a = find_ranking(X1_test_1[:,:,:], X2_test_1, model_lstm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_results_test, rank_results_test = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1000.000000\n",
      "mean       49.668000\n",
      "std        70.423094\n",
      "min         1.000000\n",
      "25%         9.000000\n",
      "50%        23.000000\n",
      "75%        58.000000\n",
      "max       514.500000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    " print(pd.Series(rank_results_test).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4UAAAG5CAYAAAA595FfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJA2ZRKEmSJEkD9n/8WrW0hb9V0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b9de4ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "# matplotlib.rcParams['figure.figsize'] = (6.0, 2.0)\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 7)\n",
    "plt.plot(rank_results_test,'bo')\n",
    "plt.title('TOP Ranking for test documents (1-1000)')\n",
    "plt.xlabel('Document Number')\n",
    "plt.ylabel('The ranking of the real pair')\n",
    "plt.ylim([1000,0])\n",
    "plt.grid(True)\n",
    "plt.savefig('top-test.eps', format='eps', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n",
      "150\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print sum(np.array(rank_results_test) <= 10)\n",
    "print sum(np.array(rank_results_test) <= 5)\n",
    "print sum(np.array(rank_results_test) <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# googletop1top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   7. ,    1. ,    1. ,   58. ,   84.5,   13. ,  195. ,    6. ,\n",
       "          6. ,   34.5,    3. ,   37. ,   25. ,    1. ,   25.5,   53. ,\n",
       "         29.5,   73. ,   13. ,   15.5,   30. ,   19. ,   73. ,    1. ,\n",
       "         24. ,    8.5,   62. ,   35.5,    1. ,    5. ,    5. ,    6. ,\n",
       "         19. ,   82.5,    6. ,    7. ,    3.5,   62. ,   18. ,  110. ,\n",
       "         10. ,   18.5,   51. ,   14. ,   29. ,  123. ,    4. ,    9. ,\n",
       "         77. ,  199. ,    6. ,    8. ,   32. ,   76. ,   29.5,   28. ,\n",
       "         26. ,   18. ,   29. ,    7. ,   17. ,   16. ,   14. ,    2. ,\n",
       "         38. ,   20. ,   93. ,   16. ,   15. ,   21. ,   80. ,   58. ,\n",
       "          7.5,    2. ,    8. ,    7.5,   18. ,   24.5,  205. ,    1. ,\n",
       "         82.5,    2.5,    5.5,   65. ,   19. ,    2. ,   13.5,   41. ,\n",
       "         21.5,   34.5,    3. ,    1. ,    8. ,  117. ,    5. ,   26. ,\n",
       "         19. ,   79. ,   28. ,  119. ,    8.5,   30. ,   23. ,   30. ,\n",
       "          7.5,   37. ,    2.5,   22.5,   82. ,   15.5,    2. ,   88.5,\n",
       "         46. ,   16. ,   13. ,   82.5,   24. ,   11. ,   78. ,   32. ,\n",
       "         29.5,   15.5,   44. ,    2. ,   12. ,   98. ,   12. ,    7.5,\n",
       "          6.5,   13. ,    2. ,    3. ,   12. ,   18. ,   47. ,    4. ,\n",
       "         24. ,  347. ,   77. ,  115. ,  165. ,   21.5,    2. ,   14. ,\n",
       "        254. ,    8. ,  469. ,   46.5,   14. ,    9. ,  236.5,    4.5,\n",
       "         42. ,   91.5,    1.5,  104.5,   23. ,  283. ,    9.5,  246. ,\n",
       "         25.5,   25. ,    2. ,    6. ,    4. ,   13. ,  106. ,  273.5,\n",
       "         77.5,   14.5,   25. ,   32. ,   58.5,   10. ,   17. ,    3. ,\n",
       "         17. ,    7. ,   47.5,   20. ,    1.5,   25. ,    5. ,   33. ,\n",
       "        139. ,    3. ,   35. ,    2. ,   54. ,   67.5,   25.5,   17. ,\n",
       "         23. ,  317. ,  111. ,    3. ,   18.5,  251. ,   91.5,   12.5,\n",
       "        242. ,    6. ,   46. ,   14.5,   14. ,   16.5,    5. ,   47. ,\n",
       "         24. ,  123. ,  104.5,   59. ,  289. ,    4. ,   37. ,  146. ,\n",
       "        279. ,  301.5,   91.5,   22. ,    1. ,   54. ,  249. ,   29. ,\n",
       "          3. ,   91.5,    4. ,   39. ,   79. ,   23. ,    8. ,  134. ,\n",
       "         21. ,   17. ,  444. ,   20. ,  101.5,    7.5,    3. ,  214. ,\n",
       "         30. ,   36. ,   25. ,  108.5,    8. ,   14.5,  242. ,   10.5,\n",
       "          5.5,   49. ,   82. ,   14. ,   56. ,  108.5,   25. ,  172. ,\n",
       "         16. ,   85.5,    3. ,   15.5,    8. ,  213. ,   20. ,   22. ,\n",
       "         10.5,  242. ,  159. ,   49.5,   94. ,    5. ,   81. ,    9. ,\n",
       "        273.5,    2. ,   49.5,   89. ,   20.5,    2. ,   10.5,  165. ,\n",
       "         38. ,  111. ,   62.5,   14.5,   91.5,   46.5,    7.5,    3. ,\n",
       "        111. ,   12. ,    1. ,   25.5,    7. ,  397. ,   16. ,   14. ,\n",
       "          1. ,    4.5,    3. ,   28.5,   14. ,    7.5,   11. ,  137. ,\n",
       "         60. ,    5.5,   29. ,   20. ,   12. ,   23. ,   53. ,   23.5,\n",
       "         91.5,    9. ,   88. ,   25. ,   77. ,   25. ,    2. ,   51. ,\n",
       "         75. ,   40. ,   48. ,   23.5,   11. ,    5.5,   23. ,    9. ,\n",
       "          3.5,   91.5,    5. ,    5.5,   87. ,   10.5,   15. ,   20. ,\n",
       "         12.5,   39. ,   14. ,   22. ,    1. ,   50.5,   28.5,  301.5,\n",
       "         21.5,  105.5,   43. ,    7. ,  111. ,   17. ,   33. ,   41. ,\n",
       "         56.5,    7. ,   12. ,   92. ,    5. ,   39. ,   16. ,    1.5,\n",
       "         93. ,  342.5,    8.5,  156. ,   14. ,   21.5,   19. ,   70. ,\n",
       "         35.5,   55.5,   19. ,   12. ,   55. ,   37.5,  185. ,   20. ,\n",
       "         27. ,   31. ,   21.5,  231. ,    6. ,  118. ,    2. ,   28. ,\n",
       "          1. ,   21. ,  155.5,    7. ,   12. ,   44. ,    9. ,   35. ,\n",
       "          7. ,   23. ,   43.5,   24. ,  242.5,    2. ,   63. ,   12. ,\n",
       "          3. ,    7. ,   16. ,   37.5,    5.5,    4.5,   13. ,   10.5,\n",
       "         17.5,   70.5,   24. ,   20. ,   15.5,    2. ,   23. ,   21.5,\n",
       "          6. ,   45.5,   20. ,   45.5,   17.5,  105. ,    4. ,    8. ,\n",
       "        335.5,    5. ,   41. ,   40.5,   24.5,   35.5,   39.5,   11. ,\n",
       "          2. ,    4.5,   37. ,   12. ,    9. ,  104. ,   41.5,   13. ,\n",
       "         35. ,   55. ,   54.5,   19. ,   26. ,   19.5,    8.5,    5. ,\n",
       "         17. ,   10. ,   19. ,   67. ,  147. ,   72.5,    8. ,    2. ,\n",
       "         23. ,    1.5,   28. ,   17. ,    7. ,   46. ,   52. ,   24. ,\n",
       "          3. ,   19.5,   12. ,   32. ,  238.5,    8.5,   18. ,   32. ,\n",
       "         34. ,    2. ,   22. ,   55. ,    7. ,   12. ,   92. ,    1. ,\n",
       "         12. ,  104.5,   12. ,   18. ,    3. ,   23.5,   11. ,   46. ,\n",
       "          5.5,   32. ,    8. ,  156.5,   14. ,   70.5,   10.5,   37. ,\n",
       "          5.5,   25.5,    4. ,    7. ,   49.5,    8.5,   69. ,    1. ,\n",
       "         13. ,   26. ,    2. ,    1. ,    6.5,   13. ,   14. ,   30. ,\n",
       "         18. ,    5.5,    8. ,   17.5,   43.5,   60. ,  136. ,    2. ,\n",
       "         99. ,    2. ,   59.5,   32.5,  144. ,   25. ,   14. ,   16. ,\n",
       "         19. ,  150. ,   23.5,   52. ,    2. ,   21. ,    6. ,    7. ,\n",
       "         56.5,   35. ,   41.5,   31. ,   13. ,   69.5,  196.5,   81. ,\n",
       "         35. ,    5. ,   42. ,   21.5,   37.5,   36. ,   30. ,   18. ,\n",
       "         70. ,   31.5,    1.5,    1. ,    1.5,   15. ,  108. ,  196.5,\n",
       "         36. ,   10. ,    1.5,    9. ,   24.5,   83. ,   83. ,    9. ,\n",
       "         16. ,    8. ,   25.5,    9. ,    4. ,   58. ,   17.5,   59. ,\n",
       "         40.5,    9. ,   23. ,   34. ,    5. ,   19. ,   28. ,    2. ,\n",
       "         49. ,    1.5,   17. ,   32. ,  327. ,   17. ,    4. ,  514.5,\n",
       "         16. ,  502.5,   61.5,   85. ,    3. ,   28.5,    2. ,   23.5,\n",
       "         28.5,   50. ,    6. ,   19. ,   19. ,   75.5,   14. ,   37. ,\n",
       "         29. ,   37. ,   18. ,   57. ,   12. ,   28.5,   60.5,    3. ,\n",
       "         91. ,   27.5,   23. ,    2. ,    6. ,   55. ,   85. ,    4. ,\n",
       "         12. ,   70. ,    1.5,   13.5,    8.5,   27. ,  137. ,  148. ,\n",
       "         45.5,    5.5,   11. ,   47. ,  235. ,   30.5,    1. ,    2. ,\n",
       "          3. ,   32. ,    1. ,   84.5,   93. ,   39.5,   30. ,   21.5,\n",
       "         27. ,   29.5,   12. ,    5.5,   15. ,   85.5,   52. ,    9.5,\n",
       "         35. ,   14. ,    3. ,    7. ,  153. ,   22. ,   73. ,   77.5,\n",
       "         32. ,   88. ,  211.5,   50.5,  117. ,    1. ,   84. ,    4. ,\n",
       "          1. ,  197. ,    2. ,   14. ,   11. ,   69.5,   21.5,   44. ,\n",
       "         13.5,  106. ,    5. ,   31. ,   34. ,   41. ,   54.5,   36.5,\n",
       "         21.5,   46. ,   35. ,   11. ,    7. ,   10.5,  111.5,    9.5,\n",
       "          9. ,   72. ,   52.5,   20. ,  223.5,   15. ,   15. ,   83.5,\n",
       "         77.5,    6. ,   88. ,   27. ,   16.5,   37.5,   73. ,   11. ,\n",
       "          1.5,   39.5,   83.5,    8. ,   36. ,   37. ,    5. ,   76.5,\n",
       "         28.5,   17. ,   17. ,   11. ,   35. ,   85.5,   65.5,   59. ,\n",
       "         44. ,   47. ,    3. ,   30. ,   15.5,    6.5,    8. ,   32. ,\n",
       "         10. ,  103. ,    9. ,   12.5,    5. ,    8. ,  107.5,  143.5,\n",
       "         29.5,   92.5,    2. ,   11.5,   15.5,   67. ,  213.5,   19. ,\n",
       "          2. ,   28.5,   13.5,    4. ,   60.5,   51. ,   20. ,  140.5,\n",
       "         12.5,  133.5,   25. ,   23.5,    2. ,   54. ,    4. ,   21.5,\n",
       "         16. ,    9.5,    2. ,    1. ,    7. ,    8. ,   51. ,   11. ,\n",
       "        235. ,   85.5,    4. ,   13.5,    9.5,   73.5,   59. ,   19. ,\n",
       "        145. ,   19. ,   12. ,   92. ,  152.5,   33.5,   91. ,  156.5,\n",
       "         77.5,  123. ,   30. ,  379.5,  308.5,  171. ,  160. ,  216.5,\n",
       "         67.5,  248.5,  189.5,  377.5,  233.5,  219.5,  306.5,   13. ,\n",
       "        199. ,   67.5,  201.5,  377.5,  379.5,   27. ,   25. ,    4. ,\n",
       "        129.5,   34. ,   16. ,    4. ,  200.5,  140.5,  197.5,  160. ,\n",
       "        205. ,  218.5,    3. ,  199. ,  200. ,  254.5,    5. ,  109. ,\n",
       "        110. ,   18.5,    7. ,   36.5,  109. ,  192. ,   15.5,   34. ,\n",
       "         79. ,    8.5,   96. ,   18.5,    8. ,    9.5,   16. ,  116.5,\n",
       "         10.5,   35. ,   20.5,   34. ,  108. ,   10. ,    7. ,   68. ,\n",
       "         33.5,   22. ,   10.5,   37. ,   18.5,   22. ,   24. ,  156. ,\n",
       "          2. ,   66. ,   21. ,    9. ,    7. ,   48.5,    3. ,    3. ,\n",
       "         58. ,   43. ,   25. ,   10. ,   33.5,   52. ,   61. ,   26. ,\n",
       "          4. ,   81. ,   41.5,    9. ,  119. ,   16. ,    6. ,  121.5,\n",
       "          1. ,    2. ,   71.5,   19.5,   13. ,   12. ,    2. ,   27. ,\n",
       "         21. ,   21.5,   20.5,    9. ,    3.5,   51.5,    1. ,   31.5,\n",
       "         13. ,   43. ,    5. ,   23.5,   29. ,   22.5,    7. ,   50. ,\n",
       "         38.5,   41. ,    2. ,    3. ,   30. ,    2. ,    4.5,    8.5,\n",
       "        199.5,  157. ,   53.5,  115.5,   11. ,    9.5,    6. ,    2. ,\n",
       "        293. ,    2. ,   12. ,   51.5,   11.5,   12. ,   25. ,   10.5,\n",
       "         19. ,   80. ,   22. ,   31. ,   63. ,  134.5,   24. ,   24. ,\n",
       "          3. ,   27. ,   30. ,   10. ,   60.5,   15. ,   74. ,  103. ,\n",
       "         23.5,   34. ,   49.5,    6. ,    9.5,   60.5,  206.5,   54.5,\n",
       "         22. ,   71. ,   21.5,   41.5,   28. ,    7. ,    5. ,   98.5,\n",
       "          2. ,   47. ,    4. ,  109. ,    4. ,    2. ,   13. ,   34. ,\n",
       "         11.5,   12. ,    2. ,   19. ,   57. ,   20. ,    3. ,   27. ,\n",
       "         37. ,   21. ,   20.5,    5.5,  140. ,   89. ,    5.5,    8. ,\n",
       "         17. ,    3. ,    1.5,   20.5,   21. ,    7.5,    4.5,    4. ])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rank_results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Reading english Data:', 63386)\n",
      "('Reading english Data:', 63386)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    63340\n",
      "True         3\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main_keras.py:206: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_en'] = df_pairs_sample['en_article'].apply(doc2vec_en)\n",
      "main_keras.py:207: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_jp'] = df_pairs_sample['jp_article'].apply(doc2vec_jp)\n",
      "main_keras.py:211: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_en'] = df_pairs_sample['word2vec_en'].apply(padding)\n",
      "main_keras.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_jp'] = df_pairs_sample['word2vec_jp'].apply(padding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 1 position: [2580]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/home/liuenda/Workspace/cas-keras/main_keras.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# --- Generate balanced test data --- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX1_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_test_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1_test_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mX2_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2_test_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_test_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_test_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_test_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run main_keras.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tX1_test = np.concatenate((X1_test_1, X1_test_0), axis=0)\n",
    "\tX2_test = np.concatenate((X2_test_1, X2_test_0), axis=0)\n",
    "\ty_test = np.concatenate((np.ones(len(X1_test_1)), np.zeros(len(X1_test_0))), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.models.load_model(\"model_lstm2_b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_training = model1.predict([X1_train, X2_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.45      0.54      4000\n",
      "        1.0       0.59      0.80      0.68      4000\n",
      "\n",
      "avg / total       0.64      0.62      0.61      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_training>.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_training = model1.predict([X1_test, X2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.47      0.36      0.41      1000\n",
      "        1.0       0.48      0.59      0.53      1000\n",
      "\n",
      "avg / total       0.47      0.47      0.47      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_training>.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ma..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 259s - loss: 0.6565 - acc: 0.6345 - val_loss: 0.6320 - val_acc: 0.6430\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 302s - loss: 0.4402 - acc: 0.8023 - val_loss: 0.4839 - val_acc: 0.7650\n",
      "Epoch 3/10\n",
      "1280/8000 [===>..........................] - ETA: 150s - loss: 0.3563 - acc: 0.8492"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6ba6216544cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Fit the training model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m hist = model_lstm2.fit([X1_train, X2_train], [y_train],\n\u001b[0;32m---> 30\u001b[0;31m                        validation_data=([X1_test, X2_test], y_test), epochs=10, batch_size=256)\n\u001b[0m",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\t# Input layer\n",
    "\tinput_1 = Input(shape=(maxlen,200), dtype='float32', name='main_input_1')\n",
    "\tinput_2 = Input(shape=(maxlen,200), dtype='float32', name='main_input_2')\n",
    "\n",
    "\t# LSTM layer\n",
    "\t# lstm_out_1 = LSTM(50)(input_1)\n",
    "\t# lstm_out_2 = LSTM(50)(input_2)\n",
    "\tlstm_out_1 = LSTM(50, go_backwards = True)(input_1)\n",
    "\tlstm_out_2 = LSTM(50, go_backwards = True)(input_2)\n",
    "\n",
    "\t# Merge layer\n",
    "\tmerged_vector = keras.layers.concatenate([lstm_out_1, lstm_out_2], axis=-1)\n",
    "\n",
    "\t# (Dense 1) * 3\n",
    "\tx1 = Dense(64, activation='relu')(merged_vector)\n",
    "\tx1 = Dense(64, activation='relu')(x1)\n",
    "\tx1 = Dense(64, activation='relu')(x1)\n",
    "\tmain_output = Dense(1, activation='sigmoid', name='main_output')(x1)\n",
    "\n",
    "\t# Model definition\n",
    "\tmodel_lstm2 = Model(input=[input_1, input_2], output=main_output)\n",
    "\n",
    "\t# Compile the model\n",
    "\tmodel_lstm2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\t# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\t# Fit the training model\n",
    "\thist = model_lstm2.fit([X1_train, X2_train], [y_train],\n",
    "\t                       validation_data=([X1_test, X2_test], y_test), epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "r = np.array([   7. ,    1. ,    1. ,   58. ,   84.5,   13. ,  195. ,    6. ,\n",
    "          6. ,   34.5,    3. ,   37. ,   25. ,    1. ,   25.5,   53. ,\n",
    "         29.5,   73. ,   13. ,   15.5,   30. ,   19. ,   73. ,    1. ,\n",
    "         24. ,    8.5,   62. ,   35.5,    1. ,    5. ,    5. ,    6. ,\n",
    "         19. ,   82.5,    6. ,    7. ,    3.5,   62. ,   18. ,  110. ,\n",
    "         10. ,   18.5,   51. ,   14. ,   29. ,  123. ,    4. ,    9. ,\n",
    "         77. ,  199. ,    6. ,    8. ,   32. ,   76. ,   29.5,   28. ,\n",
    "         26. ,   18. ,   29. ,    7. ,   17. ,   16. ,   14. ,    2. ,\n",
    "         38. ,   20. ,   93. ,   16. ,   15. ,   21. ,   80. ,   58. ,\n",
    "          7.5,    2. ,    8. ,    7.5,   18. ,   24.5,  205. ,    1. ,\n",
    "         82.5,    2.5,    5.5,   65. ,   19. ,    2. ,   13.5,   41. ,\n",
    "         21.5,   34.5,    3. ,    1. ,    8. ,  117. ,    5. ,   26. ,\n",
    "         19. ,   79. ,   28. ,  119. ,    8.5,   30. ,   23. ,   30. ,\n",
    "          7.5,   37. ,    2.5,   22.5,   82. ,   15.5,    2. ,   88.5,\n",
    "         46. ,   16. ,   13. ,   82.5,   24. ,   11. ,   78. ,   32. ,\n",
    "         29.5,   15.5,   44. ,    2. ,   12. ,   98. ,   12. ,    7.5,\n",
    "          6.5,   13. ,    2. ,    3. ,   12. ,   18. ,   47. ,    4. ,\n",
    "         24. ,  347. ,   77. ,  115. ,  165. ,   21.5,    2. ,   14. ,\n",
    "        254. ,    8. ,  469. ,   46.5,   14. ,    9. ,  236.5,    4.5,\n",
    "         42. ,   91.5,    1.5,  104.5,   23. ,  283. ,    9.5,  246. ,\n",
    "         25.5,   25. ,    2. ,    6. ,    4. ,   13. ,  106. ,  273.5,\n",
    "         77.5,   14.5,   25. ,   32. ,   58.5,   10. ,   17. ,    3. ,\n",
    "         17. ,    7. ,   47.5,   20. ,    1.5,   25. ,    5. ,   33. ,\n",
    "        139. ,    3. ,   35. ,    2. ,   54. ,   67.5,   25.5,   17. ,\n",
    "         23. ,  317. ,  111. ,    3. ,   18.5,  251. ,   91.5,   12.5,\n",
    "        242. ,    6. ,   46. ,   14.5,   14. ,   16.5,    5. ,   47. ,\n",
    "         24. ,  123. ,  104.5,   59. ,  289. ,    4. ,   37. ,  146. ,\n",
    "        279. ,  301.5,   91.5,   22. ,    1. ,   54. ,  249. ,   29. ,\n",
    "          3. ,   91.5,    4. ,   39. ,   79. ,   23. ,    8. ,  134. ,\n",
    "         21. ,   17. ,  444. ,   20. ,  101.5,    7.5,    3. ,  214. ,\n",
    "         30. ,   36. ,   25. ,  108.5,    8. ,   14.5,  242. ,   10.5,\n",
    "          5.5,   49. ,   82. ,   14. ,   56. ,  108.5,   25. ,  172. ,\n",
    "         16. ,   85.5,    3. ,   15.5,    8. ,  213. ,   20. ,   22. ,\n",
    "         10.5,  242. ,  159. ,   49.5,   94. ,    5. ,   81. ,    9. ,\n",
    "        273.5,    2. ,   49.5,   89. ,   20.5,    2. ,   10.5,  165. ,\n",
    "         38. ,  111. ,   62.5,   14.5,   91.5,   46.5,    7.5,    3. ,\n",
    "        111. ,   12. ,    1. ,   25.5,    7. ,  397. ,   16. ,   14. ,\n",
    "          1. ,    4.5,    3. ,   28.5,   14. ,    7.5,   11. ,  137. ,\n",
    "         60. ,    5.5,   29. ,   20. ,   12. ,   23. ,   53. ,   23.5,\n",
    "         91.5,    9. ,   88. ,   25. ,   77. ,   25. ,    2. ,   51. ,\n",
    "         75. ,   40. ,   48. ,   23.5,   11. ,    5.5,   23. ,    9. ,\n",
    "          3.5,   91.5,    5. ,    5.5,   87. ,   10.5,   15. ,   20. ,\n",
    "         12.5,   39. ,   14. ,   22. ,    1. ,   50.5,   28.5,  301.5,\n",
    "         21.5,  105.5,   43. ,    7. ,  111. ,   17. ,   33. ,   41. ,\n",
    "         56.5,    7. ,   12. ,   92. ,    5. ,   39. ,   16. ,    1.5,\n",
    "         93. ,  342.5,    8.5,  156. ,   14. ,   21.5,   19. ,   70. ,\n",
    "         35.5,   55.5,   19. ,   12. ,   55. ,   37.5,  185. ,   20. ,\n",
    "         27. ,   31. ,   21.5,  231. ,    6. ,  118. ,    2. ,   28. ,\n",
    "          1. ,   21. ,  155.5,    7. ,   12. ,   44. ,    9. ,   35. ,\n",
    "          7. ,   23. ,   43.5,   24. ,  242.5,    2. ,   63. ,   12. ,\n",
    "          3. ,    7. ,   16. ,   37.5,    5.5,    4.5,   13. ,   10.5,\n",
    "         17.5,   70.5,   24. ,   20. ,   15.5,    2. ,   23. ,   21.5,\n",
    "          6. ,   45.5,   20. ,   45.5,   17.5,  105. ,    4. ,    8. ,\n",
    "        335.5,    5. ,   41. ,   40.5,   24.5,   35.5,   39.5,   11. ,\n",
    "          2. ,    4.5,   37. ,   12. ,    9. ,  104. ,   41.5,   13. ,\n",
    "         35. ,   55. ,   54.5,   19. ,   26. ,   19.5,    8.5,    5. ,\n",
    "         17. ,   10. ,   19. ,   67. ,  147. ,   72.5,    8. ,    2. ,\n",
    "         23. ,    1.5,   28. ,   17. ,    7. ,   46. ,   52. ,   24. ,\n",
    "          3. ,   19.5,   12. ,   32. ,  238.5,    8.5,   18. ,   32. ,\n",
    "         34. ,    2. ,   22. ,   55. ,    7. ,   12. ,   92. ,    1. ,\n",
    "         12. ,  104.5,   12. ,   18. ,    3. ,   23.5,   11. ,   46. ,\n",
    "          5.5,   32. ,    8. ,  156.5,   14. ,   70.5,   10.5,   37. ,\n",
    "          5.5,   25.5,    4. ,    7. ,   49.5,    8.5,   69. ,    1. ,\n",
    "         13. ,   26. ,    2. ,    1. ,    6.5,   13. ,   14. ,   30. ,\n",
    "         18. ,    5.5,    8. ,   17.5,   43.5,   60. ,  136. ,    2. ,\n",
    "         99. ,    2. ,   59.5,   32.5,  144. ,   25. ,   14. ,   16. ,\n",
    "         19. ,  150. ,   23.5,   52. ,    2. ,   21. ,    6. ,    7. ,\n",
    "         56.5,   35. ,   41.5,   31. ,   13. ,   69.5,  196.5,   81. ,\n",
    "         35. ,    5. ,   42. ,   21.5,   37.5,   36. ,   30. ,   18. ,\n",
    "         70. ,   31.5,    1.5,    1. ,    1.5,   15. ,  108. ,  196.5,\n",
    "         36. ,   10. ,    1.5,    9. ,   24.5,   83. ,   83. ,    9. ,\n",
    "         16. ,    8. ,   25.5,    9. ,    4. ,   58. ,   17.5,   59. ,\n",
    "         40.5,    9. ,   23. ,   34. ,    5. ,   19. ,   28. ,    2. ,\n",
    "         49. ,    1.5,   17. ,   32. ,  327. ,   17. ,    4. ,  514.5,\n",
    "         16. ,  502.5,   61.5,   85. ,    3. ,   28.5,    2. ,   23.5,\n",
    "         28.5,   50. ,    6. ,   19. ,   19. ,   75.5,   14. ,   37. ,\n",
    "         29. ,   37. ,   18. ,   57. ,   12. ,   28.5,   60.5,    3. ,\n",
    "         91. ,   27.5,   23. ,    2. ,    6. ,   55. ,   85. ,    4. ,\n",
    "         12. ,   70. ,    1.5,   13.5,    8.5,   27. ,  137. ,  148. ,\n",
    "         45.5,    5.5,   11. ,   47. ,  235. ,   30.5,    1. ,    2. ,\n",
    "          3. ,   32. ,    1. ,   84.5,   93. ,   39.5,   30. ,   21.5,\n",
    "         27. ,   29.5,   12. ,    5.5,   15. ,   85.5,   52. ,    9.5,\n",
    "         35. ,   14. ,    3. ,    7. ,  153. ,   22. ,   73. ,   77.5,\n",
    "         32. ,   88. ,  211.5,   50.5,  117. ,    1. ,   84. ,    4. ,\n",
    "          1. ,  197. ,    2. ,   14. ,   11. ,   69.5,   21.5,   44. ,\n",
    "         13.5,  106. ,    5. ,   31. ,   34. ,   41. ,   54.5,   36.5,\n",
    "         21.5,   46. ,   35. ,   11. ,    7. ,   10.5,  111.5,    9.5,\n",
    "          9. ,   72. ,   52.5,   20. ,  223.5,   15. ,   15. ,   83.5,\n",
    "         77.5,    6. ,   88. ,   27. ,   16.5,   37.5,   73. ,   11. ,\n",
    "          1.5,   39.5,   83.5,    8. ,   36. ,   37. ,    5. ,   76.5,\n",
    "         28.5,   17. ,   17. ,   11. ,   35. ,   85.5,   65.5,   59. ,\n",
    "         44. ,   47. ,    3. ,   30. ,   15.5,    6.5,    8. ,   32. ,\n",
    "         10. ,  103. ,    9. ,   12.5,    5. ,    8. ,  107.5,  143.5,\n",
    "         29.5,   92.5,    2. ,   11.5,   15.5,   67. ,  213.5,   19. ,\n",
    "          2. ,   28.5,   13.5,    4. ,   60.5,   51. ,   20. ,  140.5,\n",
    "         12.5,  133.5,   25. ,   23.5,    2. ,   54. ,    4. ,   21.5,\n",
    "         16. ,    9.5,    2. ,    1. ,    7. ,    8. ,   51. ,   11. ,\n",
    "        235. ,   85.5,    4. ,   13.5,    9.5,   73.5,   59. ,   19. ,\n",
    "        145. ,   19. ,   12. ,   92. ,  152.5,   33.5,   91. ,  156.5,\n",
    "         77.5,  123. ,   30. ,  379.5,  308.5,  171. ,  160. ,  216.5,\n",
    "         67.5,  248.5,  189.5,  377.5,  233.5,  219.5,  306.5,   13. ,\n",
    "        199. ,   67.5,  201.5,  377.5,  379.5,   27. ,   25. ,    4. ,\n",
    "        129.5,   34. ,   16. ,    4. ,  200.5,  140.5,  197.5,  160. ,\n",
    "        205. ,  218.5,    3. ,  199. ,  200. ,  254.5,    5. ,  109. ,\n",
    "        110. ,   18.5,    7. ,   36.5,  109. ,  192. ,   15.5,   34. ,\n",
    "         79. ,    8.5,   96. ,   18.5,    8. ,    9.5,   16. ,  116.5,\n",
    "         10.5,   35. ,   20.5,   34. ,  108. ,   10. ,    7. ,   68. ,\n",
    "         33.5,   22. ,   10.5,   37. ,   18.5,   22. ,   24. ,  156. ,\n",
    "          2. ,   66. ,   21. ,    9. ,    7. ,   48.5,    3. ,    3. ,\n",
    "         58. ,   43. ,   25. ,   10. ,   33.5,   52. ,   61. ,   26. ,\n",
    "          4. ,   81. ,   41.5,    9. ,  119. ,   16. ,    6. ,  121.5,\n",
    "          1. ,    2. ,   71.5,   19.5,   13. ,   12. ,    2. ,   27. ,\n",
    "         21. ,   21.5,   20.5,    9. ,    3.5,   51.5,    1. ,   31.5,\n",
    "         13. ,   43. ,    5. ,   23.5,   29. ,   22.5,    7. ,   50. ,\n",
    "         38.5,   41. ,    2. ,    3. ,   30. ,    2. ,    4.5,    8.5,\n",
    "        199.5,  157. ,   53.5,  115.5,   11. ,    9.5,    6. ,    2. ,\n",
    "        293. ,    2. ,   12. ,   51.5,   11.5,   12. ,   25. ,   10.5,\n",
    "         19. ,   80. ,   22. ,   31. ,   63. ,  134.5,   24. ,   24. ,\n",
    "          3. ,   27. ,   30. ,   10. ,   60.5,   15. ,   74. ,  103. ,\n",
    "         23.5,   34. ,   49.5,    6. ,    9.5,   60.5,  206.5,   54.5,\n",
    "         22. ,   71. ,   21.5,   41.5,   28. ,    7. ,    5. ,   98.5,\n",
    "          2. ,   47. ,    4. ,  109. ,    4. ,    2. ,   13. ,   34. ,\n",
    "         11.5,   12. ,    2. ,   19. ,   57. ,   20. ,    3. ,   27. ,\n",
    "         37. ,   21. ,   20.5,    5.5,  140. ,   89. ,    5.5,    8. ,\n",
    "         17. ,    3. ,    1.5,   20.5,   21. ,    7.5,    4.5,    4. ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       49.668000\n",
       "std        70.423094\n",
       "min         1.000000\n",
       "25%         9.000000\n",
       "50%        23.000000\n",
       "75%        58.000000\n",
       "max       514.500000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(r).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
