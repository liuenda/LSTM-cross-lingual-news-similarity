{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Reading english Data:', 63386)\n",
      "('Reading english Data:', 63386)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    63340\n",
      "True         3\n",
      "Name: en_article, dtype: int64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main_keras.py:207: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_en'] = df_pairs_sample['en_article'].apply(doc2vec_en)\n",
      "main_keras.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_jp'] = df_pairs_sample['jp_article'].apply(doc2vec_jp)\n",
      "main_keras.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_en'] = df_pairs_sample['word2vec_en'].apply(padding)\n",
      "main_keras.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_jp'] = df_pairs_sample['word2vec_jp'].apply(padding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C value = 2 position: [983, 1229]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main_keras.py:269: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ma..., inputs=[<tf.Tenso...)`\n",
      "  model_lstm2 = Model(input=[input_1, input_2], output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 95s - loss: 0.6924 - acc: 0.5036    \n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 82s - loss: 0.6795 - acc: 0.5334    \n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 81s - loss: 0.6581 - acc: 0.5605    \n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 81s - loss: 0.6558 - acc: 0.5632    \n",
      "Epoch 5/50\n",
      "3072/8000 [==========>...................] - ETA: 48s - loss: 0.6316 - acc: 0.5895"
     ]
    }
   ],
   "source": [
    "run main_keras.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 300, 200)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 300, 200)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 50)            50200       main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 50)            50200       main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 100)           0           lstm_1[0][0]                     \n",
      "                                                                   lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 64)            6464        concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 64)            4160        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 64)            4160        dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             65          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 115,249\n",
      "Trainable params: 115,249\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_lstm2.save(filepath=\"dlmodel/model_lstm2_a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "filepath=\"dlmodel/model_lstm2_a\"\n",
    "model_lstm2 = keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"490pt\" viewBox=\"0.00 0.00 431.00 490.00\" width=\"431pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 486)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-486 427,-486 427,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140690896156368 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140690896156368</title>\n",
       "<polygon fill=\"none\" points=\"-0.5,-445 -0.5,-481 202.5,-481 202.5,-445 -0.5,-445\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-459.3\">main_input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140690896156816 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140690896156816</title>\n",
       "<polygon fill=\"none\" points=\"65,-371 65,-407 181,-407 181,-371 65,-371\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123\" y=\"-385.3\">lstm_1: LSTM</text>\n",
       "</g>\n",
       "<!-- 140690896156368&#45;&gt;140690896156816 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140690896156368-&gt;140690896156816</title>\n",
       "<path d=\"M106.214,-444.937C108.752,-436.63 111.864,-426.444 114.717,-417.108\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"118.096,-418.027 117.671,-407.441 111.401,-415.981 118.096,-418.027\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140690896156496 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140690896156496</title>\n",
       "<polygon fill=\"none\" points=\"220.5,-445 220.5,-481 423.5,-481 423.5,-445 220.5,-445\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322\" y=\"-459.3\">main_input_2: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140690484263696 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140690484263696</title>\n",
       "<polygon fill=\"none\" points=\"242,-371 242,-407 358,-407 358,-371 242,-371\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-385.3\">lstm_2: LSTM</text>\n",
       "</g>\n",
       "<!-- 140690896156496&#45;&gt;140690484263696 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140690896156496-&gt;140690484263696</title>\n",
       "<path d=\"M316.786,-444.937C314.248,-436.63 311.136,-426.444 308.283,-417.108\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"311.599,-415.981 305.329,-407.441 304.904,-418.027 311.599,-415.981\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140690484182224 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140690484182224</title>\n",
       "<polygon fill=\"none\" points=\"100.5,-297 100.5,-333 321.5,-333 321.5,-297 100.5,-297\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-311.3\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 140690896156816&#45;&gt;140690484182224 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140690896156816-&gt;140690484182224</title>\n",
       "<path d=\"M143.855,-370.937C155.279,-361.59 169.612,-349.863 182.1,-339.646\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"184.467,-342.231 189.99,-333.19 180.034,-336.814 184.467,-342.231\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140690484263696&#45;&gt;140690484182224 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140690484263696-&gt;140690484182224</title>\n",
       "<path d=\"M278.908,-370.937C267.355,-361.59 252.858,-349.863 240.229,-339.646\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"242.225,-336.758 232.249,-333.19 237.822,-342.201 242.225,-336.758\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140690484182992 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140690484182992</title>\n",
       "<polygon fill=\"none\" points=\"147,-223 147,-259 275,-259 275,-223 147,-223\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-237.3\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140690484182224&#45;&gt;140690484182992 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140690484182224-&gt;140690484182992</title>\n",
       "<path d=\"M211,-296.937C211,-288.807 211,-278.876 211,-269.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"214.5,-269.441 211,-259.441 207.5,-269.441 214.5,-269.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140690481769488 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140690481769488</title>\n",
       "<polygon fill=\"none\" points=\"147,-149 147,-185 275,-185 275,-149 147,-149\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-163.3\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 140690484182992&#45;&gt;140690481769488 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140690484182992-&gt;140690481769488</title>\n",
       "<path d=\"M211,-222.937C211,-214.807 211,-204.876 211,-195.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"214.5,-195.441 211,-185.441 207.5,-195.441 214.5,-195.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140690480697296 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140690480697296</title>\n",
       "<polygon fill=\"none\" points=\"147,-75 147,-111 275,-111 275,-75 147,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-89.3\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 140690481769488&#45;&gt;140690480697296 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140690481769488-&gt;140690480697296</title>\n",
       "<path d=\"M211,-148.937C211,-140.807 211,-130.876 211,-121.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"214.5,-121.441 211,-111.441 207.5,-121.441 214.5,-121.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140690480786000 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140690480786000</title>\n",
       "<polygon fill=\"none\" points=\"131,-1 131,-37 291,-37 291,-1 131,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-15.3\">main_output: Dense</text>\n",
       "</g>\n",
       "<!-- 140690480697296&#45;&gt;140690480786000 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140690480697296-&gt;140690480786000</title>\n",
       "<path d=\"M211,-74.937C211,-66.8072 211,-56.8761 211,-47.7047\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"214.5,-47.4406 211,-37.4407 207.5,-47.4407 214.5,-47.4406\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model_lstm2).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Reading english Data:', 63386)\n",
      "('Reading english Data:', 63386)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    63340\n",
      "True         3\n",
      "Name: en_article, dtype: int64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main_keras.py:207: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_en'] = df_pairs_sample['en_article'].apply(doc2vec_en)\n",
      "main_keras.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_jp'] = df_pairs_sample['jp_article'].apply(doc2vec_jp)\n",
      "main_keras.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_en'] = df_pairs_sample['word2vec_en'].apply(padding)\n",
      "main_keras.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_jp'] = df_pairs_sample['word2vec_jp'].apply(padding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C value = 1 position: [1181]\n"
     ]
    }
   ],
   "source": [
    "run main_keras.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([664])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model_lstm2.predict([X1_test, X2_test])>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\tX1_train1, X1_test_1, X1_train2, X1_train3_wrong, X1_test_0 = np.split(X_1, [2000, 3000, 5000, 9000])\n",
    "\tX2_train1, X2_test_1, X2_train2, X2_train3_wrong, X2_test_0 = np.split(X_2, [2000, 3000, 5000, 9000])\n",
    "\ty_train1, y_test, y_train2, y_train3_wrong, Y_o = np.split(y, [2000, 3000, 9000, 9000])\n",
    "\n",
    "\tX1_train = np.concatenate((X1_train1, X1_train2, X1_train3_wrong), axis = 0)\n",
    "\tX2_train = np.concatenate((X2_train1, X2_train2, X2_train3_wrong), axis = 0)\n",
    "\ty_train = np.concatenate((y_train1, y_train2, y_train3_wrong), axis = 0)\n",
    "\t# X_train_correct = np.concatenate((X_train1, X_train2), axis = 0)\n",
    "\t# y_train_correct = np.concatenate((y_train1, y_train2), axis = 0)\n",
    "\n",
    "\t# --- Generate balanced test data --- #\n",
    "\tX1_test = np.concatenate((X1_test_1, X1_test_0), axis=0)\n",
    "\tX2_test = np.concatenate((X2_test_1, X2_test_0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 300, 200)\n",
      "(2000, 300, 200)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "y_test = np.concatenate((np.ones(len(X1_test_1)), np.zeros(len(X1_test_0))), axis = 0)\n",
    "print(X1_test.shape)\n",
    "print(X2_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.49      0.32      0.39      1000\n",
      "        1.0       0.49      0.66      0.57      1000\n",
      "\n",
      "avg / total       0.49      0.49      0.48      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_eva_predict = model_lstm2.predict([X1_test, X2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test, y_eva_predict>.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Reading english Data:', 63386)\n",
      "('Reading english Data:', 63386)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    63340\n",
      "True         3\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main_keras.py:207: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_en'] = df_pairs_sample['en_article'].apply(doc2vec_en)\n",
      "main_keras.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_jp'] = df_pairs_sample['jp_article'].apply(doc2vec_jp)\n",
      "main_keras.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_en'] = df_pairs_sample['word2vec_en'].apply(padding)\n",
      "main_keras.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_jp'] = df_pairs_sample['word2vec_jp'].apply(padding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 1 position: [4868]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main_keras.py:273: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ma..., inputs=[<tf.Tenso...)`\n",
      "  model_lstm2 = Model(input=[input_1, input_2], output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 82s - loss: 0.6932 - acc: 0.4914 - val_loss: 0.7058 - val_acc: 0.4525\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 75s - loss: 0.6889 - acc: 0.5187 - val_loss: 0.7461 - val_acc: 0.4505\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 74s - loss: 0.6816 - acc: 0.5265 - val_loss: 0.7568 - val_acc: 0.4730\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 72s - loss: 0.6633 - acc: 0.5576 - val_loss: 0.8104 - val_acc: 0.4960\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 72s - loss: 0.6500 - acc: 0.5737 - val_loss: 0.7767 - val_acc: 0.4920\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 74s - loss: 0.6367 - acc: 0.5836 - val_loss: 0.8485 - val_acc: 0.4815\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6311 - acc: 0.5835 - val_loss: 0.8296 - val_acc: 0.4860\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6584 - acc: 0.5851 - val_loss: 0.7874 - val_acc: 0.4705\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6332 - acc: 0.5846 - val_loss: 0.8162 - val_acc: 0.4745\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6286 - acc: 0.5941 - val_loss: 0.8369 - val_acc: 0.4630\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 71s - loss: 0.6246 - acc: 0.5944 - val_loss: 0.8269 - val_acc: 0.4530\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6226 - acc: 0.5954 - val_loss: 0.9225 - val_acc: 0.4475\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6408 - acc: 0.5823 - val_loss: 0.7939 - val_acc: 0.4685\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6495 - acc: 0.5691 - val_loss: 0.9434 - val_acc: 0.4640\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6303 - acc: 0.5889 - val_loss: 0.9407 - val_acc: 0.4465\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6263 - acc: 0.5980 - val_loss: 0.9821 - val_acc: 0.4645\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6238 - acc: 0.5961 - val_loss: 0.9573 - val_acc: 0.4460\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6263 - acc: 0.5960 - val_loss: 0.9547 - val_acc: 0.4575\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6196 - acc: 0.6000 - val_loss: 1.0181 - val_acc: 0.4420\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6145 - acc: 0.6055 - val_loss: 1.0523 - val_acc: 0.4490\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6186 - acc: 0.6041 - val_loss: 0.9684 - val_acc: 0.4405\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6128 - acc: 0.6094 - val_loss: 1.0387 - val_acc: 0.4305\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6390 - acc: 0.5966 - val_loss: 0.9870 - val_acc: 0.4320\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6239 - acc: 0.5920 - val_loss: 0.9853 - val_acc: 0.4360\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6071 - acc: 0.6142 - val_loss: 1.0435 - val_acc: 0.4385\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6054 - acc: 0.6119 - val_loss: 1.0848 - val_acc: 0.4250\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6018 - acc: 0.6165 - val_loss: 1.2025 - val_acc: 0.3900\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5993 - acc: 0.6151 - val_loss: 1.2209 - val_acc: 0.4260\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5996 - acc: 0.6183 - val_loss: 1.2091 - val_acc: 0.4245\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 68s - loss: 0.5985 - acc: 0.6186 - val_loss: 1.2118 - val_acc: 0.4335\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5933 - acc: 0.6285 - val_loss: 1.3265 - val_acc: 0.4785\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6033 - acc: 0.6166 - val_loss: 1.1885 - val_acc: 0.4175\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6038 - acc: 0.6085 - val_loss: 1.2008 - val_acc: 0.4270\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5997 - acc: 0.6132 - val_loss: 1.2752 - val_acc: 0.4195\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6003 - acc: 0.6078 - val_loss: 1.2538 - val_acc: 0.4315\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6264 - acc: 0.5811 - val_loss: 1.2415 - val_acc: 0.4285\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 68s - loss: 0.6095 - acc: 0.5966 - val_loss: 1.3397 - val_acc: 0.4290\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.5954 - acc: 0.6154 - val_loss: 1.3541 - val_acc: 0.4145\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.5951 - acc: 0.6134 - val_loss: 1.2977 - val_acc: 0.4310\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 68s - loss: 0.5961 - acc: 0.6109 - val_loss: 1.3657 - val_acc: 0.4335\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.6076 - acc: 0.5962 - val_loss: 1.3643 - val_acc: 0.4310\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.6153 - acc: 0.5936 - val_loss: 1.3078 - val_acc: 0.4125\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5981 - acc: 0.6090 - val_loss: 1.4794 - val_acc: 0.4195\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5881 - acc: 0.6240 - val_loss: 1.3813 - val_acc: 0.4130\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 68s - loss: 0.5853 - acc: 0.6228 - val_loss: 1.5412 - val_acc: 0.4190\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 68s - loss: 0.5838 - acc: 0.6276 - val_loss: 1.6289 - val_acc: 0.4095\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 70s - loss: 0.5838 - acc: 0.6275 - val_loss: 1.4332 - val_acc: 0.4320\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5751 - acc: 0.6429 - val_loss: 1.3026 - val_acc: 0.4210\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5853 - acc: 0.6260 - val_loss: 1.3486 - val_acc: 0.4105\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 69s - loss: 0.5821 - acc: 0.6329 - val_loss: 1.4713 - val_acc: 0.4330\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't pickle module objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/home/liuenda/Workspace/cas-keras/main_keras.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mpath_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hist_lstm2_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m     \u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROTO\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mListType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mListType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mListType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mListType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMARK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/copy_reg.pyc\u001b[0m in \u001b[0;36m_reduce_ex\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"can't pickle %s objects\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle module objects"
     ]
    }
   ],
   "source": [
    "run main_keras.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.40      0.28      0.33      1000\n",
      "        1.0       0.45      0.59      0.51      1000\n",
      "\n",
      "avg / total       0.43      0.43      0.42      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_eva_predict = model_lstm2.predict([X1_test, X2_test])\n",
    "print(classification_report(y_test, y_eva_predict>.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.43005243,  0.52353752,  0.52349687, ...,  0.52324378,\n",
       "        0.48257449,  0.1201562 ], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eva_predict[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.49137500000000001,\n",
       "  0.51875000000000004,\n",
       "  0.52649999999999997,\n",
       "  0.55762500000000004,\n",
       "  0.57374999999999998,\n",
       "  0.58362499999999995,\n",
       "  0.58350000000000002,\n",
       "  0.58512500000000001,\n",
       "  0.58462499999999995,\n",
       "  0.59412500000000001,\n",
       "  0.59437499999999999,\n",
       "  0.59537499999999999,\n",
       "  0.58225000000000005,\n",
       "  0.56912499999999999,\n",
       "  0.58887500000000004,\n",
       "  0.59799999999999998,\n",
       "  0.59612500000000002,\n",
       "  0.59599999999999997,\n",
       "  0.59999999999999998,\n",
       "  0.60550000000000004,\n",
       "  0.60412500000000002,\n",
       "  0.609375,\n",
       "  0.59662499999999996,\n",
       "  0.59199999999999997,\n",
       "  0.61424999999999996,\n",
       "  0.61187499999999995,\n",
       "  0.61650000000000005,\n",
       "  0.61512500000000003,\n",
       "  0.61824999999999997,\n",
       "  0.61862499999999998,\n",
       "  0.62849999999999995,\n",
       "  0.61662499999999998,\n",
       "  0.60850000000000004,\n",
       "  0.61324999999999996,\n",
       "  0.60775000000000001,\n",
       "  0.581125,\n",
       "  0.59662499999999996,\n",
       "  0.61537500000000001,\n",
       "  0.613375,\n",
       "  0.61087499999999995,\n",
       "  0.59624999999999995,\n",
       "  0.59362499999999996,\n",
       "  0.60899999999999999,\n",
       "  0.624,\n",
       "  0.62275000000000003,\n",
       "  0.62762499999999999,\n",
       "  0.62749999999999995,\n",
       "  0.64287499999999997,\n",
       "  0.626,\n",
       "  0.63287499999999997],\n",
       " 'loss': [0.69320144271850581,\n",
       "  0.68886063432693478,\n",
       "  0.68158361148834223,\n",
       "  0.6632558679580689,\n",
       "  0.64999859714508057,\n",
       "  0.63667856693267821,\n",
       "  0.6311110625267029,\n",
       "  0.65838728618621822,\n",
       "  0.63323669672012328,\n",
       "  0.62856693840026856,\n",
       "  0.6246405525207519,\n",
       "  0.62255440473556523,\n",
       "  0.64079170227050786,\n",
       "  0.64946638965606684,\n",
       "  0.63027391099929808,\n",
       "  0.62626634502410894,\n",
       "  0.62376322031021114,\n",
       "  0.62632727336883542,\n",
       "  0.6195556898117065,\n",
       "  0.6144901819229126,\n",
       "  0.61861417007446284,\n",
       "  0.61275748062133784,\n",
       "  0.63902948188781739,\n",
       "  0.62392177200317378,\n",
       "  0.60714437866210935,\n",
       "  0.60542545461654662,\n",
       "  0.60184864473342892,\n",
       "  0.59930062866210942,\n",
       "  0.5996273245811462,\n",
       "  0.59851735591888433,\n",
       "  0.5933008985519409,\n",
       "  0.60331707859039307,\n",
       "  0.60381507301330561,\n",
       "  0.59973499011993403,\n",
       "  0.60027404880523683,\n",
       "  0.62641422843933103,\n",
       "  0.60947470760345457,\n",
       "  0.59537311649322511,\n",
       "  0.59509035253524778,\n",
       "  0.59614702129364017,\n",
       "  0.60763711547851562,\n",
       "  0.61530770015716552,\n",
       "  0.59806580257415776,\n",
       "  0.58812296867370606,\n",
       "  0.58528755187988279,\n",
       "  0.58376430225372311,\n",
       "  0.58378804492950442,\n",
       "  0.57512019824981686,\n",
       "  0.58525325775146486,\n",
       "  0.58205349206924439],\n",
       " 'val_acc': [0.45249999904632571,\n",
       "  0.4505000014305115,\n",
       "  0.47300000405311582,\n",
       "  0.49600000357627871,\n",
       "  0.49200000047683717,\n",
       "  0.48150000143051147,\n",
       "  0.48600000238418578,\n",
       "  0.47050000131130221,\n",
       "  0.47449999952316285,\n",
       "  0.46300000238418582,\n",
       "  0.45300000166893006,\n",
       "  0.44750000023841857,\n",
       "  0.46849999952316285,\n",
       "  0.46400000238418582,\n",
       "  0.44650000095367431,\n",
       "  0.46450000095367433,\n",
       "  0.44600000143051149,\n",
       "  0.45750000000000002,\n",
       "  0.44200000131130218,\n",
       "  0.44900000274181368,\n",
       "  0.4405000023841858,\n",
       "  0.43050000047683717,\n",
       "  0.43200000190734861,\n",
       "  0.43600000011920931,\n",
       "  0.43850000238418579,\n",
       "  0.42499999988079074,\n",
       "  0.39000000000000001,\n",
       "  0.42600000429153445,\n",
       "  0.42450000166893004,\n",
       "  0.43350000131130217,\n",
       "  0.47850000381469726,\n",
       "  0.41750000095367434,\n",
       "  0.42700000143051148,\n",
       "  0.4195000002384186,\n",
       "  0.43149999952316287,\n",
       "  0.42850000476837158,\n",
       "  0.42900000119209292,\n",
       "  0.41450000238418577,\n",
       "  0.43100000405311584,\n",
       "  0.43350000286102297,\n",
       "  0.43100000154972079,\n",
       "  0.41250000214576721,\n",
       "  0.4195000002384186,\n",
       "  0.41300000190734865,\n",
       "  0.41900000202655791,\n",
       "  0.40950000190734864,\n",
       "  0.43200000083446505,\n",
       "  0.42099999928474424,\n",
       "  0.41050000143051146,\n",
       "  0.43300000047683718],\n",
       " 'val_loss': [0.70577453184127803,\n",
       "  0.74610202550888061,\n",
       "  0.75680347681045534,\n",
       "  0.81037764406204227,\n",
       "  0.77673555517196657,\n",
       "  0.84850609540939326,\n",
       "  0.82961297178268434,\n",
       "  0.78739346313476566,\n",
       "  0.8162432227134705,\n",
       "  0.83689403247833249,\n",
       "  0.82687836742401122,\n",
       "  0.92245899295806888,\n",
       "  0.79394653177261354,\n",
       "  0.94336384010314944,\n",
       "  0.94074716281890869,\n",
       "  0.98211404800415036,\n",
       "  0.95731424999237058,\n",
       "  0.95474103927612308,\n",
       "  1.0181064853668214,\n",
       "  1.0523095798492432,\n",
       "  0.9684078817367554,\n",
       "  1.0386735687255859,\n",
       "  0.98702313995361324,\n",
       "  0.98525243663787843,\n",
       "  1.0434988050460816,\n",
       "  1.0847878971099854,\n",
       "  1.2025455713272095,\n",
       "  1.2209227819442749,\n",
       "  1.2090815029144286,\n",
       "  1.2118327589035034,\n",
       "  1.3264845895767212,\n",
       "  1.1884630212783813,\n",
       "  1.2007983045578003,\n",
       "  1.2751914262771606,\n",
       "  1.2537969141006469,\n",
       "  1.2414872150421143,\n",
       "  1.3396885671615602,\n",
       "  1.3540934982299804,\n",
       "  1.2977121725082397,\n",
       "  1.3657266960144043,\n",
       "  1.3643183565139771,\n",
       "  1.3077669563293457,\n",
       "  1.4793569450378419,\n",
       "  1.3813088541030885,\n",
       "  1.5411620235443115,\n",
       "  1.628905460357666,\n",
       "  1.4331693029403687,\n",
       "  1.3026067991256713,\n",
       "  1.3486393251419067,\n",
       "  1.4713486671447753]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the ranking results with respect to real pairs\n",
    "Defaulty, projection1 should be JP\n",
    "Whiile, projection2 should be EN->JP\n",
    "\"\"\"\n",
    "def find_ranking(projection1, projection2, dlmodel):\n",
    "\tsim_results = []\n",
    "\trank_results = []\n",
    "\n",
    "\t# Iterate each of the ariticle from projection1 (999) as proj1\n",
    "\t# Calculate the simialrity of proj1 with all ariticles in projection2 (999)\n",
    "\tfor i, proj1 in enumerate(projection1):\n",
    "\t\tprint(\"Find answer for doc.\", i)\n",
    "\t\tproj1_tile = np.tile(proj1, (len(projection2),1,1))\n",
    "# \t\tprint proj1_tile.shape\n",
    "# \t\tprint proj1_tile\n",
    "# \t\tprint proj1.shape\n",
    "\t\tsim = dlmodel.predict([proj1_tile, projection2])[:,0]\n",
    "# \t\tprint sim\n",
    "\t\trank = pd.Series(sim).rank(ascending = False)[i]\n",
    "\t\tsim_results.append(sim)\n",
    "\t\trank_results.append(rank)\n",
    "\t\tprint rank\n",
    "\n",
    "\t# sim_results contains 999*999 similairty matrix\n",
    "\treturn sim_results, rank_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Find answer for doc.', 0)\n",
      "147.0\n",
      "('Find answer for doc.', 1)\n",
      "291.0\n",
      "('Find answer for doc.', 2)\n",
      "498.0\n",
      "('Find answer for doc.', 3)\n",
      "450.0\n",
      "('Find answer for doc.', 4)\n",
      "789.5\n",
      "('Find answer for doc.', 5)\n",
      "821.0\n",
      "('Find answer for doc.', 6)\n",
      "795.0\n",
      "('Find answer for doc.', 7)\n",
      "743.0\n",
      "('Find answer for doc.', 8)\n",
      "616.0\n",
      "('Find answer for doc.', 9)\n",
      "372.5\n",
      "('Find answer for doc.', 10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-f46e567c46f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_ranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_test_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_test_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_lstm2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-cf9c413c0c80>\u001b[0m in \u001b[0;36mfind_ranking\u001b[0;34m(projection1, projection2, dlmodel)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#               print proj1_tile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#               print proj1.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproj1_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#               print sim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1585\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1210\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a = find_ranking(X1_test_1[:,:,:], X2_test_1, model_lstm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 根本学习就不成功！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09626271,  0.00656432, -0.20799024, ...,  0.07659759,\n",
       "        -0.13206814,  0.06503551],\n",
       "       [ 0.26123866,  0.01382056,  0.00648347, ...,  0.22894549,\n",
       "        -0.13786219, -0.12912716],\n",
       "       [ 0.03575521, -0.23474377, -0.02440281, ...,  0.09979937,\n",
       "        -0.06005824, -0.07902404],\n",
       "       ..., \n",
       "       [ 0.23872878,  0.06416631,  0.07533237, ...,  0.24324439,\n",
       "        -0.31456584, -0.49234882],\n",
       "       [ 0.20270877,  0.07590064,  0.03888318, ...,  0.26487142,\n",
       "         0.10724627, -0.11777702],\n",
       "       [ 0.09335291,  0.28491914, -0.0272277 , ...,  0.1573166 ,\n",
       "        -0.08874487,  0.14690572]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train[4001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.2035594 , -0.17032957,  0.13630773, ..., -0.15776674,\n",
       "         -0.05689833,  0.0529804 ],\n",
       "        [-0.12451203, -0.3213411 , -0.20498073, ...,  0.20521204,\n",
       "         -0.07325041,  0.27277657],\n",
       "        [-0.06744123, -0.16009675,  0.17753807, ..., -0.01309109,\n",
       "          0.04884958,  0.13856369],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.3649289 ,  0.02026587,  0.17083779, ...,  0.07582411,\n",
       "          0.04643445, -0.05549098],\n",
       "        [-0.05416851, -0.13047245,  0.0578197 , ..., -0.0097992 ,\n",
       "         -0.12715523, -0.60661757],\n",
       "        [-0.2792525 , -0.26107585, -0.02758151, ..., -0.04302026,\n",
       "         -0.35708189, -0.30353752],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.37992465, -0.16320978,  0.21647577, ..., -0.07380453,\n",
       "          0.2222032 ,  0.00801729],\n",
       "        [ 0.21176256, -0.23381241, -0.07060514, ..., -0.02609797,\n",
       "          0.03988031, -0.24141885],\n",
       "        [-0.46719864, -0.04468558, -0.2491429 , ...,  0.03507265,\n",
       "         -0.14025956,  0.08898471],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ..., \n",
       "       [[-0.08517134,  0.20535553,  0.12593433, ...,  0.07032266,\n",
       "          0.24877806, -0.00124323],\n",
       "        [ 0.16721793,  0.14109521, -0.0099226 , ..., -0.21902807,\n",
       "          0.02923114, -0.00869101],\n",
       "        [ 0.27545041,  0.0250656 ,  0.08259386, ...,  0.01894636,\n",
       "         -0.07830112,  0.01383533],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.2035594 , -0.17032957,  0.13630773, ..., -0.15776674,\n",
       "         -0.05689833,  0.0529804 ],\n",
       "        [-0.07113036, -0.37713   ,  0.07353979, ..., -0.06985579,\n",
       "          0.09448376,  0.17041913],\n",
       "        [ 0.14587575, -0.03462216,  0.05109059, ...,  0.19641764,\n",
       "         -0.28392082,  0.08958188],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.2035594 , -0.17032957,  0.13630773, ..., -0.15776674,\n",
       "         -0.05689833,  0.0529804 ],\n",
       "        [ 0.2765663 , -0.09103319,  0.25488484, ...,  0.26420298,\n",
       "         -0.07610356, -0.03254816],\n",
       "        [ 0.15495408, -0.58930755,  0.30961218, ...,  0.27981713,\n",
       "          0.06970363, -0.20249979],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[3999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.46130753e-02,   9.54257995e-02,   2.01974958e-01,\n",
       "        -1.88879788e-01,   1.49911344e-01,   7.41543472e-02,\n",
       "         2.80297130e-01,   2.06199691e-01,   1.05131559e-01,\n",
       "        -2.28328779e-01,  -1.71689972e-01,  -1.40397131e-01,\n",
       "         1.43209575e-02,  -1.47004157e-01,   4.54984196e-02,\n",
       "        -2.13625193e-01,  -9.76795554e-02,   4.28388566e-01,\n",
       "        -8.19410384e-02,  -8.34822282e-02,  -1.17317043e-01,\n",
       "         3.29226926e-02,   5.09187579e-02,   7.38451853e-02,\n",
       "        -3.33025306e-02,  -4.29547042e-01,  -7.40184113e-02,\n",
       "        -2.97672898e-01,  -1.95241719e-01,  -1.98570509e-02,\n",
       "         5.34500889e-02,  -1.96851701e-01,   1.98751673e-01,\n",
       "         1.33167773e-01,   1.65657312e-01,   3.39270979e-02,\n",
       "         2.12546214e-01,  -6.87375665e-02,   1.09114878e-01,\n",
       "         2.53317505e-01,   3.50452997e-02,   1.12259544e-01,\n",
       "        -2.83444434e-01,   2.62120292e-02,   3.69520895e-02,\n",
       "         1.59424357e-02,  -2.65563745e-02,  -1.95016041e-01,\n",
       "        -2.47364923e-01,  -4.62418385e-02,   8.00507069e-02,\n",
       "        -2.52563566e-01,  -5.62832616e-02,  -6.78401589e-02,\n",
       "        -2.08042502e-01,   1.66517884e-01,   1.11643799e-01,\n",
       "         2.54404962e-01,   1.22635894e-01,   2.80075341e-01,\n",
       "        -3.41233285e-03,  -2.43205056e-01,   1.08223647e-01,\n",
       "        -9.83586758e-02,  -2.12439269e-01,   4.17900970e-03,\n",
       "        -2.77497172e-01,   1.07707947e-01,  -1.28009647e-01,\n",
       "        -6.65610731e-02,   2.13050097e-01,  -1.15425296e-01,\n",
       "        -3.26132625e-01,  -6.32183701e-02,  -1.13583468e-01,\n",
       "        -2.16432601e-01,  -2.07547560e-01,   8.61282349e-02,\n",
       "        -2.32072785e-01,  -8.21935385e-02,  -3.34710032e-02,\n",
       "        -4.15929817e-02,  -8.09755176e-02,  -1.35908425e-01,\n",
       "         2.19252571e-01,   1.74458608e-01,  -4.01258357e-02,\n",
       "         4.40933816e-02,  -2.63489723e-01,  -6.49405494e-02,\n",
       "         9.06346962e-02,   8.32978934e-02,  -4.21618760e-01,\n",
       "        -5.55608794e-02,  -1.32004455e-01,   8.07709321e-02,\n",
       "        -1.25579834e-01,  -2.57528543e-01,   8.09331909e-02,\n",
       "         2.11322248e-01,  -2.38200352e-02,   1.16971225e-01,\n",
       "         1.43899858e-01,   7.31083937e-03,  -3.14066969e-02,\n",
       "         2.37127952e-02,  -1.52738735e-01,  -1.00707710e-01,\n",
       "         2.15320778e-03,   2.11684421e-01,  -2.46896088e-01,\n",
       "         2.53208522e-02,  -3.82295668e-01,   1.94371995e-02,\n",
       "        -2.38617629e-01,  -1.69273302e-01,   1.02492638e-01,\n",
       "         5.49611524e-02,   4.65595052e-02,  -1.89020962e-01,\n",
       "         1.66469961e-01,   1.75267041e-01,  -3.65577079e-02,\n",
       "        -1.49122793e-02,   7.74850976e-03,   1.15291931e-01,\n",
       "        -1.76123723e-01,  -1.18053012e-01,  -5.47455437e-03,\n",
       "        -1.23924553e-01,  -2.09526554e-01,  -1.53991152e-02,\n",
       "        -1.71262071e-01,  -2.92435378e-01,   8.77041742e-02,\n",
       "        -1.82932645e-01,   5.62726753e-03,  -3.13690484e-01,\n",
       "         1.69287011e-01,  -1.88464597e-01,  -1.44499674e-01,\n",
       "         1.03135288e-01,   1.13957837e-01,  -9.31097046e-02,\n",
       "         2.45047554e-01,   4.10623429e-03,  -1.65068492e-01,\n",
       "        -6.49256334e-02,  -3.47099006e-02,   1.45082802e-01,\n",
       "        -1.02479771e-01,   1.98218673e-01,   2.01275691e-01,\n",
       "        -5.79555444e-02,  -4.03605402e-02,  -3.28151248e-02,\n",
       "        -2.43347108e-01,  -1.96908303e-02,   5.80059886e-02,\n",
       "         2.27364346e-01,   1.76700242e-02,   8.12432822e-03,\n",
       "         1.52011350e-01,   1.19443178e-01,  -8.04160386e-02,\n",
       "         9.82611924e-02,  -1.28491372e-02,  -3.82230669e-01,\n",
       "        -8.61649960e-02,   5.95518854e-03,  -2.43256941e-01,\n",
       "         1.02265468e-02,   8.65914579e-03,   4.22651917e-02,\n",
       "        -1.07977241e-01,   1.35203823e-01,  -2.04340950e-01,\n",
       "        -1.08679496e-01,  -1.65501405e-02,   1.54196754e-01,\n",
       "        -3.68039869e-02,   9.16271061e-02,   2.00911507e-01,\n",
       "         2.85099477e-01,  -2.16426104e-01,   3.26648429e-02,\n",
       "        -3.95247400e-01,  -2.10846588e-01,  -7.35367835e-02,\n",
       "        -2.61756610e-02,   2.65215002e-02,   9.04486701e-02,\n",
       "         2.79559374e-01,  -1.60725415e-01,   1.72031313e-01,\n",
       "        -4.21598088e-04,  -1.80436552e-01,   1.02300756e-01,\n",
       "        -1.00897588e-01,  -1.65765255e-03], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en[\"chinese\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>en_article</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>jp_article</th>\n",
       "      <th>similarity</th>\n",
       "      <th>dis_similarity</th>\n",
       "      <th>en_article_wrong</th>\n",
       "      <th>word2vec_en</th>\n",
       "      <th>word2vec_jp</th>\n",
       "      <th>padding_en</th>\n",
       "      <th>padding_jp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>u.s. commerce department seasonal adjust annua...</td>\n",
       "      <td>0</td>\n",
       "      <td>米 商務省 発表 する 建設 支出 以下 とおり 季節調整 年率 総 建設 支出 民間 部門...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>philippine will offer tender next year airport...</td>\n",
       "      <td>[[0.079418, -0.0698862, 0.0105229, 0.0433305, ...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.0794180035591, -0.0698861926794, 0.0105229...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>chinese budget smartphone maker xiaomi plan se...</td>\n",
       "      <td>1</td>\n",
       "      <td>中国 低価格 スマホ メーカー 小米科技 () 雷軍 董事長 以上 販売 する 計画 明らか...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>taiwanese bank have exposure loan company chin...</td>\n",
       "      <td>[[0.0946131, 0.0954258, 0.201975, -0.18888, 0....</td>\n",
       "      <td>[[0.364929, 0.0202659, 0.170838, 0.0298371, -0...</td>\n",
       "      <td>[[0.0946130752563, 0.095425799489, 0.201974958...</td>\n",
       "      <td>[[0.364928901196, 0.0202658716589, 0.170837789...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>samsung electronics co ltd fell more percent t...</td>\n",
       "      <td>2</td>\n",
       "      <td>ソウル 株式市場 サムスン電子 株価 超 下落 する 安値 付ける 一部 アナリスト ウォン...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bank canada should keep it key interest rate h...</td>\n",
       "      <td>[[0.111116, 0.163467, 0.173304, -0.21241, 0.19...</td>\n",
       "      <td>[[0.379925, -0.16321, 0.216476, -0.00105682, -...</td>\n",
       "      <td>[[0.111115589738, 0.163467362523, 0.1733036488...</td>\n",
       "      <td>[[0.379924654961, -0.163209781051, 0.216475769...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fiat deal gain full control chrysler group llc...</td>\n",
       "      <td>3</td>\n",
       "      <td>欧州 株式市場 イタリア 自動車 大手 FIAT 株価 一時 急伸 する 8月 以来 高値 ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>brazil incoming finance minister joaquim levy ...</td>\n",
       "      <td>[[0.252217, -0.149704, -0.000305933, 0.335273,...</td>\n",
       "      <td>[[0.27545, 0.0250656, 0.0825939, 0.136058, -0....</td>\n",
       "      <td>[[0.252217, -0.149704, -0.000305933, 0.335273,...</td>\n",
       "      <td>[[0.275450408459, 0.0250655952841, 0.082593858...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fiat share jump thursday it strike deal gain f...</td>\n",
       "      <td>4</td>\n",
       "      <td>欧州 株式市場 イタリア 自動車 大手 FIAT 株価 一時 急伸 する 8月 以来 高値 ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>u.s. employer add large number worker nearly y...</td>\n",
       "      <td>[[0.252217, -0.149704, -0.000305933, 0.335273,...</td>\n",
       "      <td>[[0.27545, 0.0250656, 0.0825939, 0.136058, -0....</td>\n",
       "      <td>[[0.252217, -0.149704, -0.000305933, 0.335273,...</td>\n",
       "      <td>[[0.275450408459, 0.0250655952841, 0.082593858...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>u.s. treasuries price rise thursday benchmark ...</td>\n",
       "      <td>5</td>\n",
       "      <td>カッコ 前 営業日 米 東部 時間 時分 前 営業日 終盤 米 東部 時間 時分 前 営業日...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>india central bank keep it key policy repo rat...</td>\n",
       "      <td>[[0.079418, -0.0698862, 0.0105229, 0.0433305, ...</td>\n",
       "      <td>[[-0.401097, -0.568938, -0.155227, 0.434545, -...</td>\n",
       "      <td>[[0.079418, -0.0698862, 0.0105229, 0.0433305, ...</td>\n",
       "      <td>[[-0.401097238064, -0.56893825531, -0.15522733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>auction detail see 3-year note</td>\n",
       "      <td>6</td>\n",
       "      <td>米財務省 銘柄 統合 入札 実施 する 発表 する 発行 いずれ 償還 1月 11月 11月</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sweden central bank keep it key interest rate ...</td>\n",
       "      <td>[[0.145339, 0.0967358, -0.290555, -0.157721, 0...</td>\n",
       "      <td>[[-0.440666, 0.610078, -0.0983196, 0.801558, 0...</td>\n",
       "      <td>[[0.145339399576, 0.0967358276248, -0.29055538...</td>\n",
       "      <td>[[-0.440665841103, 0.610077679157, -0.09831961...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>brent crude sink barrel thursday libya prepare...</td>\n",
       "      <td>7</td>\n",
       "      <td>原油 先物 相場 リビア 大 規模 油田 生産 停止 要因 なる いる 抗議活動 休止 する...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>asset manager credit suisse hedging griffo be ...</td>\n",
       "      <td>[[-0.00470701, -0.396765, -0.322486, -0.53076,...</td>\n",
       "      <td>[[0.00253854, -0.129143, -0.126948, 0.0700992,...</td>\n",
       "      <td>[[-0.00470701, -0.396765, -0.322486, -0.53076,...</td>\n",
       "      <td>[[0.00253854179755, -0.129142984748, -0.126948...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>gauge u.s. factory activity hold 2-1/2-year hi...</td>\n",
       "      <td>8</td>\n",
       "      <td>米 労働省 発表 する 12月 週 新規 失業保険 申請 件数 季節調整 前週 り 連続 減...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>* usd/cnh close ny trade 6.1370-6.1450 offshor...</td>\n",
       "      <td>[[0.258893, -0.240117, -0.39061, -0.180771, 0....</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.258893, -0.240117, -0.39061, -0.180771, 0....</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>work massive panama canal extension project ma...</td>\n",
       "      <td>9</td>\n",
       "      <td>パナマ運河 拡張 工事 めぐる 建設 会社 成る 企業 連合 パナマ運河 PC コスト 超過...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chipmaker altera corp be work intel corp combi...</td>\n",
       "      <td>[[-0.246409, -0.300402, 0.0540296, 0.0361169, ...</td>\n",
       "      <td>[[0.0367229, 0.154389, -0.430821, 0.336414, -0...</td>\n",
       "      <td>[[-0.246409475803, -0.300402313471, 0.05402963...</td>\n",
       "      <td>[[0.0367229022086, 0.154389277101, -0.43082135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>increase december car sale france spain prompt...</td>\n",
       "      <td>10</td>\n",
       "      <td>12月 フランス イタリア スペイン 自動車販売 台数 前年 同月 増加 する 欧州 自動車...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>president francois hollande brush aside questi...</td>\n",
       "      <td>[[0.0325002, 0.110915, -0.126051, -0.221096, 0...</td>\n",
       "      <td>[[-0.47501, 0.0407163, 0.111163, 0.451794, -0....</td>\n",
       "      <td>[[0.0325002, 0.110915, -0.126051, -0.221096, 0...</td>\n",
       "      <td>[[-0.475010246038, 0.0407162643969, 0.11116266...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>federal reserve provide liquidity foreign cent...</td>\n",
       "      <td>11</td>\n",
       "      <td>米 連邦準備理事会 FRB 傘下 ニューヨーク連銀 発表 する 最新 週間 データ よる 通...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>share italy third-biggest bank monte dei pasch...</td>\n",
       "      <td>[[0.0761386, 0.273143, -0.42036, -0.0670243, -...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.0761386305094, 0.27314338088, -0.420359730...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>new car sale spain rise percent year early car...</td>\n",
       "      <td>12</td>\n",
       "      <td>スペイン 自動車 業界団体 よる 新車 販売 政府 補助 支援 する 前年 なる 減少 する...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>seoul share rebound thursday snap day lose str...</td>\n",
       "      <td>[[-0.0148091, 0.0937563, -0.266831, -0.100736,...</td>\n",
       "      <td>[[-0.101784, 0.297449, -0.0359539, -0.183187, ...</td>\n",
       "      <td>[[-0.0148091288283, 0.0937562733889, -0.266831...</td>\n",
       "      <td>[[-0.10178424418, 0.297449380159, -0.035953946...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>south korean auto maker hyundai motor co kia m...</td>\n",
       "      <td>13</td>\n",
       "      <td>韓国 自動車メーカー 現代自動車 系列 起亜自動車 世界 販売台数 両社 合計 前年 目標 ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>average new home price china major city drop p...</td>\n",
       "      <td>[[-0.0864343, -0.392118, -0.265892, 0.0306064,...</td>\n",
       "      <td>[[-0.133516, -0.0476626, -0.0501251, -0.141976...</td>\n",
       "      <td>[[-0.0864343, -0.392118, -0.265892, 0.0306064,...</td>\n",
       "      <td>[[-0.133516088128, -0.0476626008749, -0.050125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>u.s. manufacturing end year high note grow dec...</td>\n",
       "      <td>14</td>\n",
       "      <td>Markit 発表 する 12月 米 製造業 購買担当者景気指数 PM 改定 1月 以来 高...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>greece economy shrank annual pace percent seco...</td>\n",
       "      <td>[[0.079418, -0.0698862, 0.0105229, 0.0433305, ...</td>\n",
       "      <td>[[-0.129796, 0.467595, -0.160948, 0.13798, -0....</td>\n",
       "      <td>[[0.0794180035591, -0.0698861926794, 0.0105229...</td>\n",
       "      <td>[[-0.12979593873, 0.467594563961, -0.160947903...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>oil price fell more thursday libya prepare res...</td>\n",
       "      <td>15</td>\n",
       "      <td>原油 先物 相場 リビア 大 規模 油田 生産 停止 要因 なる いる 抗議活動 休止 する...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>turkish prime minister tayyip erdogan accuse p...</td>\n",
       "      <td>[[-0.122633, -0.213171, -0.236308, -0.440996, ...</td>\n",
       "      <td>[[0.00253854, -0.129143, -0.126948, 0.0700992,...</td>\n",
       "      <td>[[-0.122633, -0.213171, -0.236308, -0.440996, ...</td>\n",
       "      <td>[[0.00253854179755, -0.129142984748, -0.126948...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>freddie mac average u.s. mortgage rate percent...</td>\n",
       "      <td>16</td>\n",
       "      <td>米 連邦 住宅 貸付 抵当 公社 フレディマック 調査 住宅ローン 金利 手数料 以下 通り...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>be discussion high level u.s. government how u...</td>\n",
       "      <td>[[0.348366, -0.0344246, -0.0886954, -0.606096,...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.348365992308, -0.034424636513, -0.08869536...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>u.s. construction spending rise it high level ...</td>\n",
       "      <td>17</td>\n",
       "      <td>米 商務省 発表 する 11月 建設 支出 前 月 年率 3月 以来 高水準 公共 部門 減...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>australian share rise percent wednesday hover ...</td>\n",
       "      <td>[[0.079418, -0.0698862, 0.0105229, 0.0433305, ...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.0794180035591, -0.0698861926794, 0.0105229...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>russia world big oil producer raise output pos...</td>\n",
       "      <td>18</td>\n",
       "      <td>ロシア エネルギー省 発表 する データ よる 石油 生産量 日量 ソビエト連邦 崩壊 最 ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>canadian have die avian influenza return trip ...</td>\n",
       "      <td>[[0.0481659, -0.0320038, 0.00198885, -0.044975...</td>\n",
       "      <td>[[0.17937, 0.0217469, -0.00774201, -0.275233, ...</td>\n",
       "      <td>[[0.0481659, -0.0320038, 0.00198885, -0.044975...</td>\n",
       "      <td>[[0.179370418191, 0.0217469427735, -0.00774200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>morning fix</td>\n",
       "      <td>19</td>\n",
       "      <td>ロンドン 市場 午後 値 決め 以下 通り ドル オンス 午後 ドル 午前 ドル</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>former french president nicolas sarkozy be pla...</td>\n",
       "      <td>[[0.0178536, -0.137507, -0.101738, -0.0816501,...</td>\n",
       "      <td>[[-0.0987584, -0.130326, 0.000382429, 0.453031...</td>\n",
       "      <td>[[0.0178535878658, -0.137506857514, -0.1017375...</td>\n",
       "      <td>[[-0.09875844419, -0.130326345563, 0.000382429...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>premium italian spanish bond offer benchmark g...</td>\n",
       "      <td>20</td>\n",
       "      <td>カッコ 先物 欧州 市場 前 営業日 終値 現物 前 営業日 終盤 時分 先物 清算 ユーロ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>crude price plunge further monday opec once ag...</td>\n",
       "      <td>[[0.172091, -0.28611, 0.0797486, -0.0987142, 0...</td>\n",
       "      <td>[[-0.401097, -0.568938, -0.155227, 0.434545, -...</td>\n",
       "      <td>[[0.172091, -0.28611, 0.0797486, -0.0987142, 0...</td>\n",
       "      <td>[[-0.401097238064, -0.56893825531, -0.15522733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>china yuan pull back slightly record high doll...</td>\n",
       "      <td>21</td>\n",
       "      <td>年明け 上海 外国為替市場 人民元 相場 引け 強含み 昨年 12月 付ける 最 高値 水準...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>european stock fell early trade monday resume ...</td>\n",
       "      <td>[[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...</td>\n",
       "      <td>[[-0.0356909, 0.0368742, -0.210699, -0.0758654...</td>\n",
       "      <td>[[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...</td>\n",
       "      <td>[[-0.0356909483671, 0.0368741899729, -0.210698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>italian carmaker fiat spa say wednesday it hav...</td>\n",
       "      <td>22</td>\n",
       "      <td>イタリア 自動車 大手 FIAT 傘下 米 クライスラー グループ 完全子会社 合意 する ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pro-russian separatist ukraine have agree prov...</td>\n",
       "      <td>[[0.14417, -0.206665, -0.0273102, 0.378012, 0....</td>\n",
       "      <td>[[0.0566944, 0.221398, -0.105711, -0.144083, -...</td>\n",
       "      <td>[[0.144170120358, -0.206664994359, -0.02731021...</td>\n",
       "      <td>[[0.0566943995655, 0.221398234367, -0.10571137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>brent crude rise barrel thursday decline oil s...</td>\n",
       "      <td>23</td>\n",
       "      <td>原油 先物 相場 リビア 大 規模 油田 生産 停止 要因 なる いる 抗議活動 休止 する...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>* share india essar oil ltd astrazeneca pharma...</td>\n",
       "      <td>[[-0.00470701, -0.396765, -0.322486, -0.53076,...</td>\n",
       "      <td>[[0.00253854, -0.129143, -0.126948, 0.0700992,...</td>\n",
       "      <td>[[-0.00470701325685, -0.396764904261, -0.32248...</td>\n",
       "      <td>[[0.00253854179755, -0.129142984748, -0.126948...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>china have approve more company list mainland ...</td>\n",
       "      <td>24</td>\n",
       "      <td>中国 再開 する 新規株式公開 承認 加速 する いる 国営 メディア 新た 上場 承認 す...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>european central bank keep interest rate recor...</td>\n",
       "      <td>[[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...</td>\n",
       "      <td>[[0.364929, 0.0202659, 0.170838, 0.0298371, -0...</td>\n",
       "      <td>[[-0.0418512448668, 0.0643166452646, 0.1977352...</td>\n",
       "      <td>[[0.364928901196, 0.0202658716589, 0.170837789...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>janet yellen come step close final approval fe...</td>\n",
       "      <td>25</td>\n",
       "      <td>米 上院 連邦準備理事会 FRB 次期 議長 指名 する イエレン 副議長 指名 承認 採決...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>time warner inc break financials it premium mo...</td>\n",
       "      <td>[[0.237401, 0.362354, -0.204507, -0.237838, 0....</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.237400531769, 0.362354069948, -0.204507112...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>libya hop resume oil production it large oilfi...</td>\n",
       "      <td>26</td>\n",
       "      <td>リビア 大 規模 油田 エル シャララ 生産 停止 要因 なる いる 抗議活動 デモ隊 活動...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mcdonald corp say it business have be hurt chi...</td>\n",
       "      <td>[[0.178806, 0.105778, -0.390584, 0.0331697, -0...</td>\n",
       "      <td>[[0.41208, -0.134387, -0.464477, -0.0422248, 0...</td>\n",
       "      <td>[[0.178805798292, 0.105777747929, -0.390584498...</td>\n",
       "      <td>[[0.412079721689, -0.134387344122, -0.46447741...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>italian carmaker fiat spa strike deal gain ful...</td>\n",
       "      <td>27</td>\n",
       "      <td>イタリア 自動車 大手 FIAT 傘下 米 クライスラー グループ 完全子会社 合意 する ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spec flip usd net long vs bln small net short ...</td>\n",
       "      <td>[[0.14417, -0.206665, -0.0273102, 0.378012, 0....</td>\n",
       "      <td>[[0.0566944, 0.221398, -0.105711, -0.144083, -...</td>\n",
       "      <td>[[0.14417, -0.206665, -0.0273102, 0.378012, 0....</td>\n",
       "      <td>[[0.0566943995655, 0.221398234367, -0.10571137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>number american file new claim unemployment be...</td>\n",
       "      <td>28</td>\n",
       "      <td>米 労働省 発表 する 12月 週 新規 失業保険 申請 件数 季節調整 前週 り 連続 減...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nokia surprise investor strong quarterly earni...</td>\n",
       "      <td>[[-0.0908237, 0.126889, -0.305503, -0.0270881,...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[-0.0908236578107, 0.126888975501, -0.3055031...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>britain top share index fell first trading day...</td>\n",
       "      <td>29</td>\n",
       "      <td>カッコ 前 営業日 総合 株価指数 ロンドン 終値 前 営業日 終値 ロンドン株式市場 反落...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>burger king be talk acquire canadian coffee do...</td>\n",
       "      <td>[[-0.137006, 0.105725, 0.115759, 0.41086, 0.34...</td>\n",
       "      <td>[[-0.401097, -0.568938, -0.155227, 0.434545, -...</td>\n",
       "      <td>[[-0.137006, 0.105725, 0.115759, 0.41086, 0.34...</td>\n",
       "      <td>[[-0.401097238064, -0.56893825531, -0.15522733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>4973</td>\n",
       "      <td>sharp emerge market sell-off appear subside th...</td>\n",
       "      <td>4973</td>\n",
       "      <td>外国為替市場 一時 加速 する いる 新興国通貨 下落 一服 する 中南米 通貨 上昇 する...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>quota allocate china dollar-dominated qualifie...</td>\n",
       "      <td>[[-0.181887, 0.187679, -0.0888446, -0.284644, ...</td>\n",
       "      <td>[[0.405083, 0.0932307, 0.823482, -0.377643, -0...</td>\n",
       "      <td>[[-0.181887, 0.187679, -0.0888446, -0.284644, ...</td>\n",
       "      <td>[[0.405083149672, 0.0932307168841, 0.823481857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>4974</td>\n",
       "      <td>taiwan financial market be closed jan feb chin...</td>\n",
       "      <td>4974</td>\n",
       "      <td>加権指数 前 営業日 売買 代金 前 営業日 終値 安 台湾 ドル 台湾 株式市場 1月 2...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>european central bank leave interest rate unch...</td>\n",
       "      <td>[[0.140891, 0.133389, -0.259482, -0.045965, 0....</td>\n",
       "      <td>[[0.232547, -0.519346, -0.280419, 0.204819, -0...</td>\n",
       "      <td>[[0.140890628099, 0.133389428258, -0.259482234...</td>\n",
       "      <td>[[0.232547223568, -0.519345581532, -0.28041857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>4975</td>\n",
       "      <td>wall street rebound open thursday previous ses...</td>\n",
       "      <td>4975</td>\n",
       "      <td>カッコ 前 営業日 ダウ 工業 株 ドル 米 東部 時間 時分 寄り付き 前 営業日 終値 ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>european central bank keep interest rate stead...</td>\n",
       "      <td>[[0.261115, 0.322767, -0.0312655, -0.031369, 0...</td>\n",
       "      <td>[[-0.401097, -0.568938, -0.155227, 0.434545, -...</td>\n",
       "      <td>[[0.26111510396, 0.322767198086, -0.0312655344...</td>\n",
       "      <td>[[-0.401097238064, -0.56893825531, -0.15522733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>4976</td>\n",
       "      <td>dollar rise basket currency thursday data show...</td>\n",
       "      <td>4976</td>\n",
       "      <td>日 終盤 年 終値 中盤 米 ニューヨーク 外為 市場 ドル 主要 通貨 上昇 する いる ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hundred hong kong police forcible remove kicki...</td>\n",
       "      <td>[[0.0591501, -0.00193826, -0.357213, 0.115154,...</td>\n",
       "      <td>[[0.0464822, -0.0669743, 0.123004, -0.122508, ...</td>\n",
       "      <td>[[0.0591500923038, -0.00193826400209, -0.35721...</td>\n",
       "      <td>[[0.046482168138, -0.0669743493199, 0.12300406...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>4977</td>\n",
       "      <td>amazon.com inc report close-to-expected sale c...</td>\n",
       "      <td>4977</td>\n",
       "      <td>米 オンライン 小売り 大手 アマゾン ドット コム 四半期 決算 純利益 市場 予想 下回...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>india market regulator monday partial reverse ...</td>\n",
       "      <td>[[-0.44227, 0.342926, 0.8082, -0.0856614, 0.25...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[-0.442269712687, 0.342925727367, 0.808200478...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>4978</td>\n",
       "      <td>jetblue airway wednesday report higher-than-ex...</td>\n",
       "      <td>4978</td>\n",
       "      <td>格安航空会社 米 JetBlue エア Waze 発表 する 四半期 決算 純利益 当たり ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>european central bank leave interest rate unch...</td>\n",
       "      <td>[[0.0560445, -0.0741857, -0.169413, 0.207105, ...</td>\n",
       "      <td>[[0.162483, -0.0885207, -0.177669, 0.0562228, ...</td>\n",
       "      <td>[[0.0560445040464, -0.0741856694221, -0.169412...</td>\n",
       "      <td>[[0.162483349442, -0.0885207280517, -0.1776690...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>4979</td>\n",
       "      <td>* custody holding treasury fell bln-ifr* large...</td>\n",
       "      <td>4979</td>\n",
       "      <td>外国 中銀 米国債 保有 昨 年月 以来 大幅 減少 FRB 米 連邦準備理事会 FRB 発...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>britain first increase interest rate financial...</td>\n",
       "      <td>[[0.060403, -0.21116, -0.112524, 0.418048, -0....</td>\n",
       "      <td>[[-0.448259, 0.418138, -0.0675213, 0.173515, -...</td>\n",
       "      <td>[[0.0604030229151, -0.211159676313, -0.1125241...</td>\n",
       "      <td>[[-0.448258966208, 0.418137580156, -0.06752131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>4980</td>\n",
       "      <td>swiss drugmaker roche report full-year profit ...</td>\n",
       "      <td>4980</td>\n",
       "      <td>スイス 製薬 大手 ロシュ ホールディング 発表 する 通期 決算 当たり 利益 前年 トム...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>* stop channel resistance trip close rally tow...</td>\n",
       "      <td>[[0.531755, 0.0465069, -0.280278, 0.0207437, -...</td>\n",
       "      <td>[[0.0230546, 0.134405, 0.276877, -0.215977, -0...</td>\n",
       "      <td>[[0.531755208969, 0.0465068519115, -0.28027793...</td>\n",
       "      <td>[[0.0230546388775, 0.134404763579, 0.276877105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>4981</td>\n",
       "      <td>u.s. president barack obama nod trade his annu...</td>\n",
       "      <td>4981</td>\n",
       "      <td>オバマ 米 大統領 一般教書演説 通商 協定 推進 する 姿勢 示す ため 議会 説得 する...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>u.s. house price rise will probable slow furth...</td>\n",
       "      <td>[[0.079418, -0.0698862, 0.0105229, 0.0433305, ...</td>\n",
       "      <td>[[0.393028, 0.0563531, -0.249674, -0.0347517, ...</td>\n",
       "      <td>[[0.079418, -0.0698862, 0.0105229, 0.0433305, ...</td>\n",
       "      <td>[[0.393028, 0.0563531, -0.249674, -0.0347517, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>4982</td>\n",
       "      <td>starbucks corp chief executive officer howard ...</td>\n",
       "      <td>4982</td>\n",
       "      <td>コーヒー チェーン 世界 最大手 米 スターバックス スタバ ハワード・シュルツ 最高経営責...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>federal reserve wednesday end it monthly bond ...</td>\n",
       "      <td>[[-0.0383446, 0.155325, 0.62502, 0.152943, 0.0...</td>\n",
       "      <td>[[0.386177, -0.115329, 0.18794, -0.0113484, -0...</td>\n",
       "      <td>[[-0.0383446030319, 0.155325382948, 0.62501972...</td>\n",
       "      <td>[[0.386177003384, -0.115329496562, 0.187939628...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>4983</td>\n",
       "      <td>china lenovo group be near deal buy google inc...</td>\n",
       "      <td>4983</td>\n",
       "      <td>中国 パソコン PC 大手 レノボ・グループ 連想集団 米 Google Inc. 携帯電話...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>follow be highlight remark economy monetary po...</td>\n",
       "      <td>[[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...</td>\n",
       "      <td>[[0.364929, 0.0202659, 0.170838, 0.0298371, -0...</td>\n",
       "      <td>[[-0.0418512448668, 0.0643166452646, 0.1977352...</td>\n",
       "      <td>[[0.364928901196, 0.0202658716589, 0.170837789...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>4984</td>\n",
       "      <td>detail u.s. treasury auction 13-week 26-week 5...</td>\n",
       "      <td>4984</td>\n",
       "      <td>米財務省 2月 短期 証券 ビル ビル ビル 入札 実施 する 発表 する</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bank england be not close raise interest rate ...</td>\n",
       "      <td>[[0.141714, 0.116061, -0.0546338, -0.234393, -...</td>\n",
       "      <td>[[-0.440666, 0.610078, -0.0983196, 0.801558, 0...</td>\n",
       "      <td>[[0.14171436429, 0.116061158478, -0.0546337664...</td>\n",
       "      <td>[[-0.440665841103, 0.610077679157, -0.09831961...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>4985</td>\n",
       "      <td>infineon expect demand microchip use car smart...</td>\n",
       "      <td>4985</td>\n",
       "      <td>ドイツ 半導体 メーカー インフィニオン・テクノロジーズ 発表 する 四半期 12月 営業利...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mexican economic growth will accelerate percen...</td>\n",
       "      <td>[[0.161593, 0.154688, 0.199677, 0.0963585, 0.1...</td>\n",
       "      <td>[[-0.0851713, 0.205356, 0.125934, -0.069173, -...</td>\n",
       "      <td>[[0.161593, 0.154688, 0.199677, 0.0963585, 0.1...</td>\n",
       "      <td>[[-0.0851713418961, 0.205355525017, 0.12593433...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>4986</td>\n",
       "      <td>reverse wednesday loss em pressure dissipated*...</td>\n",
       "      <td>4986</td>\n",
       "      <td>豪ドル 円 テクニカル分析 日 上回る 下降 トレンド 疑問符 新興国 不安 後退 する 中...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hong kong justice department hand investigatio...</td>\n",
       "      <td>[[-0.0972391, -0.0130996, 0.0103848, 0.196479,...</td>\n",
       "      <td>[[0.0193808, -0.0897314, 0.0394857, 0.224606, ...</td>\n",
       "      <td>[[-0.097239099443, -0.0130996406078, 0.0103847...</td>\n",
       "      <td>[[0.0193807650357, -0.0897313952446, 0.0394856...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>4987</td>\n",
       "      <td>amazon.com inc miss wall street profit estimat...</td>\n",
       "      <td>4987</td>\n",
       "      <td>米 オンライン 小売り 大手 アマゾン ドット コム 年末 商戦 四半期 決算 発表 する ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>congressional negotiator race tuesday wrap fin...</td>\n",
       "      <td>[[-0.44227, 0.342926, 0.8082, -0.0856614, 0.25...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[-0.442269712687, 0.342925727367, 0.808200478...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>4988</td>\n",
       "      <td>turkey be not consider sort capital control it...</td>\n",
       "      <td>4988</td>\n",
       "      <td>トルコ 政府高官 通貨 リラ 防衛 資本規制 検討 事項 挙がる いる 明らか する エルド...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>following bid merger acquisition disposal be r...</td>\n",
       "      <td>[[0.205812, -0.0776789, -0.0100262, 0.0848734,...</td>\n",
       "      <td>[[0.489795, -0.096977, -0.235068, -0.26358, 0....</td>\n",
       "      <td>[[0.205812335014, -0.0776788592339, -0.0100261...</td>\n",
       "      <td>[[0.489795058966, -0.096977032721, -0.23506839...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>4989</td>\n",
       "      <td>australian share fell percent thursday wall st...</td>\n",
       "      <td>4989</td>\n",
       "      <td>P AS 指数 大引け 安 GM 前 営業日 終値 高 シドニー 株式市場 反落 する 引け...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fiat say late wednesday it have call sharehold...</td>\n",
       "      <td>[[0.229783, 0.0867598, -0.154559, -0.0812089, ...</td>\n",
       "      <td>[[-0.308348, -0.29255, -0.608433, 0.365757, -0...</td>\n",
       "      <td>[[0.229783073068, 0.0867598429322, -0.15455880...</td>\n",
       "      <td>[[-0.308347702026, -0.292549997568, -0.6084330...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>4990</td>\n",
       "      <td>massive rate hike may have stall turkish lira ...</td>\n",
       "      <td>4990</td>\n",
       "      <td>トルコ 中央銀行 大幅 利上げ 通貨 リラ 下落 食い止める 中銀 独立 救う 可能性 ある...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>china key money rate slump four-month low week...</td>\n",
       "      <td>[[0.323224, 0.0206201, 0.0343361, -0.0548864, ...</td>\n",
       "      <td>[[0.489795, -0.096977, -0.235068, -0.26358, 0....</td>\n",
       "      <td>[[0.323224, 0.0206201, 0.0343361, -0.0548864, ...</td>\n",
       "      <td>[[0.489795058966, -0.096977032721, -0.23506839...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>4991</td>\n",
       "      <td>thailand army will increase number troop capit...</td>\n",
       "      <td>4991</td>\n",
       "      <td>タイ 来月 総選挙 控える 首都 バンコク 配備 する 兵士 数 増やす 明らか する 政府...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>european central bank unexpected cut interest ...</td>\n",
       "      <td>[[-0.00144556, -0.080357, -0.164071, 0.396402,...</td>\n",
       "      <td>[[-0.0549502, -0.123358, -0.252149, -0.161471,...</td>\n",
       "      <td>[[-0.00144556, -0.080357, -0.164071, 0.396402,...</td>\n",
       "      <td>[[-0.054950222373, -0.123358346522, -0.2521488...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>4992</td>\n",
       "      <td>recent outbreak bird flu china have cost poult...</td>\n",
       "      <td>4992</td>\n",
       "      <td>上海 証券 よる 中国 鳥インフルエンザ 流行 養鶏 農家 被害 出る おる 政府 新た 支...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>u.s. federal reserve be widely expect chop it ...</td>\n",
       "      <td>[[-0.0184049, -0.11853, -0.113298, -0.102021, ...</td>\n",
       "      <td>[[0.307846, 0.304336, -0.384274, 0.275885, -0....</td>\n",
       "      <td>[[-0.0184048675001, -0.118529520929, -0.113297...</td>\n",
       "      <td>[[0.307845532894, 0.30433639884, -0.3842737972...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>4993</td>\n",
       "      <td>italy benchmark 10-year debt cost fell their l...</td>\n",
       "      <td>4993</td>\n",
       "      <td>イタリア 実施 する 国債 入札 利回り 8月 以来 低 水準 なる 利回り ユーロ 導入 ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>president vladimir putin say wednesday it will...</td>\n",
       "      <td>[[-0.0289411, -0.00576493, -0.0602972, 0.43231...</td>\n",
       "      <td>[[0.0566944, 0.221398, -0.105711, -0.144083, -...</td>\n",
       "      <td>[[-0.0289410501719, -0.00576493237168, -0.0602...</td>\n",
       "      <td>[[0.0566943995655, 0.221398234367, -0.10571137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>4994</td>\n",
       "      <td>china ruling communist party have expel former...</td>\n",
       "      <td>4994</td>\n",
       "      <td>中国共産党 汚職 調査 担当 する 中央 規律 検査 委員会 収賄 権力 乱用 行為 及ぶ ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>china share end down slightly wednesday bevera...</td>\n",
       "      <td>[[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...</td>\n",
       "      <td>[[-0.264259, -0.00900147, 0.236856, 0.181937, ...</td>\n",
       "      <td>[[-0.0418512448668, 0.0643166452646, 0.1977352...</td>\n",
       "      <td>[[-0.264258921146, -0.00900147110224, 0.236855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>google inc quarterly revenue beat wall street ...</td>\n",
       "      <td>4995</td>\n",
       "      <td>インターネット 検索 大手 米 Google Inc. 発表 する 四半期 決算 広告 料金...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sprint corp have drop it bid acquire no u.s. c...</td>\n",
       "      <td>[[-0.184489, 0.108974, 0.432585, -0.259388, 0....</td>\n",
       "      <td>[[-0.073621, -0.46774, -0.243989, 0.10658, -0....</td>\n",
       "      <td>[[-0.184488818049, 0.108973585069, 0.432584911...</td>\n",
       "      <td>[[-0.0736210420728, -0.467739701271, -0.243988...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>turkey lira weaken dollar thursday late trade ...</td>\n",
       "      <td>4996</td>\n",
       "      <td>TRY 対ドル 前日 終盤 時点 近辺 近く 下落 する いる 投資家 引き続く 大幅 利上...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>federal reserve be risk it credibility not act...</td>\n",
       "      <td>[[0.205812, -0.0776789, -0.0100262, 0.0848734,...</td>\n",
       "      <td>[[-0.0531319, 0.0673207, 0.207877, 0.0881506, ...</td>\n",
       "      <td>[[0.205812335014, -0.0776788592339, -0.0100261...</td>\n",
       "      <td>[[-0.0531319342554, 0.067320741713, 0.20787686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>exxon mobil corp world large public trade oil ...</td>\n",
       "      <td>4997</td>\n",
       "      <td>米 石油 大手 エクソンモービル 発表 する 四半期 決算 生産量 減少 響く 利益 市場 ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>russia qualify next month soccer world cup hos...</td>\n",
       "      <td>[[0.0399386, 0.127008, -0.189544, -0.172313, -...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.0399386, 0.127008, -0.189544, -0.172313, -...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>visa inc chief executive urge u.s. merchant ba...</td>\n",
       "      <td>4998</td>\n",
       "      <td>米 クレジットカード 大手 ビザ 発表 する 四半期 12月 決算 クレジットカード 利用 ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>china create new job city first month year bri...</td>\n",
       "      <td>[[-0.383909, 0.376686, 0.0438472, 0.0146235, -...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[-0.383908867836, 0.376686453819, 0.043847214...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>singapore share hit five-month low thursday po...</td>\n",
       "      <td>4999</td>\n",
       "      <td>東南アジア 株式市場 軟化 する 取引 終える 米 量的緩和 縮小 継続 決定 受ける リス...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>u.s. company pick pace hiring march signal dam...</td>\n",
       "      <td>[[-0.00751844, -0.0674906, -0.356288, 0.060561...</td>\n",
       "      <td>[[0.261055, -0.130575, -0.261364, 0.0722576, 0...</td>\n",
       "      <td>[[-0.00751843955368, -0.0674905627966, -0.3562...</td>\n",
       "      <td>[[0.261055022478, -0.130575269461, -0.26136353...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>5000</td>\n",
       "      <td>symantec corp report percent fall quarterly re...</td>\n",
       "      <td>5000</td>\n",
       "      <td>米 セキュリティー ソフト 大手 Symantec 発表 する 四半期 12月 決算 売上高...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>china have exclude u.s.-based symantec corp ru...</td>\n",
       "      <td>[[0.211295, 0.339492, 0.265527, 0.210434, 0.02...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.211294844747, 0.339491575956, 0.2655267417...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>5001</td>\n",
       "      <td>northrop grumman corp maker surveillance drone...</td>\n",
       "      <td>5001</td>\n",
       "      <td>米 防衛 大手 ノースロップ・グラマン 発表 する 昨年 四半期 決算 純利益 当たり 前年...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nissan motor co unveil it new taxi london mond...</td>\n",
       "      <td>[[0.313289, 0.0940975, -0.0294598, 0.110512, 0...</td>\n",
       "      <td>[[0.203559, -0.17033, 0.136308, -0.0854052, -0...</td>\n",
       "      <td>[[0.313289284706, 0.094097495079, -0.029459763...</td>\n",
       "      <td>[[0.203559398651, -0.17032957077, 0.1363077312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>5002</td>\n",
       "      <td>author be reuters breakingviews columnist opin...</td>\n",
       "      <td>5002</td>\n",
       "      <td>シカゴ ロイター 米 Google Inc. 買収 する 携帯電話 端末 部門 モトローラ ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>singapore-listed frasers centrepoint ltd make ...</td>\n",
       "      <td>[[0.0817824, -0.07372, -0.377568, 0.0546247, -...</td>\n",
       "      <td>[[-0.728102, 0.445352, -0.220505, 0.212112, -0...</td>\n",
       "      <td>[[0.0817824, -0.07372, -0.377568, 0.0546247, -...</td>\n",
       "      <td>[[-0.728102147579, 0.445351630449, -0.22050540...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                         en_article  \\\n",
       "0              0  u.s. commerce department seasonal adjust annua...   \n",
       "1              1  chinese budget smartphone maker xiaomi plan se...   \n",
       "2              2  samsung electronics co ltd fell more percent t...   \n",
       "3              3  fiat deal gain full control chrysler group llc...   \n",
       "4              4  fiat share jump thursday it strike deal gain f...   \n",
       "5              5  u.s. treasuries price rise thursday benchmark ...   \n",
       "6              6                     auction detail see 3-year note   \n",
       "7              7  brent crude sink barrel thursday libya prepare...   \n",
       "8              8  gauge u.s. factory activity hold 2-1/2-year hi...   \n",
       "9              9  work massive panama canal extension project ma...   \n",
       "10            10  increase december car sale france spain prompt...   \n",
       "11            11  federal reserve provide liquidity foreign cent...   \n",
       "12            12  new car sale spain rise percent year early car...   \n",
       "13            13  south korean auto maker hyundai motor co kia m...   \n",
       "14            14  u.s. manufacturing end year high note grow dec...   \n",
       "15            15  oil price fell more thursday libya prepare res...   \n",
       "16            16  freddie mac average u.s. mortgage rate percent...   \n",
       "17            17  u.s. construction spending rise it high level ...   \n",
       "18            18  russia world big oil producer raise output pos...   \n",
       "19            19                                        morning fix   \n",
       "20            20  premium italian spanish bond offer benchmark g...   \n",
       "21            21  china yuan pull back slightly record high doll...   \n",
       "22            22  italian carmaker fiat spa say wednesday it hav...   \n",
       "23            23  brent crude rise barrel thursday decline oil s...   \n",
       "24            24  china have approve more company list mainland ...   \n",
       "25            25  janet yellen come step close final approval fe...   \n",
       "26            26  libya hop resume oil production it large oilfi...   \n",
       "27            27  italian carmaker fiat spa strike deal gain ful...   \n",
       "28            28  number american file new claim unemployment be...   \n",
       "29            29  britain top share index fell first trading day...   \n",
       "...          ...                                                ...   \n",
       "4973        4973  sharp emerge market sell-off appear subside th...   \n",
       "4974        4974  taiwan financial market be closed jan feb chin...   \n",
       "4975        4975  wall street rebound open thursday previous ses...   \n",
       "4976        4976  dollar rise basket currency thursday data show...   \n",
       "4977        4977  amazon.com inc report close-to-expected sale c...   \n",
       "4978        4978  jetblue airway wednesday report higher-than-ex...   \n",
       "4979        4979  * custody holding treasury fell bln-ifr* large...   \n",
       "4980        4980  swiss drugmaker roche report full-year profit ...   \n",
       "4981        4981  u.s. president barack obama nod trade his annu...   \n",
       "4982        4982  starbucks corp chief executive officer howard ...   \n",
       "4983        4983  china lenovo group be near deal buy google inc...   \n",
       "4984        4984  detail u.s. treasury auction 13-week 26-week 5...   \n",
       "4985        4985  infineon expect demand microchip use car smart...   \n",
       "4986        4986  reverse wednesday loss em pressure dissipated*...   \n",
       "4987        4987  amazon.com inc miss wall street profit estimat...   \n",
       "4988        4988  turkey be not consider sort capital control it...   \n",
       "4989        4989  australian share fell percent thursday wall st...   \n",
       "4990        4990  massive rate hike may have stall turkish lira ...   \n",
       "4991        4991  thailand army will increase number troop capit...   \n",
       "4992        4992  recent outbreak bird flu china have cost poult...   \n",
       "4993        4993  italy benchmark 10-year debt cost fell their l...   \n",
       "4994        4994  china ruling communist party have expel former...   \n",
       "4995        4995  google inc quarterly revenue beat wall street ...   \n",
       "4996        4996  turkey lira weaken dollar thursday late trade ...   \n",
       "4997        4997  exxon mobil corp world large public trade oil ...   \n",
       "4998        4998  visa inc chief executive urge u.s. merchant ba...   \n",
       "4999        4999  singapore share hit five-month low thursday po...   \n",
       "5000        5000  symantec corp report percent fall quarterly re...   \n",
       "5001        5001  northrop grumman corp maker surveillance drone...   \n",
       "5002        5002  author be reuters breakingviews columnist opin...   \n",
       "\n",
       "      Unnamed: 0                                         jp_article  \\\n",
       "0              0  米 商務省 発表 する 建設 支出 以下 とおり 季節調整 年率 総 建設 支出 民間 部門...   \n",
       "1              1  中国 低価格 スマホ メーカー 小米科技 () 雷軍 董事長 以上 販売 する 計画 明らか...   \n",
       "2              2  ソウル 株式市場 サムスン電子 株価 超 下落 する 安値 付ける 一部 アナリスト ウォン...   \n",
       "3              3  欧州 株式市場 イタリア 自動車 大手 FIAT 株価 一時 急伸 する 8月 以来 高値 ...   \n",
       "4              4  欧州 株式市場 イタリア 自動車 大手 FIAT 株価 一時 急伸 する 8月 以来 高値 ...   \n",
       "5              5  カッコ 前 営業日 米 東部 時間 時分 前 営業日 終盤 米 東部 時間 時分 前 営業日...   \n",
       "6              6     米財務省 銘柄 統合 入札 実施 する 発表 する 発行 いずれ 償還 1月 11月 11月   \n",
       "7              7  原油 先物 相場 リビア 大 規模 油田 生産 停止 要因 なる いる 抗議活動 休止 する...   \n",
       "8              8  米 労働省 発表 する 12月 週 新規 失業保険 申請 件数 季節調整 前週 り 連続 減...   \n",
       "9              9  パナマ運河 拡張 工事 めぐる 建設 会社 成る 企業 連合 パナマ運河 PC コスト 超過...   \n",
       "10            10  12月 フランス イタリア スペイン 自動車販売 台数 前年 同月 増加 する 欧州 自動車...   \n",
       "11            11  米 連邦準備理事会 FRB 傘下 ニューヨーク連銀 発表 する 最新 週間 データ よる 通...   \n",
       "12            12  スペイン 自動車 業界団体 よる 新車 販売 政府 補助 支援 する 前年 なる 減少 する...   \n",
       "13            13  韓国 自動車メーカー 現代自動車 系列 起亜自動車 世界 販売台数 両社 合計 前年 目標 ...   \n",
       "14            14  Markit 発表 する 12月 米 製造業 購買担当者景気指数 PM 改定 1月 以来 高...   \n",
       "15            15  原油 先物 相場 リビア 大 規模 油田 生産 停止 要因 なる いる 抗議活動 休止 する...   \n",
       "16            16  米 連邦 住宅 貸付 抵当 公社 フレディマック 調査 住宅ローン 金利 手数料 以下 通り...   \n",
       "17            17  米 商務省 発表 する 11月 建設 支出 前 月 年率 3月 以来 高水準 公共 部門 減...   \n",
       "18            18  ロシア エネルギー省 発表 する データ よる 石油 生産量 日量 ソビエト連邦 崩壊 最 ...   \n",
       "19            19           ロンドン 市場 午後 値 決め 以下 通り ドル オンス 午後 ドル 午前 ドル   \n",
       "20            20  カッコ 先物 欧州 市場 前 営業日 終値 現物 前 営業日 終盤 時分 先物 清算 ユーロ...   \n",
       "21            21  年明け 上海 外国為替市場 人民元 相場 引け 強含み 昨年 12月 付ける 最 高値 水準...   \n",
       "22            22  イタリア 自動車 大手 FIAT 傘下 米 クライスラー グループ 完全子会社 合意 する ...   \n",
       "23            23  原油 先物 相場 リビア 大 規模 油田 生産 停止 要因 なる いる 抗議活動 休止 する...   \n",
       "24            24  中国 再開 する 新規株式公開 承認 加速 する いる 国営 メディア 新た 上場 承認 す...   \n",
       "25            25  米 上院 連邦準備理事会 FRB 次期 議長 指名 する イエレン 副議長 指名 承認 採決...   \n",
       "26            26  リビア 大 規模 油田 エル シャララ 生産 停止 要因 なる いる 抗議活動 デモ隊 活動...   \n",
       "27            27  イタリア 自動車 大手 FIAT 傘下 米 クライスラー グループ 完全子会社 合意 する ...   \n",
       "28            28  米 労働省 発表 する 12月 週 新規 失業保険 申請 件数 季節調整 前週 り 連続 減...   \n",
       "29            29  カッコ 前 営業日 総合 株価指数 ロンドン 終値 前 営業日 終値 ロンドン株式市場 反落...   \n",
       "...          ...                                                ...   \n",
       "4973        4973  外国為替市場 一時 加速 する いる 新興国通貨 下落 一服 する 中南米 通貨 上昇 する...   \n",
       "4974        4974  加権指数 前 営業日 売買 代金 前 営業日 終値 安 台湾 ドル 台湾 株式市場 1月 2...   \n",
       "4975        4975  カッコ 前 営業日 ダウ 工業 株 ドル 米 東部 時間 時分 寄り付き 前 営業日 終値 ...   \n",
       "4976        4976  日 終盤 年 終値 中盤 米 ニューヨーク 外為 市場 ドル 主要 通貨 上昇 する いる ...   \n",
       "4977        4977  米 オンライン 小売り 大手 アマゾン ドット コム 四半期 決算 純利益 市場 予想 下回...   \n",
       "4978        4978  格安航空会社 米 JetBlue エア Waze 発表 する 四半期 決算 純利益 当たり ...   \n",
       "4979        4979  外国 中銀 米国債 保有 昨 年月 以来 大幅 減少 FRB 米 連邦準備理事会 FRB 発...   \n",
       "4980        4980  スイス 製薬 大手 ロシュ ホールディング 発表 する 通期 決算 当たり 利益 前年 トム...   \n",
       "4981        4981  オバマ 米 大統領 一般教書演説 通商 協定 推進 する 姿勢 示す ため 議会 説得 する...   \n",
       "4982        4982  コーヒー チェーン 世界 最大手 米 スターバックス スタバ ハワード・シュルツ 最高経営責...   \n",
       "4983        4983  中国 パソコン PC 大手 レノボ・グループ 連想集団 米 Google Inc. 携帯電話...   \n",
       "4984        4984             米財務省 2月 短期 証券 ビル ビル ビル 入札 実施 する 発表 する    \n",
       "4985        4985  ドイツ 半導体 メーカー インフィニオン・テクノロジーズ 発表 する 四半期 12月 営業利...   \n",
       "4986        4986  豪ドル 円 テクニカル分析 日 上回る 下降 トレンド 疑問符 新興国 不安 後退 する 中...   \n",
       "4987        4987  米 オンライン 小売り 大手 アマゾン ドット コム 年末 商戦 四半期 決算 発表 する ...   \n",
       "4988        4988  トルコ 政府高官 通貨 リラ 防衛 資本規制 検討 事項 挙がる いる 明らか する エルド...   \n",
       "4989        4989  P AS 指数 大引け 安 GM 前 営業日 終値 高 シドニー 株式市場 反落 する 引け...   \n",
       "4990        4990  トルコ 中央銀行 大幅 利上げ 通貨 リラ 下落 食い止める 中銀 独立 救う 可能性 ある...   \n",
       "4991        4991  タイ 来月 総選挙 控える 首都 バンコク 配備 する 兵士 数 増やす 明らか する 政府...   \n",
       "4992        4992  上海 証券 よる 中国 鳥インフルエンザ 流行 養鶏 農家 被害 出る おる 政府 新た 支...   \n",
       "4993        4993  イタリア 実施 する 国債 入札 利回り 8月 以来 低 水準 なる 利回り ユーロ 導入 ...   \n",
       "4994        4994  中国共産党 汚職 調査 担当 する 中央 規律 検査 委員会 収賄 権力 乱用 行為 及ぶ ...   \n",
       "4995        4995  インターネット 検索 大手 米 Google Inc. 発表 する 四半期 決算 広告 料金...   \n",
       "4996        4996  TRY 対ドル 前日 終盤 時点 近辺 近く 下落 する いる 投資家 引き続く 大幅 利上...   \n",
       "4997        4997  米 石油 大手 エクソンモービル 発表 する 四半期 決算 生産量 減少 響く 利益 市場 ...   \n",
       "4998        4998  米 クレジットカード 大手 ビザ 発表 する 四半期 12月 決算 クレジットカード 利用 ...   \n",
       "4999        4999  東南アジア 株式市場 軟化 する 取引 終える 米 量的緩和 縮小 継続 決定 受ける リス...   \n",
       "5000        5000  米 セキュリティー ソフト 大手 Symantec 発表 する 四半期 12月 決算 売上高...   \n",
       "5001        5001  米 防衛 大手 ノースロップ・グラマン 発表 する 昨年 四半期 決算 純利益 当たり 前年...   \n",
       "5002        5002  シカゴ ロイター 米 Google Inc. 買収 する 携帯電話 端末 部門 モトローラ ...   \n",
       "\n",
       "      similarity  dis_similarity  \\\n",
       "0            5.0             1.0   \n",
       "1            5.0             1.0   \n",
       "2            5.0             1.0   \n",
       "3            5.0             1.0   \n",
       "4            5.0             1.0   \n",
       "5            5.0             1.0   \n",
       "6            5.0             1.0   \n",
       "7            5.0             1.0   \n",
       "8            5.0             1.0   \n",
       "9            5.0             1.0   \n",
       "10           5.0             1.0   \n",
       "11           5.0             1.0   \n",
       "12           5.0             1.0   \n",
       "13           5.0             1.0   \n",
       "14           5.0             1.0   \n",
       "15           5.0             1.0   \n",
       "16           5.0             1.0   \n",
       "17           5.0             1.0   \n",
       "18           5.0             1.0   \n",
       "19           5.0             1.0   \n",
       "20           5.0             1.0   \n",
       "21           5.0             1.0   \n",
       "22           5.0             1.0   \n",
       "23           5.0             1.0   \n",
       "24           5.0             1.0   \n",
       "25           5.0             1.0   \n",
       "26           5.0             1.0   \n",
       "27           5.0             1.0   \n",
       "28           5.0             1.0   \n",
       "29           5.0             1.0   \n",
       "...          ...             ...   \n",
       "4973         5.0             1.0   \n",
       "4974         5.0             1.0   \n",
       "4975         5.0             1.0   \n",
       "4976         5.0             1.0   \n",
       "4977         5.0             1.0   \n",
       "4978         5.0             1.0   \n",
       "4979         5.0             1.0   \n",
       "4980         5.0             1.0   \n",
       "4981         5.0             1.0   \n",
       "4982         5.0             1.0   \n",
       "4983         5.0             1.0   \n",
       "4984         5.0             1.0   \n",
       "4985         5.0             1.0   \n",
       "4986         5.0             1.0   \n",
       "4987         5.0             1.0   \n",
       "4988         5.0             1.0   \n",
       "4989         5.0             1.0   \n",
       "4990         5.0             1.0   \n",
       "4991         5.0             1.0   \n",
       "4992         5.0             1.0   \n",
       "4993         5.0             1.0   \n",
       "4994         5.0             1.0   \n",
       "4995         5.0             1.0   \n",
       "4996         5.0             1.0   \n",
       "4997         5.0             1.0   \n",
       "4998         5.0             1.0   \n",
       "4999         5.0             1.0   \n",
       "5000         5.0             1.0   \n",
       "5001         5.0             1.0   \n",
       "5002         5.0             1.0   \n",
       "\n",
       "                                       en_article_wrong  \\\n",
       "0     philippine will offer tender next year airport...   \n",
       "1     taiwanese bank have exposure loan company chin...   \n",
       "2     bank canada should keep it key interest rate h...   \n",
       "3     brazil incoming finance minister joaquim levy ...   \n",
       "4     u.s. employer add large number worker nearly y...   \n",
       "5     india central bank keep it key policy repo rat...   \n",
       "6     sweden central bank keep it key interest rate ...   \n",
       "7     asset manager credit suisse hedging griffo be ...   \n",
       "8     * usd/cnh close ny trade 6.1370-6.1450 offshor...   \n",
       "9     chipmaker altera corp be work intel corp combi...   \n",
       "10    president francois hollande brush aside questi...   \n",
       "11    share italy third-biggest bank monte dei pasch...   \n",
       "12    seoul share rebound thursday snap day lose str...   \n",
       "13    average new home price china major city drop p...   \n",
       "14    greece economy shrank annual pace percent seco...   \n",
       "15    turkish prime minister tayyip erdogan accuse p...   \n",
       "16    be discussion high level u.s. government how u...   \n",
       "17    australian share rise percent wednesday hover ...   \n",
       "18    canadian have die avian influenza return trip ...   \n",
       "19    former french president nicolas sarkozy be pla...   \n",
       "20    crude price plunge further monday opec once ag...   \n",
       "21    european stock fell early trade monday resume ...   \n",
       "22    pro-russian separatist ukraine have agree prov...   \n",
       "23    * share india essar oil ltd astrazeneca pharma...   \n",
       "24    european central bank keep interest rate recor...   \n",
       "25    time warner inc break financials it premium mo...   \n",
       "26    mcdonald corp say it business have be hurt chi...   \n",
       "27    spec flip usd net long vs bln small net short ...   \n",
       "28    nokia surprise investor strong quarterly earni...   \n",
       "29    burger king be talk acquire canadian coffee do...   \n",
       "...                                                 ...   \n",
       "4973  quota allocate china dollar-dominated qualifie...   \n",
       "4974  european central bank leave interest rate unch...   \n",
       "4975  european central bank keep interest rate stead...   \n",
       "4976  hundred hong kong police forcible remove kicki...   \n",
       "4977  india market regulator monday partial reverse ...   \n",
       "4978  european central bank leave interest rate unch...   \n",
       "4979  britain first increase interest rate financial...   \n",
       "4980  * stop channel resistance trip close rally tow...   \n",
       "4981  u.s. house price rise will probable slow furth...   \n",
       "4982  federal reserve wednesday end it monthly bond ...   \n",
       "4983  follow be highlight remark economy monetary po...   \n",
       "4984  bank england be not close raise interest rate ...   \n",
       "4985  mexican economic growth will accelerate percen...   \n",
       "4986  hong kong justice department hand investigatio...   \n",
       "4987  congressional negotiator race tuesday wrap fin...   \n",
       "4988  following bid merger acquisition disposal be r...   \n",
       "4989  fiat say late wednesday it have call sharehold...   \n",
       "4990  china key money rate slump four-month low week...   \n",
       "4991  european central bank unexpected cut interest ...   \n",
       "4992  u.s. federal reserve be widely expect chop it ...   \n",
       "4993  president vladimir putin say wednesday it will...   \n",
       "4994  china share end down slightly wednesday bevera...   \n",
       "4995  sprint corp have drop it bid acquire no u.s. c...   \n",
       "4996  federal reserve be risk it credibility not act...   \n",
       "4997  russia qualify next month soccer world cup hos...   \n",
       "4998  china create new job city first month year bri...   \n",
       "4999  u.s. company pick pace hiring march signal dam...   \n",
       "5000  china have exclude u.s.-based symantec corp ru...   \n",
       "5001  nissan motor co unveil it new taxi london mond...   \n",
       "5002  singapore-listed frasers centrepoint ltd make ...   \n",
       "\n",
       "                                            word2vec_en  \\\n",
       "0     [[0.079418, -0.0698862, 0.0105229, 0.0433305, ...   \n",
       "1     [[0.0946131, 0.0954258, 0.201975, -0.18888, 0....   \n",
       "2     [[0.111116, 0.163467, 0.173304, -0.21241, 0.19...   \n",
       "3     [[0.252217, -0.149704, -0.000305933, 0.335273,...   \n",
       "4     [[0.252217, -0.149704, -0.000305933, 0.335273,...   \n",
       "5     [[0.079418, -0.0698862, 0.0105229, 0.0433305, ...   \n",
       "6     [[0.145339, 0.0967358, -0.290555, -0.157721, 0...   \n",
       "7     [[-0.00470701, -0.396765, -0.322486, -0.53076,...   \n",
       "8     [[0.258893, -0.240117, -0.39061, -0.180771, 0....   \n",
       "9     [[-0.246409, -0.300402, 0.0540296, 0.0361169, ...   \n",
       "10    [[0.0325002, 0.110915, -0.126051, -0.221096, 0...   \n",
       "11    [[0.0761386, 0.273143, -0.42036, -0.0670243, -...   \n",
       "12    [[-0.0148091, 0.0937563, -0.266831, -0.100736,...   \n",
       "13    [[-0.0864343, -0.392118, -0.265892, 0.0306064,...   \n",
       "14    [[0.079418, -0.0698862, 0.0105229, 0.0433305, ...   \n",
       "15    [[-0.122633, -0.213171, -0.236308, -0.440996, ...   \n",
       "16    [[0.348366, -0.0344246, -0.0886954, -0.606096,...   \n",
       "17    [[0.079418, -0.0698862, 0.0105229, 0.0433305, ...   \n",
       "18    [[0.0481659, -0.0320038, 0.00198885, -0.044975...   \n",
       "19    [[0.0178536, -0.137507, -0.101738, -0.0816501,...   \n",
       "20    [[0.172091, -0.28611, 0.0797486, -0.0987142, 0...   \n",
       "21    [[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...   \n",
       "22    [[0.14417, -0.206665, -0.0273102, 0.378012, 0....   \n",
       "23    [[-0.00470701, -0.396765, -0.322486, -0.53076,...   \n",
       "24    [[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...   \n",
       "25    [[0.237401, 0.362354, -0.204507, -0.237838, 0....   \n",
       "26    [[0.178806, 0.105778, -0.390584, 0.0331697, -0...   \n",
       "27    [[0.14417, -0.206665, -0.0273102, 0.378012, 0....   \n",
       "28    [[-0.0908237, 0.126889, -0.305503, -0.0270881,...   \n",
       "29    [[-0.137006, 0.105725, 0.115759, 0.41086, 0.34...   \n",
       "...                                                 ...   \n",
       "4973  [[-0.181887, 0.187679, -0.0888446, -0.284644, ...   \n",
       "4974  [[0.140891, 0.133389, -0.259482, -0.045965, 0....   \n",
       "4975  [[0.261115, 0.322767, -0.0312655, -0.031369, 0...   \n",
       "4976  [[0.0591501, -0.00193826, -0.357213, 0.115154,...   \n",
       "4977  [[-0.44227, 0.342926, 0.8082, -0.0856614, 0.25...   \n",
       "4978  [[0.0560445, -0.0741857, -0.169413, 0.207105, ...   \n",
       "4979  [[0.060403, -0.21116, -0.112524, 0.418048, -0....   \n",
       "4980  [[0.531755, 0.0465069, -0.280278, 0.0207437, -...   \n",
       "4981  [[0.079418, -0.0698862, 0.0105229, 0.0433305, ...   \n",
       "4982  [[-0.0383446, 0.155325, 0.62502, 0.152943, 0.0...   \n",
       "4983  [[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...   \n",
       "4984  [[0.141714, 0.116061, -0.0546338, -0.234393, -...   \n",
       "4985  [[0.161593, 0.154688, 0.199677, 0.0963585, 0.1...   \n",
       "4986  [[-0.0972391, -0.0130996, 0.0103848, 0.196479,...   \n",
       "4987  [[-0.44227, 0.342926, 0.8082, -0.0856614, 0.25...   \n",
       "4988  [[0.205812, -0.0776789, -0.0100262, 0.0848734,...   \n",
       "4989  [[0.229783, 0.0867598, -0.154559, -0.0812089, ...   \n",
       "4990  [[0.323224, 0.0206201, 0.0343361, -0.0548864, ...   \n",
       "4991  [[-0.00144556, -0.080357, -0.164071, 0.396402,...   \n",
       "4992  [[-0.0184049, -0.11853, -0.113298, -0.102021, ...   \n",
       "4993  [[-0.0289411, -0.00576493, -0.0602972, 0.43231...   \n",
       "4994  [[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...   \n",
       "4995  [[-0.184489, 0.108974, 0.432585, -0.259388, 0....   \n",
       "4996  [[0.205812, -0.0776789, -0.0100262, 0.0848734,...   \n",
       "4997  [[0.0399386, 0.127008, -0.189544, -0.172313, -...   \n",
       "4998  [[-0.383909, 0.376686, 0.0438472, 0.0146235, -...   \n",
       "4999  [[-0.00751844, -0.0674906, -0.356288, 0.060561...   \n",
       "5000  [[0.211295, 0.339492, 0.265527, 0.210434, 0.02...   \n",
       "5001  [[0.313289, 0.0940975, -0.0294598, 0.110512, 0...   \n",
       "5002  [[0.0817824, -0.07372, -0.377568, 0.0546247, -...   \n",
       "\n",
       "                                            word2vec_jp  \\\n",
       "0     [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "1     [[0.364929, 0.0202659, 0.170838, 0.0298371, -0...   \n",
       "2     [[0.379925, -0.16321, 0.216476, -0.00105682, -...   \n",
       "3     [[0.27545, 0.0250656, 0.0825939, 0.136058, -0....   \n",
       "4     [[0.27545, 0.0250656, 0.0825939, 0.136058, -0....   \n",
       "5     [[-0.401097, -0.568938, -0.155227, 0.434545, -...   \n",
       "6     [[-0.440666, 0.610078, -0.0983196, 0.801558, 0...   \n",
       "7     [[0.00253854, -0.129143, -0.126948, 0.0700992,...   \n",
       "8     [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "9     [[0.0367229, 0.154389, -0.430821, 0.336414, -0...   \n",
       "10    [[-0.47501, 0.0407163, 0.111163, 0.451794, -0....   \n",
       "11    [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "12    [[-0.101784, 0.297449, -0.0359539, -0.183187, ...   \n",
       "13    [[-0.133516, -0.0476626, -0.0501251, -0.141976...   \n",
       "14    [[-0.129796, 0.467595, -0.160948, 0.13798, -0....   \n",
       "15    [[0.00253854, -0.129143, -0.126948, 0.0700992,...   \n",
       "16    [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "17    [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "18    [[0.17937, 0.0217469, -0.00774201, -0.275233, ...   \n",
       "19    [[-0.0987584, -0.130326, 0.000382429, 0.453031...   \n",
       "20    [[-0.401097, -0.568938, -0.155227, 0.434545, -...   \n",
       "21    [[-0.0356909, 0.0368742, -0.210699, -0.0758654...   \n",
       "22    [[0.0566944, 0.221398, -0.105711, -0.144083, -...   \n",
       "23    [[0.00253854, -0.129143, -0.126948, 0.0700992,...   \n",
       "24    [[0.364929, 0.0202659, 0.170838, 0.0298371, -0...   \n",
       "25    [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "26    [[0.41208, -0.134387, -0.464477, -0.0422248, 0...   \n",
       "27    [[0.0566944, 0.221398, -0.105711, -0.144083, -...   \n",
       "28    [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "29    [[-0.401097, -0.568938, -0.155227, 0.434545, -...   \n",
       "...                                                 ...   \n",
       "4973  [[0.405083, 0.0932307, 0.823482, -0.377643, -0...   \n",
       "4974  [[0.232547, -0.519346, -0.280419, 0.204819, -0...   \n",
       "4975  [[-0.401097, -0.568938, -0.155227, 0.434545, -...   \n",
       "4976  [[0.0464822, -0.0669743, 0.123004, -0.122508, ...   \n",
       "4977  [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "4978  [[0.162483, -0.0885207, -0.177669, 0.0562228, ...   \n",
       "4979  [[-0.448259, 0.418138, -0.0675213, 0.173515, -...   \n",
       "4980  [[0.0230546, 0.134405, 0.276877, -0.215977, -0...   \n",
       "4981  [[0.393028, 0.0563531, -0.249674, -0.0347517, ...   \n",
       "4982  [[0.386177, -0.115329, 0.18794, -0.0113484, -0...   \n",
       "4983  [[0.364929, 0.0202659, 0.170838, 0.0298371, -0...   \n",
       "4984  [[-0.440666, 0.610078, -0.0983196, 0.801558, 0...   \n",
       "4985  [[-0.0851713, 0.205356, 0.125934, -0.069173, -...   \n",
       "4986  [[0.0193808, -0.0897314, 0.0394857, 0.224606, ...   \n",
       "4987  [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "4988  [[0.489795, -0.096977, -0.235068, -0.26358, 0....   \n",
       "4989  [[-0.308348, -0.29255, -0.608433, 0.365757, -0...   \n",
       "4990  [[0.489795, -0.096977, -0.235068, -0.26358, 0....   \n",
       "4991  [[-0.0549502, -0.123358, -0.252149, -0.161471,...   \n",
       "4992  [[0.307846, 0.304336, -0.384274, 0.275885, -0....   \n",
       "4993  [[0.0566944, 0.221398, -0.105711, -0.144083, -...   \n",
       "4994  [[-0.264259, -0.00900147, 0.236856, 0.181937, ...   \n",
       "4995  [[-0.073621, -0.46774, -0.243989, 0.10658, -0....   \n",
       "4996  [[-0.0531319, 0.0673207, 0.207877, 0.0881506, ...   \n",
       "4997  [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "4998  [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "4999  [[0.261055, -0.130575, -0.261364, 0.0722576, 0...   \n",
       "5000  [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "5001  [[0.203559, -0.17033, 0.136308, -0.0854052, -0...   \n",
       "5002  [[-0.728102, 0.445352, -0.220505, 0.212112, -0...   \n",
       "\n",
       "                                             padding_en  \\\n",
       "0     [[0.0794180035591, -0.0698861926794, 0.0105229...   \n",
       "1     [[0.0946130752563, 0.095425799489, 0.201974958...   \n",
       "2     [[0.111115589738, 0.163467362523, 0.1733036488...   \n",
       "3     [[0.252217, -0.149704, -0.000305933, 0.335273,...   \n",
       "4     [[0.252217, -0.149704, -0.000305933, 0.335273,...   \n",
       "5     [[0.079418, -0.0698862, 0.0105229, 0.0433305, ...   \n",
       "6     [[0.145339399576, 0.0967358276248, -0.29055538...   \n",
       "7     [[-0.00470701, -0.396765, -0.322486, -0.53076,...   \n",
       "8     [[0.258893, -0.240117, -0.39061, -0.180771, 0....   \n",
       "9     [[-0.246409475803, -0.300402313471, 0.05402963...   \n",
       "10    [[0.0325002, 0.110915, -0.126051, -0.221096, 0...   \n",
       "11    [[0.0761386305094, 0.27314338088, -0.420359730...   \n",
       "12    [[-0.0148091288283, 0.0937562733889, -0.266831...   \n",
       "13    [[-0.0864343, -0.392118, -0.265892, 0.0306064,...   \n",
       "14    [[0.0794180035591, -0.0698861926794, 0.0105229...   \n",
       "15    [[-0.122633, -0.213171, -0.236308, -0.440996, ...   \n",
       "16    [[0.348365992308, -0.034424636513, -0.08869536...   \n",
       "17    [[0.0794180035591, -0.0698861926794, 0.0105229...   \n",
       "18    [[0.0481659, -0.0320038, 0.00198885, -0.044975...   \n",
       "19    [[0.0178535878658, -0.137506857514, -0.1017375...   \n",
       "20    [[0.172091, -0.28611, 0.0797486, -0.0987142, 0...   \n",
       "21    [[-0.0418512, 0.0643166, 0.197735, -0.24311, 0...   \n",
       "22    [[0.144170120358, -0.206664994359, -0.02731021...   \n",
       "23    [[-0.00470701325685, -0.396764904261, -0.32248...   \n",
       "24    [[-0.0418512448668, 0.0643166452646, 0.1977352...   \n",
       "25    [[0.237400531769, 0.362354069948, -0.204507112...   \n",
       "26    [[0.178805798292, 0.105777747929, -0.390584498...   \n",
       "27    [[0.14417, -0.206665, -0.0273102, 0.378012, 0....   \n",
       "28    [[-0.0908236578107, 0.126888975501, -0.3055031...   \n",
       "29    [[-0.137006, 0.105725, 0.115759, 0.41086, 0.34...   \n",
       "...                                                 ...   \n",
       "4973  [[-0.181887, 0.187679, -0.0888446, -0.284644, ...   \n",
       "4974  [[0.140890628099, 0.133389428258, -0.259482234...   \n",
       "4975  [[0.26111510396, 0.322767198086, -0.0312655344...   \n",
       "4976  [[0.0591500923038, -0.00193826400209, -0.35721...   \n",
       "4977  [[-0.442269712687, 0.342925727367, 0.808200478...   \n",
       "4978  [[0.0560445040464, -0.0741856694221, -0.169412...   \n",
       "4979  [[0.0604030229151, -0.211159676313, -0.1125241...   \n",
       "4980  [[0.531755208969, 0.0465068519115, -0.28027793...   \n",
       "4981  [[0.079418, -0.0698862, 0.0105229, 0.0433305, ...   \n",
       "4982  [[-0.0383446030319, 0.155325382948, 0.62501972...   \n",
       "4983  [[-0.0418512448668, 0.0643166452646, 0.1977352...   \n",
       "4984  [[0.14171436429, 0.116061158478, -0.0546337664...   \n",
       "4985  [[0.161593, 0.154688, 0.199677, 0.0963585, 0.1...   \n",
       "4986  [[-0.097239099443, -0.0130996406078, 0.0103847...   \n",
       "4987  [[-0.442269712687, 0.342925727367, 0.808200478...   \n",
       "4988  [[0.205812335014, -0.0776788592339, -0.0100261...   \n",
       "4989  [[0.229783073068, 0.0867598429322, -0.15455880...   \n",
       "4990  [[0.323224, 0.0206201, 0.0343361, -0.0548864, ...   \n",
       "4991  [[-0.00144556, -0.080357, -0.164071, 0.396402,...   \n",
       "4992  [[-0.0184048675001, -0.118529520929, -0.113297...   \n",
       "4993  [[-0.0289410501719, -0.00576493237168, -0.0602...   \n",
       "4994  [[-0.0418512448668, 0.0643166452646, 0.1977352...   \n",
       "4995  [[-0.184488818049, 0.108973585069, 0.432584911...   \n",
       "4996  [[0.205812335014, -0.0776788592339, -0.0100261...   \n",
       "4997  [[0.0399386, 0.127008, -0.189544, -0.172313, -...   \n",
       "4998  [[-0.383908867836, 0.376686453819, 0.043847214...   \n",
       "4999  [[-0.00751843955368, -0.0674905627966, -0.3562...   \n",
       "5000  [[0.211294844747, 0.339491575956, 0.2655267417...   \n",
       "5001  [[0.313289284706, 0.094097495079, -0.029459763...   \n",
       "5002  [[0.0817824, -0.07372, -0.377568, 0.0546247, -...   \n",
       "\n",
       "                                             padding_jp  \n",
       "0     [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "1     [[0.364928901196, 0.0202658716589, 0.170837789...  \n",
       "2     [[0.379924654961, -0.163209781051, 0.216475769...  \n",
       "3     [[0.275450408459, 0.0250655952841, 0.082593858...  \n",
       "4     [[0.275450408459, 0.0250655952841, 0.082593858...  \n",
       "5     [[-0.401097238064, -0.56893825531, -0.15522733...  \n",
       "6     [[-0.440665841103, 0.610077679157, -0.09831961...  \n",
       "7     [[0.00253854179755, -0.129142984748, -0.126948...  \n",
       "8     [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "9     [[0.0367229022086, 0.154389277101, -0.43082135...  \n",
       "10    [[-0.475010246038, 0.0407162643969, 0.11116266...  \n",
       "11    [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "12    [[-0.10178424418, 0.297449380159, -0.035953946...  \n",
       "13    [[-0.133516088128, -0.0476626008749, -0.050125...  \n",
       "14    [[-0.12979593873, 0.467594563961, -0.160947903...  \n",
       "15    [[0.00253854179755, -0.129142984748, -0.126948...  \n",
       "16    [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "17    [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "18    [[0.179370418191, 0.0217469427735, -0.00774200...  \n",
       "19    [[-0.09875844419, -0.130326345563, 0.000382429...  \n",
       "20    [[-0.401097238064, -0.56893825531, -0.15522733...  \n",
       "21    [[-0.0356909483671, 0.0368741899729, -0.210698...  \n",
       "22    [[0.0566943995655, 0.221398234367, -0.10571137...  \n",
       "23    [[0.00253854179755, -0.129142984748, -0.126948...  \n",
       "24    [[0.364928901196, 0.0202658716589, 0.170837789...  \n",
       "25    [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "26    [[0.412079721689, -0.134387344122, -0.46447741...  \n",
       "27    [[0.0566943995655, 0.221398234367, -0.10571137...  \n",
       "28    [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "29    [[-0.401097238064, -0.56893825531, -0.15522733...  \n",
       "...                                                 ...  \n",
       "4973  [[0.405083149672, 0.0932307168841, 0.823481857...  \n",
       "4974  [[0.232547223568, -0.519345581532, -0.28041857...  \n",
       "4975  [[-0.401097238064, -0.56893825531, -0.15522733...  \n",
       "4976  [[0.046482168138, -0.0669743493199, 0.12300406...  \n",
       "4977  [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "4978  [[0.162483349442, -0.0885207280517, -0.1776690...  \n",
       "4979  [[-0.448258966208, 0.418137580156, -0.06752131...  \n",
       "4980  [[0.0230546388775, 0.134404763579, 0.276877105...  \n",
       "4981  [[0.393028, 0.0563531, -0.249674, -0.0347517, ...  \n",
       "4982  [[0.386177003384, -0.115329496562, 0.187939628...  \n",
       "4983  [[0.364928901196, 0.0202658716589, 0.170837789...  \n",
       "4984  [[-0.440665841103, 0.610077679157, -0.09831961...  \n",
       "4985  [[-0.0851713418961, 0.205355525017, 0.12593433...  \n",
       "4986  [[0.0193807650357, -0.0897313952446, 0.0394856...  \n",
       "4987  [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "4988  [[0.489795058966, -0.096977032721, -0.23506839...  \n",
       "4989  [[-0.308347702026, -0.292549997568, -0.6084330...  \n",
       "4990  [[0.489795058966, -0.096977032721, -0.23506839...  \n",
       "4991  [[-0.054950222373, -0.123358346522, -0.2521488...  \n",
       "4992  [[0.307845532894, 0.30433639884, -0.3842737972...  \n",
       "4993  [[0.0566943995655, 0.221398234367, -0.10571137...  \n",
       "4994  [[-0.264258921146, -0.00900147110224, 0.236855...  \n",
       "4995  [[-0.0736210420728, -0.467739701271, -0.243988...  \n",
       "4996  [[-0.0531319342554, 0.067320741713, 0.20787686...  \n",
       "4997  [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "4998  [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "4999  [[0.261055022478, -0.130575269461, -0.26136353...  \n",
       "5000  [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "5001  [[0.203559398651, -0.17032957077, 0.1363077312...  \n",
       "5002  [[-0.728102147579, 0.445351630449, -0.22050540...  \n",
       "\n",
       "[5000 rows x 11 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pairs_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unrecognized keyword arguments: {'go_backwards': True}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-f3a604c6a43a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model_lstm2.fit([X1_train, X2_train], [y_train], go_backwards=True,\n\u001b[0;32m----> 2\u001b[0;31m                        validation_data=([X1_test, X2_test], y_test), epochs=50, batch_size=256)\n\u001b[0m",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nb_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized keyword arguments: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized keyword arguments: {'go_backwards': True}"
     ]
    }
   ],
   "source": [
    "hist = model_lstm2.fit([X1_train, X2_train], [y_train], go_backwards=True,\n",
    "                       validation_data=([X1_test, X2_test], y_test), epochs=50, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ma..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.6337 - acc: 0.6641 - val_loss: 0.5705 - val_acc: 0.7120\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 44s - loss: 0.4121 - acc: 0.8139 - val_loss: 0.4276 - val_acc: 0.8045\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.2964 - acc: 0.8811 - val_loss: 0.3740 - val_acc: 0.8475\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.2400 - acc: 0.9083 - val_loss: 0.3988 - val_acc: 0.8440\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 43s - loss: 0.2042 - acc: 0.9263 - val_loss: 0.4031 - val_acc: 0.8375\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 43s - loss: 0.1665 - acc: 0.9404 - val_loss: 0.4219 - val_acc: 0.8495\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 43s - loss: 0.1463 - acc: 0.9506 - val_loss: 0.4112 - val_acc: 0.8590\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.1213 - acc: 0.9590 - val_loss: 0.4353 - val_acc: 0.8510\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 46s - loss: 0.0984 - acc: 0.9693 - val_loss: 0.4692 - val_acc: 0.8525\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 44s - loss: 0.0768 - acc: 0.9768 - val_loss: 0.5122 - val_acc: 0.8550\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 44s - loss: 0.0689 - acc: 0.9785 - val_loss: 0.5768 - val_acc: 0.8415\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.0551 - acc: 0.9850 - val_loss: 0.6299 - val_acc: 0.8255\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.0505 - acc: 0.9864 - val_loss: 0.6526 - val_acc: 0.8435\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.0562 - acc: 0.9821 - val_loss: 0.6089 - val_acc: 0.8580\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 44s - loss: 0.0421 - acc: 0.9888 - val_loss: 0.6459 - val_acc: 0.8550\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 44s - loss: 0.0434 - acc: 0.9881 - val_loss: 0.6481 - val_acc: 0.8485\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.0367 - acc: 0.9904 - val_loss: 0.7227 - val_acc: 0.8520\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 45s - loss: 0.0297 - acc: 0.9925 - val_loss: 0.7390 - val_acc: 0.8545\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 46s - loss: 0.0289 - acc: 0.9920 - val_loss: 0.7331 - val_acc: 0.8530\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 46s - loss: 0.0271 - acc: 0.9920 - val_loss: 0.7866 - val_acc: 0.8430\n",
      "Epoch 21/50\n",
      "1536/8000 [====>.........................] - ETA: 33s - loss: 0.0374 - acc: 0.9889"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-c799418741a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Fit the training model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m hist = model_lstm2.fit([X1_train, X2_train], [y_train],\n\u001b[0;32m---> 30\u001b[0;31m                        validation_data=([X1_test, X2_test], y_test), epochs=50, batch_size=256)\n\u001b[0m",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\t# Input layer\n",
    "\tinput_1 = Input(shape=(maxlen,200), dtype='float32', name='main_input_1')\n",
    "\tinput_2 = Input(shape=(maxlen,200), dtype='float32', name='main_input_2')\n",
    "\n",
    "\t# LSTM layer\n",
    "\t# lstm_out_1 = LSTM(50)(input_1)\n",
    "\t# lstm_out_1 = LSTM(50)(input_1)\n",
    "\tlstm_out_1 = LSTM(50, go_backwards = True)(input_1)\n",
    "\tlstm_out_2 = LSTM(50, go_backwards = True)(input_2)\n",
    "\n",
    "\t# Merge layer\n",
    "\tmerged_vector = keras.layers.concatenate([lstm_out_1, lstm_out_2], axis=-1)\n",
    "\n",
    "\t# (Dense 1) * 3\n",
    "\tx1 = Dense(64, activation='relu')(merged_vector)\n",
    "\tx1 = Dense(64, activation='relu')(x1)\n",
    "\tx1 = Dense(64, activation='relu')(x1)\n",
    "\tmain_output = Dense(1, activation='sigmoid', name='main_output')(x1)\n",
    "\n",
    "\t# Model definition\n",
    "\tmodel_lstm2 = Model(input=[input_1, input_2], output=main_output)\n",
    "\n",
    "\t# Compile the model\n",
    "\tmodel_lstm2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\t# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\t# Fit the training model\n",
    "\thist = model_lstm2.fit([X1_train, X2_train], [y_train],\n",
    "\t                       validation_data=([X1_test, X2_test], y_test), epochs=50, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.87      0.86      1000\n",
      "        1.0       0.87      0.86      0.86      1000\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_eva_predict = model_lstm2.predict([X1_test, X2_test])\n",
    "print(classification_report(y_test, y_eva_predict>.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Find answer for doc.', 0)\n",
      "7.0\n",
      "('Find answer for doc.', 1)\n",
      "1.0\n",
      "('Find answer for doc.', 2)\n",
      "1.0\n",
      "('Find answer for doc.', 3)\n",
      "58.0\n",
      "('Find answer for doc.', 4)\n",
      "84.5\n",
      "('Find answer for doc.', 5)\n",
      "13.0\n",
      "('Find answer for doc.', 6)\n",
      "195.0\n",
      "('Find answer for doc.', 7)\n",
      "6.0\n",
      "('Find answer for doc.', 8)\n",
      "6.0\n",
      "('Find answer for doc.', 9)\n",
      "34.5\n",
      "('Find answer for doc.', 10)\n",
      "3.0\n",
      "('Find answer for doc.', 11)\n",
      "37.0\n",
      "('Find answer for doc.', 12)\n",
      "25.0\n",
      "('Find answer for doc.', 13)\n",
      "1.0\n",
      "('Find answer for doc.', 14)\n",
      "25.5\n",
      "('Find answer for doc.', 15)\n",
      "53.0\n",
      "('Find answer for doc.', 16)\n",
      "29.5\n",
      "('Find answer for doc.', 17)\n",
      "73.0\n",
      "('Find answer for doc.', 18)\n",
      "13.0\n",
      "('Find answer for doc.', 19)\n",
      "15.5\n",
      "('Find answer for doc.', 20)\n",
      "30.0\n",
      "('Find answer for doc.', 21)\n",
      "19.0\n",
      "('Find answer for doc.', 22)\n",
      "73.0\n",
      "('Find answer for doc.', 23)\n",
      "1.0\n",
      "('Find answer for doc.', 24)\n",
      "24.0\n",
      "('Find answer for doc.', 25)\n",
      "8.5\n",
      "('Find answer for doc.', 26)\n",
      "62.0\n",
      "('Find answer for doc.', 27)\n",
      "35.5\n",
      "('Find answer for doc.', 28)\n",
      "1.0\n",
      "('Find answer for doc.', 29)\n",
      "5.0\n",
      "('Find answer for doc.', 30)\n",
      "5.0\n",
      "('Find answer for doc.', 31)\n",
      "6.0\n",
      "('Find answer for doc.', 32)\n",
      "19.0\n",
      "('Find answer for doc.', 33)\n",
      "82.5\n",
      "('Find answer for doc.', 34)\n",
      "6.0\n",
      "('Find answer for doc.', 35)\n",
      "7.0\n",
      "('Find answer for doc.', 36)\n",
      "3.5\n",
      "('Find answer for doc.', 37)\n",
      "62.0\n",
      "('Find answer for doc.', 38)\n",
      "18.0\n",
      "('Find answer for doc.', 39)\n",
      "110.0\n",
      "('Find answer for doc.', 40)\n",
      "10.0\n",
      "('Find answer for doc.', 41)\n",
      "18.5\n",
      "('Find answer for doc.', 42)\n",
      "51.0\n",
      "('Find answer for doc.', 43)\n",
      "14.0\n",
      "('Find answer for doc.', 44)\n",
      "29.0\n",
      "('Find answer for doc.', 45)\n",
      "123.0\n",
      "('Find answer for doc.', 46)\n",
      "4.0\n",
      "('Find answer for doc.', 47)\n",
      "9.0\n",
      "('Find answer for doc.', 48)\n",
      "77.0\n",
      "('Find answer for doc.', 49)\n",
      "199.0\n",
      "('Find answer for doc.', 50)\n",
      "6.0\n",
      "('Find answer for doc.', 51)\n",
      "8.0\n",
      "('Find answer for doc.', 52)\n",
      "32.0\n",
      "('Find answer for doc.', 53)\n",
      "76.0\n",
      "('Find answer for doc.', 54)\n",
      "29.5\n",
      "('Find answer for doc.', 55)\n",
      "28.0\n",
      "('Find answer for doc.', 56)\n",
      "26.0\n",
      "('Find answer for doc.', 57)\n",
      "18.0\n",
      "('Find answer for doc.', 58)\n",
      "29.0\n",
      "('Find answer for doc.', 59)\n",
      "7.0\n",
      "('Find answer for doc.', 60)\n",
      "17.0\n",
      "('Find answer for doc.', 61)\n",
      "16.0\n",
      "('Find answer for doc.', 62)\n",
      "14.0\n",
      "('Find answer for doc.', 63)\n",
      "2.0\n",
      "('Find answer for doc.', 64)\n",
      "38.0\n",
      "('Find answer for doc.', 65)\n",
      "20.0\n",
      "('Find answer for doc.', 66)\n",
      "93.0\n",
      "('Find answer for doc.', 67)\n",
      "16.0\n",
      "('Find answer for doc.', 68)\n",
      "15.0\n",
      "('Find answer for doc.', 69)\n",
      "21.0\n",
      "('Find answer for doc.', 70)\n",
      "80.0\n",
      "('Find answer for doc.', 71)\n",
      "58.0\n",
      "('Find answer for doc.', 72)\n",
      "7.5\n",
      "('Find answer for doc.', 73)\n",
      "2.0\n",
      "('Find answer for doc.', 74)\n",
      "8.0\n",
      "('Find answer for doc.', 75)\n",
      "7.5\n",
      "('Find answer for doc.', 76)\n",
      "18.0\n",
      "('Find answer for doc.', 77)\n",
      "24.5\n",
      "('Find answer for doc.', 78)\n",
      "205.0\n",
      "('Find answer for doc.', 79)\n",
      "1.0\n",
      "('Find answer for doc.', 80)\n",
      "82.5\n",
      "('Find answer for doc.', 81)\n",
      "2.5\n",
      "('Find answer for doc.', 82)\n",
      "5.5\n",
      "('Find answer for doc.', 83)\n",
      "65.0\n",
      "('Find answer for doc.', 84)\n",
      "19.0\n",
      "('Find answer for doc.', 85)\n",
      "2.0\n",
      "('Find answer for doc.', 86)\n",
      "13.5\n",
      "('Find answer for doc.', 87)\n",
      "41.0\n",
      "('Find answer for doc.', 88)\n",
      "21.5\n",
      "('Find answer for doc.', 89)\n",
      "34.5\n",
      "('Find answer for doc.', 90)\n",
      "3.0\n",
      "('Find answer for doc.', 91)\n",
      "1.0\n",
      "('Find answer for doc.', 92)\n",
      "8.0\n",
      "('Find answer for doc.', 93)\n",
      "117.0\n",
      "('Find answer for doc.', 94)\n",
      "5.0\n",
      "('Find answer for doc.', 95)\n",
      "26.0\n",
      "('Find answer for doc.', 96)\n",
      "19.0\n",
      "('Find answer for doc.', 97)\n",
      "79.0\n",
      "('Find answer for doc.', 98)\n",
      "28.0\n",
      "('Find answer for doc.', 99)\n",
      "119.0\n",
      "('Find answer for doc.', 100)\n",
      "8.5\n",
      "('Find answer for doc.', 101)\n",
      "30.0\n",
      "('Find answer for doc.', 102)\n",
      "23.0\n",
      "('Find answer for doc.', 103)\n",
      "30.0\n",
      "('Find answer for doc.', 104)\n",
      "7.5\n",
      "('Find answer for doc.', 105)\n",
      "37.0\n",
      "('Find answer for doc.', 106)\n",
      "2.5\n",
      "('Find answer for doc.', 107)\n",
      "22.5\n",
      "('Find answer for doc.', 108)\n",
      "82.0\n",
      "('Find answer for doc.', 109)\n",
      "15.5\n",
      "('Find answer for doc.', 110)\n",
      "2.0\n",
      "('Find answer for doc.', 111)\n",
      "88.5\n",
      "('Find answer for doc.', 112)\n",
      "46.0\n",
      "('Find answer for doc.', 113)\n",
      "16.0\n",
      "('Find answer for doc.', 114)\n",
      "13.0\n",
      "('Find answer for doc.', 115)\n",
      "82.5\n",
      "('Find answer for doc.', 116)\n",
      "24.0\n",
      "('Find answer for doc.', 117)\n",
      "11.0\n",
      "('Find answer for doc.', 118)\n",
      "78.0\n",
      "('Find answer for doc.', 119)\n",
      "32.0\n",
      "('Find answer for doc.', 120)\n",
      "29.5\n",
      "('Find answer for doc.', 121)\n",
      "15.5\n",
      "('Find answer for doc.', 122)\n",
      "44.0\n",
      "('Find answer for doc.', 123)\n",
      "2.0\n",
      "('Find answer for doc.', 124)\n",
      "12.0\n",
      "('Find answer for doc.', 125)\n",
      "98.0\n",
      "('Find answer for doc.', 126)\n",
      "12.0\n",
      "('Find answer for doc.', 127)\n",
      "7.5\n",
      "('Find answer for doc.', 128)\n",
      "6.5\n",
      "('Find answer for doc.', 129)\n",
      "13.0\n",
      "('Find answer for doc.', 130)\n",
      "2.0\n",
      "('Find answer for doc.', 131)\n",
      "3.0\n",
      "('Find answer for doc.', 132)\n",
      "12.0\n",
      "('Find answer for doc.', 133)\n",
      "18.0\n",
      "('Find answer for doc.', 134)\n",
      "47.0\n",
      "('Find answer for doc.', 135)\n",
      "4.0\n",
      "('Find answer for doc.', 136)\n",
      "24.0\n",
      "('Find answer for doc.', 137)\n",
      "347.0\n",
      "('Find answer for doc.', 138)\n",
      "77.0\n",
      "('Find answer for doc.', 139)\n",
      "115.0\n",
      "('Find answer for doc.', 140)\n",
      "165.0\n",
      "('Find answer for doc.', 141)\n",
      "21.5\n",
      "('Find answer for doc.', 142)\n",
      "2.0\n",
      "('Find answer for doc.', 143)\n",
      "14.0\n",
      "('Find answer for doc.', 144)\n",
      "254.0\n",
      "('Find answer for doc.', 145)\n",
      "8.0\n",
      "('Find answer for doc.', 146)\n",
      "469.0\n",
      "('Find answer for doc.', 147)\n",
      "46.5\n",
      "('Find answer for doc.', 148)\n",
      "14.0\n",
      "('Find answer for doc.', 149)\n",
      "9.0\n",
      "('Find answer for doc.', 150)\n",
      "236.5\n",
      "('Find answer for doc.', 151)\n",
      "4.5\n",
      "('Find answer for doc.', 152)\n",
      "42.0\n",
      "('Find answer for doc.', 153)\n",
      "91.5\n",
      "('Find answer for doc.', 154)\n",
      "1.5\n",
      "('Find answer for doc.', 155)\n",
      "104.5\n",
      "('Find answer for doc.', 156)\n",
      "23.0\n",
      "('Find answer for doc.', 157)\n",
      "283.0\n",
      "('Find answer for doc.', 158)\n",
      "9.5\n",
      "('Find answer for doc.', 159)\n",
      "246.0\n",
      "('Find answer for doc.', 160)\n",
      "25.5\n",
      "('Find answer for doc.', 161)\n",
      "25.0\n",
      "('Find answer for doc.', 162)\n",
      "2.0\n",
      "('Find answer for doc.', 163)\n",
      "6.0\n",
      "('Find answer for doc.', 164)\n",
      "4.0\n",
      "('Find answer for doc.', 165)\n",
      "13.0\n",
      "('Find answer for doc.', 166)\n",
      "106.0\n",
      "('Find answer for doc.', 167)\n",
      "273.5\n",
      "('Find answer for doc.', 168)\n",
      "77.5\n",
      "('Find answer for doc.', 169)\n",
      "14.5\n",
      "('Find answer for doc.', 170)\n",
      "25.0\n",
      "('Find answer for doc.', 171)\n",
      "32.0\n",
      "('Find answer for doc.', 172)\n",
      "58.5\n",
      "('Find answer for doc.', 173)\n",
      "10.0\n",
      "('Find answer for doc.', 174)\n",
      "17.0\n",
      "('Find answer for doc.', 175)\n",
      "3.0\n",
      "('Find answer for doc.', 176)\n",
      "17.0\n",
      "('Find answer for doc.', 177)\n",
      "7.0\n",
      "('Find answer for doc.', 178)\n",
      "47.5\n",
      "('Find answer for doc.', 179)\n",
      "20.0\n",
      "('Find answer for doc.', 180)\n",
      "1.5\n",
      "('Find answer for doc.', 181)\n",
      "25.0\n",
      "('Find answer for doc.', 182)\n",
      "5.0\n",
      "('Find answer for doc.', 183)\n",
      "33.0\n",
      "('Find answer for doc.', 184)\n",
      "139.0\n",
      "('Find answer for doc.', 185)\n",
      "3.0\n",
      "('Find answer for doc.', 186)\n",
      "35.0\n",
      "('Find answer for doc.', 187)\n",
      "2.0\n",
      "('Find answer for doc.', 188)\n",
      "54.0\n",
      "('Find answer for doc.', 189)\n",
      "67.5\n",
      "('Find answer for doc.', 190)\n",
      "25.5\n",
      "('Find answer for doc.', 191)\n",
      "17.0\n",
      "('Find answer for doc.', 192)\n",
      "23.0\n",
      "('Find answer for doc.', 193)\n",
      "317.0\n",
      "('Find answer for doc.', 194)\n",
      "111.0\n",
      "('Find answer for doc.', 195)\n",
      "3.0\n",
      "('Find answer for doc.', 196)\n",
      "18.5\n",
      "('Find answer for doc.', 197)\n",
      "251.0\n",
      "('Find answer for doc.', 198)\n",
      "91.5\n",
      "('Find answer for doc.', 199)\n",
      "12.5\n",
      "('Find answer for doc.', 200)\n",
      "242.0\n",
      "('Find answer for doc.', 201)\n",
      "6.0\n",
      "('Find answer for doc.', 202)\n",
      "46.0\n",
      "('Find answer for doc.', 203)\n",
      "14.5\n",
      "('Find answer for doc.', 204)\n",
      "14.0\n",
      "('Find answer for doc.', 205)\n",
      "16.5\n",
      "('Find answer for doc.', 206)\n",
      "5.0\n",
      "('Find answer for doc.', 207)\n",
      "47.0\n",
      "('Find answer for doc.', 208)\n",
      "24.0\n",
      "('Find answer for doc.', 209)\n",
      "123.0\n",
      "('Find answer for doc.', 210)\n",
      "104.5\n",
      "('Find answer for doc.', 211)\n",
      "59.0\n",
      "('Find answer for doc.', 212)\n",
      "289.0\n",
      "('Find answer for doc.', 213)\n",
      "4.0\n",
      "('Find answer for doc.', 214)\n",
      "37.0\n",
      "('Find answer for doc.', 215)\n",
      "146.0\n",
      "('Find answer for doc.', 216)\n",
      "279.0\n",
      "('Find answer for doc.', 217)\n",
      "301.5\n",
      "('Find answer for doc.', 218)\n",
      "91.5\n",
      "('Find answer for doc.', 219)\n",
      "22.0\n",
      "('Find answer for doc.', 220)\n",
      "1.0\n",
      "('Find answer for doc.', 221)\n",
      "54.0\n",
      "('Find answer for doc.', 222)\n",
      "249.0\n",
      "('Find answer for doc.', 223)\n",
      "29.0\n",
      "('Find answer for doc.', 224)\n",
      "3.0\n",
      "('Find answer for doc.', 225)\n",
      "91.5\n",
      "('Find answer for doc.', 226)\n",
      "4.0\n",
      "('Find answer for doc.', 227)\n",
      "39.0\n",
      "('Find answer for doc.', 228)\n",
      "79.0\n",
      "('Find answer for doc.', 229)\n",
      "23.0\n",
      "('Find answer for doc.', 230)\n",
      "8.0\n",
      "('Find answer for doc.', 231)\n",
      "134.0\n",
      "('Find answer for doc.', 232)\n",
      "21.0\n",
      "('Find answer for doc.', 233)\n",
      "17.0\n",
      "('Find answer for doc.', 234)\n",
      "444.0\n",
      "('Find answer for doc.', 235)\n",
      "20.0\n",
      "('Find answer for doc.', 236)\n",
      "101.5\n",
      "('Find answer for doc.', 237)\n",
      "7.5\n",
      "('Find answer for doc.', 238)\n",
      "3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Find answer for doc.', 239)\n",
      "214.0\n",
      "('Find answer for doc.', 240)\n",
      "30.0\n",
      "('Find answer for doc.', 241)\n",
      "36.0\n",
      "('Find answer for doc.', 242)\n",
      "25.0\n",
      "('Find answer for doc.', 243)\n",
      "108.5\n",
      "('Find answer for doc.', 244)\n",
      "8.0\n",
      "('Find answer for doc.', 245)\n",
      "14.5\n",
      "('Find answer for doc.', 246)\n",
      "242.0\n",
      "('Find answer for doc.', 247)\n",
      "10.5\n",
      "('Find answer for doc.', 248)\n",
      "5.5\n",
      "('Find answer for doc.', 249)\n",
      "49.0\n",
      "('Find answer for doc.', 250)\n",
      "82.0\n",
      "('Find answer for doc.', 251)\n",
      "14.0\n",
      "('Find answer for doc.', 252)\n",
      "56.0\n",
      "('Find answer for doc.', 253)\n",
      "108.5\n",
      "('Find answer for doc.', 254)\n",
      "25.0\n",
      "('Find answer for doc.', 255)\n",
      "172.0\n",
      "('Find answer for doc.', 256)\n",
      "16.0\n",
      "('Find answer for doc.', 257)\n",
      "85.5\n",
      "('Find answer for doc.', 258)\n",
      "3.0\n",
      "('Find answer for doc.', 259)\n",
      "15.5\n",
      "('Find answer for doc.', 260)\n",
      "8.0\n",
      "('Find answer for doc.', 261)\n",
      "213.0\n",
      "('Find answer for doc.', 262)\n",
      "20.0\n",
      "('Find answer for doc.', 263)\n",
      "22.0\n",
      "('Find answer for doc.', 264)\n",
      "10.5\n",
      "('Find answer for doc.', 265)\n",
      "242.0\n",
      "('Find answer for doc.', 266)\n",
      "159.0\n",
      "('Find answer for doc.', 267)\n",
      "49.5\n",
      "('Find answer for doc.', 268)\n",
      "94.0\n",
      "('Find answer for doc.', 269)\n",
      "5.0\n",
      "('Find answer for doc.', 270)\n",
      "81.0\n",
      "('Find answer for doc.', 271)\n",
      "9.0\n",
      "('Find answer for doc.', 272)\n",
      "273.5\n",
      "('Find answer for doc.', 273)\n",
      "2.0\n",
      "('Find answer for doc.', 274)\n",
      "49.5\n",
      "('Find answer for doc.', 275)\n",
      "89.0\n",
      "('Find answer for doc.', 276)\n",
      "20.5\n",
      "('Find answer for doc.', 277)\n",
      "2.0\n",
      "('Find answer for doc.', 278)\n",
      "10.5\n",
      "('Find answer for doc.', 279)\n",
      "165.0\n",
      "('Find answer for doc.', 280)\n",
      "38.0\n",
      "('Find answer for doc.', 281)\n",
      "111.0\n",
      "('Find answer for doc.', 282)\n",
      "62.5\n",
      "('Find answer for doc.', 283)\n",
      "14.5\n",
      "('Find answer for doc.', 284)\n",
      "91.5\n",
      "('Find answer for doc.', 285)\n",
      "46.5\n",
      "('Find answer for doc.', 286)\n",
      "7.5\n",
      "('Find answer for doc.', 287)\n",
      "3.0\n",
      "('Find answer for doc.', 288)\n",
      "111.0\n",
      "('Find answer for doc.', 289)\n",
      "12.0\n",
      "('Find answer for doc.', 290)\n",
      "1.0\n",
      "('Find answer for doc.', 291)\n",
      "25.5\n",
      "('Find answer for doc.', 292)\n",
      "7.0\n",
      "('Find answer for doc.', 293)\n",
      "397.0\n",
      "('Find answer for doc.', 294)\n",
      "16.0\n",
      "('Find answer for doc.', 295)\n",
      "14.0\n",
      "('Find answer for doc.', 296)\n",
      "1.0\n",
      "('Find answer for doc.', 297)\n",
      "4.5\n",
      "('Find answer for doc.', 298)\n",
      "3.0\n",
      "('Find answer for doc.', 299)\n",
      "28.5\n",
      "('Find answer for doc.', 300)\n",
      "14.0\n",
      "('Find answer for doc.', 301)\n",
      "7.5\n",
      "('Find answer for doc.', 302)\n",
      "11.0\n",
      "('Find answer for doc.', 303)\n",
      "137.0\n",
      "('Find answer for doc.', 304)\n",
      "60.0\n",
      "('Find answer for doc.', 305)\n",
      "5.5\n",
      "('Find answer for doc.', 306)\n",
      "29.0\n",
      "('Find answer for doc.', 307)\n",
      "20.0\n",
      "('Find answer for doc.', 308)\n",
      "12.0\n",
      "('Find answer for doc.', 309)\n",
      "23.0\n",
      "('Find answer for doc.', 310)\n",
      "53.0\n",
      "('Find answer for doc.', 311)\n",
      "23.5\n",
      "('Find answer for doc.', 312)\n",
      "91.5\n",
      "('Find answer for doc.', 313)\n",
      "9.0\n",
      "('Find answer for doc.', 314)\n",
      "88.0\n",
      "('Find answer for doc.', 315)\n",
      "25.0\n",
      "('Find answer for doc.', 316)\n",
      "77.0\n",
      "('Find answer for doc.', 317)\n",
      "25.0\n",
      "('Find answer for doc.', 318)\n",
      "2.0\n",
      "('Find answer for doc.', 319)\n",
      "51.0\n",
      "('Find answer for doc.', 320)\n",
      "75.0\n",
      "('Find answer for doc.', 321)\n",
      "40.0\n",
      "('Find answer for doc.', 322)\n",
      "48.0\n",
      "('Find answer for doc.', 323)\n",
      "23.5\n",
      "('Find answer for doc.', 324)\n",
      "11.0\n",
      "('Find answer for doc.', 325)\n",
      "5.5\n",
      "('Find answer for doc.', 326)\n",
      "23.0\n",
      "('Find answer for doc.', 327)\n",
      "9.0\n",
      "('Find answer for doc.', 328)\n",
      "3.5\n",
      "('Find answer for doc.', 329)\n",
      "91.5\n",
      "('Find answer for doc.', 330)\n",
      "5.0\n",
      "('Find answer for doc.', 331)\n",
      "5.5\n",
      "('Find answer for doc.', 332)\n",
      "87.0\n",
      "('Find answer for doc.', 333)\n",
      "10.5\n",
      "('Find answer for doc.', 334)\n",
      "15.0\n",
      "('Find answer for doc.', 335)\n",
      "20.0\n",
      "('Find answer for doc.', 336)\n",
      "12.5\n",
      "('Find answer for doc.', 337)\n",
      "39.0\n",
      "('Find answer for doc.', 338)\n",
      "14.0\n",
      "('Find answer for doc.', 339)\n",
      "22.0\n",
      "('Find answer for doc.', 340)\n",
      "1.0\n",
      "('Find answer for doc.', 341)\n",
      "50.5\n",
      "('Find answer for doc.', 342)\n",
      "28.5\n",
      "('Find answer for doc.', 343)\n",
      "301.5\n",
      "('Find answer for doc.', 344)\n",
      "21.5\n",
      "('Find answer for doc.', 345)\n",
      "105.5\n",
      "('Find answer for doc.', 346)\n",
      "43.0\n",
      "('Find answer for doc.', 347)\n",
      "7.0\n",
      "('Find answer for doc.', 348)\n",
      "111.0\n",
      "('Find answer for doc.', 349)\n",
      "17.0\n",
      "('Find answer for doc.', 350)\n",
      "33.0\n",
      "('Find answer for doc.', 351)\n",
      "41.0\n",
      "('Find answer for doc.', 352)\n",
      "56.5\n",
      "('Find answer for doc.', 353)\n",
      "7.0\n",
      "('Find answer for doc.', 354)\n",
      "12.0\n",
      "('Find answer for doc.', 355)\n",
      "92.0\n",
      "('Find answer for doc.', 356)\n",
      "5.0\n",
      "('Find answer for doc.', 357)\n",
      "39.0\n",
      "('Find answer for doc.', 358)\n",
      "16.0\n",
      "('Find answer for doc.', 359)\n",
      "1.5\n",
      "('Find answer for doc.', 360)\n",
      "93.0\n",
      "('Find answer for doc.', 361)\n",
      "342.5\n",
      "('Find answer for doc.', 362)\n",
      "8.5\n",
      "('Find answer for doc.', 363)\n",
      "156.0\n",
      "('Find answer for doc.', 364)\n",
      "14.0\n",
      "('Find answer for doc.', 365)\n",
      "21.5\n",
      "('Find answer for doc.', 366)\n",
      "19.0\n",
      "('Find answer for doc.', 367)\n",
      "70.0\n",
      "('Find answer for doc.', 368)\n",
      "35.5\n",
      "('Find answer for doc.', 369)\n",
      "55.5\n",
      "('Find answer for doc.', 370)\n",
      "19.0\n",
      "('Find answer for doc.', 371)\n",
      "12.0\n",
      "('Find answer for doc.', 372)\n",
      "55.0\n",
      "('Find answer for doc.', 373)\n",
      "37.5\n",
      "('Find answer for doc.', 374)\n",
      "185.0\n",
      "('Find answer for doc.', 375)\n",
      "20.0\n",
      "('Find answer for doc.', 376)\n",
      "27.0\n",
      "('Find answer for doc.', 377)\n",
      "31.0\n",
      "('Find answer for doc.', 378)\n",
      "21.5\n",
      "('Find answer for doc.', 379)\n",
      "231.0\n",
      "('Find answer for doc.', 380)\n",
      "6.0\n",
      "('Find answer for doc.', 381)\n",
      "118.0\n",
      "('Find answer for doc.', 382)\n",
      "2.0\n",
      "('Find answer for doc.', 383)\n",
      "28.0\n",
      "('Find answer for doc.', 384)\n",
      "1.0\n",
      "('Find answer for doc.', 385)\n",
      "21.0\n",
      "('Find answer for doc.', 386)\n",
      "155.5\n",
      "('Find answer for doc.', 387)\n",
      "7.0\n",
      "('Find answer for doc.', 388)\n",
      "12.0\n",
      "('Find answer for doc.', 389)\n",
      "44.0\n",
      "('Find answer for doc.', 390)\n",
      "9.0\n",
      "('Find answer for doc.', 391)\n",
      "35.0\n",
      "('Find answer for doc.', 392)\n",
      "7.0\n",
      "('Find answer for doc.', 393)\n",
      "23.0\n",
      "('Find answer for doc.', 394)\n",
      "43.5\n",
      "('Find answer for doc.', 395)\n",
      "24.0\n",
      "('Find answer for doc.', 396)\n",
      "242.5\n",
      "('Find answer for doc.', 397)\n",
      "2.0\n",
      "('Find answer for doc.', 398)\n",
      "63.0\n",
      "('Find answer for doc.', 399)\n",
      "12.0\n",
      "('Find answer for doc.', 400)\n",
      "3.0\n",
      "('Find answer for doc.', 401)\n",
      "7.0\n",
      "('Find answer for doc.', 402)\n",
      "16.0\n",
      "('Find answer for doc.', 403)\n",
      "37.5\n",
      "('Find answer for doc.', 404)\n",
      "5.5\n",
      "('Find answer for doc.', 405)\n",
      "4.5\n",
      "('Find answer for doc.', 406)\n",
      "13.0\n",
      "('Find answer for doc.', 407)\n",
      "10.5\n",
      "('Find answer for doc.', 408)\n",
      "17.5\n",
      "('Find answer for doc.', 409)\n",
      "70.5\n",
      "('Find answer for doc.', 410)\n",
      "24.0\n",
      "('Find answer for doc.', 411)\n",
      "20.0\n",
      "('Find answer for doc.', 412)\n",
      "15.5\n",
      "('Find answer for doc.', 413)\n",
      "2.0\n",
      "('Find answer for doc.', 414)\n",
      "23.0\n",
      "('Find answer for doc.', 415)\n",
      "21.5\n",
      "('Find answer for doc.', 416)\n",
      "6.0\n",
      "('Find answer for doc.', 417)\n",
      "45.5\n",
      "('Find answer for doc.', 418)\n",
      "20.0\n",
      "('Find answer for doc.', 419)\n",
      "45.5\n",
      "('Find answer for doc.', 420)\n",
      "17.5\n",
      "('Find answer for doc.', 421)\n",
      "105.0\n",
      "('Find answer for doc.', 422)\n",
      "4.0\n",
      "('Find answer for doc.', 423)\n",
      "8.0\n",
      "('Find answer for doc.', 424)\n",
      "335.5\n",
      "('Find answer for doc.', 425)\n",
      "5.0\n",
      "('Find answer for doc.', 426)\n",
      "41.0\n",
      "('Find answer for doc.', 427)\n",
      "40.5\n",
      "('Find answer for doc.', 428)\n",
      "24.5\n",
      "('Find answer for doc.', 429)\n",
      "35.5\n",
      "('Find answer for doc.', 430)\n",
      "39.5\n",
      "('Find answer for doc.', 431)\n",
      "11.0\n",
      "('Find answer for doc.', 432)\n",
      "2.0\n",
      "('Find answer for doc.', 433)\n",
      "4.5\n",
      "('Find answer for doc.', 434)\n",
      "37.0\n",
      "('Find answer for doc.', 435)\n",
      "12.0\n",
      "('Find answer for doc.', 436)\n",
      "9.0\n",
      "('Find answer for doc.', 437)\n",
      "104.0\n",
      "('Find answer for doc.', 438)\n",
      "41.5\n",
      "('Find answer for doc.', 439)\n",
      "13.0\n",
      "('Find answer for doc.', 440)\n",
      "35.0\n",
      "('Find answer for doc.', 441)\n",
      "55.0\n",
      "('Find answer for doc.', 442)\n",
      "54.5\n",
      "('Find answer for doc.', 443)\n",
      "19.0\n",
      "('Find answer for doc.', 444)\n",
      "26.0\n",
      "('Find answer for doc.', 445)\n",
      "19.5\n",
      "('Find answer for doc.', 446)\n",
      "8.5\n",
      "('Find answer for doc.', 447)\n",
      "5.0\n",
      "('Find answer for doc.', 448)\n",
      "17.0\n",
      "('Find answer for doc.', 449)\n",
      "10.0\n",
      "('Find answer for doc.', 450)\n",
      "19.0\n",
      "('Find answer for doc.', 451)\n",
      "67.0\n",
      "('Find answer for doc.', 452)\n",
      "147.0\n",
      "('Find answer for doc.', 453)\n",
      "72.5\n",
      "('Find answer for doc.', 454)\n",
      "8.0\n",
      "('Find answer for doc.', 455)\n",
      "2.0\n",
      "('Find answer for doc.', 456)\n",
      "23.0\n",
      "('Find answer for doc.', 457)\n",
      "1.5\n",
      "('Find answer for doc.', 458)\n",
      "28.0\n",
      "('Find answer for doc.', 459)\n",
      "17.0\n",
      "('Find answer for doc.', 460)\n",
      "7.0\n",
      "('Find answer for doc.', 461)\n",
      "46.0\n",
      "('Find answer for doc.', 462)\n",
      "52.0\n",
      "('Find answer for doc.', 463)\n",
      "24.0\n",
      "('Find answer for doc.', 464)\n",
      "3.0\n",
      "('Find answer for doc.', 465)\n",
      "19.5\n",
      "('Find answer for doc.', 466)\n",
      "12.0\n",
      "('Find answer for doc.', 467)\n",
      "32.0\n",
      "('Find answer for doc.', 468)\n",
      "238.5\n",
      "('Find answer for doc.', 469)\n",
      "8.5\n",
      "('Find answer for doc.', 470)\n",
      "18.0\n",
      "('Find answer for doc.', 471)\n",
      "32.0\n",
      "('Find answer for doc.', 472)\n",
      "34.0\n",
      "('Find answer for doc.', 473)\n",
      "2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Find answer for doc.', 474)\n",
      "22.0\n",
      "('Find answer for doc.', 475)\n",
      "55.0\n",
      "('Find answer for doc.', 476)\n",
      "7.0\n",
      "('Find answer for doc.', 477)\n",
      "12.0\n",
      "('Find answer for doc.', 478)\n",
      "92.0\n",
      "('Find answer for doc.', 479)\n",
      "1.0\n",
      "('Find answer for doc.', 480)\n",
      "12.0\n",
      "('Find answer for doc.', 481)\n",
      "104.5\n",
      "('Find answer for doc.', 482)\n",
      "12.0\n",
      "('Find answer for doc.', 483)\n",
      "18.0\n",
      "('Find answer for doc.', 484)\n",
      "3.0\n",
      "('Find answer for doc.', 485)\n",
      "23.5\n",
      "('Find answer for doc.', 486)\n",
      "11.0\n",
      "('Find answer for doc.', 487)\n",
      "46.0\n",
      "('Find answer for doc.', 488)\n",
      "5.5\n",
      "('Find answer for doc.', 489)\n",
      "32.0\n",
      "('Find answer for doc.', 490)\n",
      "8.0\n",
      "('Find answer for doc.', 491)\n",
      "156.5\n",
      "('Find answer for doc.', 492)\n",
      "14.0\n",
      "('Find answer for doc.', 493)\n",
      "70.5\n",
      "('Find answer for doc.', 494)\n",
      "10.5\n",
      "('Find answer for doc.', 495)\n",
      "37.0\n",
      "('Find answer for doc.', 496)\n",
      "5.5\n",
      "('Find answer for doc.', 497)\n",
      "25.5\n",
      "('Find answer for doc.', 498)\n",
      "4.0\n",
      "('Find answer for doc.', 499)\n",
      "7.0\n",
      "('Find answer for doc.', 500)\n",
      "49.5\n",
      "('Find answer for doc.', 501)\n",
      "8.5\n",
      "('Find answer for doc.', 502)\n",
      "69.0\n",
      "('Find answer for doc.', 503)\n",
      "1.0\n",
      "('Find answer for doc.', 504)\n",
      "13.0\n",
      "('Find answer for doc.', 505)\n",
      "26.0\n",
      "('Find answer for doc.', 506)\n",
      "2.0\n",
      "('Find answer for doc.', 507)\n",
      "1.0\n",
      "('Find answer for doc.', 508)\n",
      "6.5\n",
      "('Find answer for doc.', 509)\n",
      "13.0\n",
      "('Find answer for doc.', 510)\n",
      "14.0\n",
      "('Find answer for doc.', 511)\n",
      "30.0\n",
      "('Find answer for doc.', 512)\n",
      "18.0\n",
      "('Find answer for doc.', 513)\n",
      "5.5\n",
      "('Find answer for doc.', 514)\n",
      "8.0\n",
      "('Find answer for doc.', 515)\n",
      "17.5\n",
      "('Find answer for doc.', 516)\n",
      "43.5\n",
      "('Find answer for doc.', 517)\n",
      "60.0\n",
      "('Find answer for doc.', 518)\n",
      "136.0\n",
      "('Find answer for doc.', 519)\n",
      "2.0\n",
      "('Find answer for doc.', 520)\n",
      "99.0\n",
      "('Find answer for doc.', 521)\n",
      "2.0\n",
      "('Find answer for doc.', 522)\n",
      "59.5\n",
      "('Find answer for doc.', 523)\n",
      "32.5\n",
      "('Find answer for doc.', 524)\n",
      "144.0\n",
      "('Find answer for doc.', 525)\n",
      "25.0\n",
      "('Find answer for doc.', 526)\n",
      "14.0\n",
      "('Find answer for doc.', 527)\n",
      "16.0\n",
      "('Find answer for doc.', 528)\n",
      "19.0\n",
      "('Find answer for doc.', 529)\n",
      "150.0\n",
      "('Find answer for doc.', 530)\n",
      "23.5\n",
      "('Find answer for doc.', 531)\n",
      "52.0\n",
      "('Find answer for doc.', 532)\n",
      "2.0\n",
      "('Find answer for doc.', 533)\n",
      "21.0\n",
      "('Find answer for doc.', 534)\n",
      "6.0\n",
      "('Find answer for doc.', 535)\n",
      "7.0\n",
      "('Find answer for doc.', 536)\n",
      "56.5\n",
      "('Find answer for doc.', 537)\n",
      "35.0\n",
      "('Find answer for doc.', 538)\n",
      "41.5\n",
      "('Find answer for doc.', 539)\n",
      "31.0\n",
      "('Find answer for doc.', 540)\n",
      "13.0\n",
      "('Find answer for doc.', 541)\n",
      "69.5\n",
      "('Find answer for doc.', 542)\n",
      "196.5\n",
      "('Find answer for doc.', 543)\n",
      "81.0\n",
      "('Find answer for doc.', 544)\n",
      "35.0\n",
      "('Find answer for doc.', 545)\n",
      "5.0\n",
      "('Find answer for doc.', 546)\n",
      "42.0\n",
      "('Find answer for doc.', 547)\n",
      "21.5\n",
      "('Find answer for doc.', 548)\n",
      "37.5\n",
      "('Find answer for doc.', 549)\n",
      "36.0\n",
      "('Find answer for doc.', 550)\n",
      "30.0\n",
      "('Find answer for doc.', 551)\n",
      "18.0\n",
      "('Find answer for doc.', 552)\n",
      "70.0\n",
      "('Find answer for doc.', 553)\n",
      "31.5\n",
      "('Find answer for doc.', 554)\n",
      "1.5\n",
      "('Find answer for doc.', 555)\n",
      "1.0\n",
      "('Find answer for doc.', 556)\n",
      "1.5\n",
      "('Find answer for doc.', 557)\n",
      "15.0\n",
      "('Find answer for doc.', 558)\n",
      "108.0\n",
      "('Find answer for doc.', 559)\n",
      "196.5\n",
      "('Find answer for doc.', 560)\n",
      "36.0\n",
      "('Find answer for doc.', 561)\n",
      "10.0\n",
      "('Find answer for doc.', 562)\n",
      "1.5\n",
      "('Find answer for doc.', 563)\n",
      "9.0\n",
      "('Find answer for doc.', 564)\n",
      "24.5\n",
      "('Find answer for doc.', 565)\n",
      "83.0\n",
      "('Find answer for doc.', 566)\n",
      "83.0\n",
      "('Find answer for doc.', 567)\n",
      "9.0\n",
      "('Find answer for doc.', 568)\n",
      "16.0\n",
      "('Find answer for doc.', 569)\n",
      "8.0\n",
      "('Find answer for doc.', 570)\n",
      "25.5\n",
      "('Find answer for doc.', 571)\n",
      "9.0\n",
      "('Find answer for doc.', 572)\n",
      "4.0\n",
      "('Find answer for doc.', 573)\n",
      "58.0\n",
      "('Find answer for doc.', 574)\n",
      "17.5\n",
      "('Find answer for doc.', 575)\n",
      "59.0\n",
      "('Find answer for doc.', 576)\n",
      "40.5\n",
      "('Find answer for doc.', 577)\n",
      "9.0\n",
      "('Find answer for doc.', 578)\n",
      "23.0\n",
      "('Find answer for doc.', 579)\n",
      "34.0\n",
      "('Find answer for doc.', 580)\n",
      "5.0\n",
      "('Find answer for doc.', 581)\n",
      "19.0\n",
      "('Find answer for doc.', 582)\n",
      "28.0\n",
      "('Find answer for doc.', 583)\n",
      "2.0\n",
      "('Find answer for doc.', 584)\n",
      "49.0\n",
      "('Find answer for doc.', 585)\n",
      "1.5\n",
      "('Find answer for doc.', 586)\n",
      "17.0\n",
      "('Find answer for doc.', 587)\n",
      "32.0\n",
      "('Find answer for doc.', 588)\n",
      "327.0\n",
      "('Find answer for doc.', 589)\n",
      "17.0\n",
      "('Find answer for doc.', 590)\n",
      "4.0\n",
      "('Find answer for doc.', 591)\n",
      "514.5\n",
      "('Find answer for doc.', 592)\n",
      "16.0\n",
      "('Find answer for doc.', 593)\n",
      "502.5\n",
      "('Find answer for doc.', 594)\n",
      "61.5\n",
      "('Find answer for doc.', 595)\n",
      "85.0\n",
      "('Find answer for doc.', 596)\n",
      "3.0\n",
      "('Find answer for doc.', 597)\n",
      "28.5\n",
      "('Find answer for doc.', 598)\n",
      "2.0\n",
      "('Find answer for doc.', 599)\n",
      "23.5\n",
      "('Find answer for doc.', 600)\n",
      "28.5\n",
      "('Find answer for doc.', 601)\n",
      "50.0\n",
      "('Find answer for doc.', 602)\n",
      "6.0\n",
      "('Find answer for doc.', 603)\n",
      "19.0\n",
      "('Find answer for doc.', 604)\n",
      "19.0\n",
      "('Find answer for doc.', 605)\n",
      "75.5\n",
      "('Find answer for doc.', 606)\n",
      "14.0\n",
      "('Find answer for doc.', 607)\n",
      "37.0\n",
      "('Find answer for doc.', 608)\n",
      "29.0\n",
      "('Find answer for doc.', 609)\n",
      "37.0\n",
      "('Find answer for doc.', 610)\n",
      "18.0\n",
      "('Find answer for doc.', 611)\n",
      "57.0\n",
      "('Find answer for doc.', 612)\n",
      "12.0\n",
      "('Find answer for doc.', 613)\n",
      "28.5\n",
      "('Find answer for doc.', 614)\n",
      "60.5\n",
      "('Find answer for doc.', 615)\n",
      "3.0\n",
      "('Find answer for doc.', 616)\n",
      "91.0\n",
      "('Find answer for doc.', 617)\n",
      "27.5\n",
      "('Find answer for doc.', 618)\n",
      "23.0\n",
      "('Find answer for doc.', 619)\n",
      "2.0\n",
      "('Find answer for doc.', 620)\n",
      "6.0\n",
      "('Find answer for doc.', 621)\n",
      "55.0\n",
      "('Find answer for doc.', 622)\n",
      "85.0\n",
      "('Find answer for doc.', 623)\n",
      "4.0\n",
      "('Find answer for doc.', 624)\n",
      "12.0\n",
      "('Find answer for doc.', 625)\n",
      "70.0\n",
      "('Find answer for doc.', 626)\n",
      "1.5\n",
      "('Find answer for doc.', 627)\n",
      "13.5\n",
      "('Find answer for doc.', 628)\n",
      "8.5\n",
      "('Find answer for doc.', 629)\n",
      "27.0\n",
      "('Find answer for doc.', 630)\n",
      "137.0\n",
      "('Find answer for doc.', 631)\n",
      "148.0\n",
      "('Find answer for doc.', 632)\n",
      "45.5\n",
      "('Find answer for doc.', 633)\n",
      "5.5\n",
      "('Find answer for doc.', 634)\n",
      "11.0\n",
      "('Find answer for doc.', 635)\n",
      "47.0\n",
      "('Find answer for doc.', 636)\n",
      "235.0\n",
      "('Find answer for doc.', 637)\n",
      "30.5\n",
      "('Find answer for doc.', 638)\n",
      "1.0\n",
      "('Find answer for doc.', 639)\n",
      "2.0\n",
      "('Find answer for doc.', 640)\n",
      "3.0\n",
      "('Find answer for doc.', 641)\n",
      "32.0\n",
      "('Find answer for doc.', 642)\n",
      "1.0\n",
      "('Find answer for doc.', 643)\n",
      "84.5\n",
      "('Find answer for doc.', 644)\n",
      "93.0\n",
      "('Find answer for doc.', 645)\n",
      "39.5\n",
      "('Find answer for doc.', 646)\n",
      "30.0\n",
      "('Find answer for doc.', 647)\n",
      "21.5\n",
      "('Find answer for doc.', 648)\n",
      "27.0\n",
      "('Find answer for doc.', 649)\n",
      "29.5\n",
      "('Find answer for doc.', 650)\n",
      "12.0\n",
      "('Find answer for doc.', 651)\n",
      "5.5\n",
      "('Find answer for doc.', 652)\n",
      "15.0\n",
      "('Find answer for doc.', 653)\n",
      "85.5\n",
      "('Find answer for doc.', 654)\n",
      "52.0\n",
      "('Find answer for doc.', 655)\n",
      "9.5\n",
      "('Find answer for doc.', 656)\n",
      "35.0\n",
      "('Find answer for doc.', 657)\n",
      "14.0\n",
      "('Find answer for doc.', 658)\n",
      "3.0\n",
      "('Find answer for doc.', 659)\n",
      "7.0\n",
      "('Find answer for doc.', 660)\n",
      "153.0\n",
      "('Find answer for doc.', 661)\n",
      "22.0\n",
      "('Find answer for doc.', 662)\n",
      "73.0\n",
      "('Find answer for doc.', 663)\n",
      "77.5\n",
      "('Find answer for doc.', 664)\n",
      "32.0\n",
      "('Find answer for doc.', 665)\n",
      "88.0\n",
      "('Find answer for doc.', 666)\n",
      "211.5\n",
      "('Find answer for doc.', 667)\n",
      "50.5\n",
      "('Find answer for doc.', 668)\n",
      "117.0\n",
      "('Find answer for doc.', 669)\n",
      "1.0\n",
      "('Find answer for doc.', 670)\n",
      "84.0\n",
      "('Find answer for doc.', 671)\n",
      "4.0\n",
      "('Find answer for doc.', 672)\n",
      "1.0\n",
      "('Find answer for doc.', 673)\n",
      "197.0\n",
      "('Find answer for doc.', 674)\n",
      "2.0\n",
      "('Find answer for doc.', 675)\n",
      "14.0\n",
      "('Find answer for doc.', 676)\n",
      "11.0\n",
      "('Find answer for doc.', 677)\n",
      "69.5\n",
      "('Find answer for doc.', 678)\n",
      "21.5\n",
      "('Find answer for doc.', 679)\n",
      "44.0\n",
      "('Find answer for doc.', 680)\n",
      "13.5\n",
      "('Find answer for doc.', 681)\n",
      "106.0\n",
      "('Find answer for doc.', 682)\n",
      "5.0\n",
      "('Find answer for doc.', 683)\n",
      "31.0\n",
      "('Find answer for doc.', 684)\n",
      "34.0\n",
      "('Find answer for doc.', 685)\n",
      "41.0\n",
      "('Find answer for doc.', 686)\n",
      "54.5\n",
      "('Find answer for doc.', 687)\n",
      "36.5\n",
      "('Find answer for doc.', 688)\n",
      "21.5\n",
      "('Find answer for doc.', 689)\n",
      "46.0\n",
      "('Find answer for doc.', 690)\n",
      "35.0\n",
      "('Find answer for doc.', 691)\n",
      "11.0\n",
      "('Find answer for doc.', 692)\n",
      "7.0\n",
      "('Find answer for doc.', 693)\n",
      "10.5\n",
      "('Find answer for doc.', 694)\n",
      "111.5\n",
      "('Find answer for doc.', 695)\n",
      "9.5\n",
      "('Find answer for doc.', 696)\n",
      "9.0\n",
      "('Find answer for doc.', 697)\n",
      "72.0\n",
      "('Find answer for doc.', 698)\n",
      "52.5\n",
      "('Find answer for doc.', 699)\n",
      "20.0\n",
      "('Find answer for doc.', 700)\n",
      "223.5\n",
      "('Find answer for doc.', 701)\n",
      "15.0\n",
      "('Find answer for doc.', 702)\n",
      "15.0\n",
      "('Find answer for doc.', 703)\n",
      "83.5\n",
      "('Find answer for doc.', 704)\n",
      "77.5\n",
      "('Find answer for doc.', 705)\n",
      "6.0\n",
      "('Find answer for doc.', 706)\n",
      "88.0\n",
      "('Find answer for doc.', 707)\n",
      "27.0\n",
      "('Find answer for doc.', 708)\n",
      "16.5\n",
      "('Find answer for doc.', 709)\n",
      "37.5\n",
      "('Find answer for doc.', 710)\n",
      "73.0\n",
      "('Find answer for doc.', 711)\n",
      "11.0\n",
      "('Find answer for doc.', 712)\n",
      "1.5\n",
      "('Find answer for doc.', 713)\n",
      "39.5\n",
      "('Find answer for doc.', 714)\n",
      "83.5\n",
      "('Find answer for doc.', 715)\n",
      "8.0\n",
      "('Find answer for doc.', 716)\n",
      "36.0\n",
      "('Find answer for doc.', 717)\n",
      "37.0\n",
      "('Find answer for doc.', 718)\n",
      "5.0\n",
      "('Find answer for doc.', 719)\n",
      "76.5\n",
      "('Find answer for doc.', 720)\n",
      "28.5\n",
      "('Find answer for doc.', 721)\n",
      "17.0\n",
      "('Find answer for doc.', 722)\n",
      "17.0\n",
      "('Find answer for doc.', 723)\n",
      "11.0\n",
      "('Find answer for doc.', 724)\n",
      "35.0\n",
      "('Find answer for doc.', 725)\n",
      "85.5\n",
      "('Find answer for doc.', 726)\n",
      "65.5\n",
      "('Find answer for doc.', 727)\n",
      "59.0\n",
      "('Find answer for doc.', 728)\n",
      "44.0\n",
      "('Find answer for doc.', 729)\n",
      "47.0\n",
      "('Find answer for doc.', 730)\n",
      "3.0\n",
      "('Find answer for doc.', 731)\n",
      "30.0\n",
      "('Find answer for doc.', 732)\n",
      "15.5\n",
      "('Find answer for doc.', 733)\n",
      "6.5\n",
      "('Find answer for doc.', 734)\n",
      "8.0\n",
      "('Find answer for doc.', 735)\n",
      "32.0\n",
      "('Find answer for doc.', 736)\n",
      "10.0\n",
      "('Find answer for doc.', 737)\n",
      "103.0\n",
      "('Find answer for doc.', 738)\n",
      "9.0\n",
      "('Find answer for doc.', 739)\n",
      "12.5\n",
      "('Find answer for doc.', 740)\n",
      "5.0\n",
      "('Find answer for doc.', 741)\n",
      "8.0\n",
      "('Find answer for doc.', 742)\n",
      "107.5\n",
      "('Find answer for doc.', 743)\n",
      "143.5\n",
      "('Find answer for doc.', 744)\n",
      "29.5\n",
      "('Find answer for doc.', 745)\n",
      "92.5\n",
      "('Find answer for doc.', 746)\n",
      "2.0\n",
      "('Find answer for doc.', 747)\n",
      "11.5\n",
      "('Find answer for doc.', 748)\n",
      "15.5\n",
      "('Find answer for doc.', 749)\n",
      "67.0\n",
      "('Find answer for doc.', 750)\n",
      "213.5\n",
      "('Find answer for doc.', 751)\n",
      "19.0\n",
      "('Find answer for doc.', 752)\n",
      "2.0\n",
      "('Find answer for doc.', 753)\n",
      "28.5\n",
      "('Find answer for doc.', 754)\n",
      "13.5\n",
      "('Find answer for doc.', 755)\n",
      "4.0\n",
      "('Find answer for doc.', 756)\n",
      "60.5\n",
      "('Find answer for doc.', 757)\n",
      "51.0\n",
      "('Find answer for doc.', 758)\n",
      "20.0\n",
      "('Find answer for doc.', 759)\n",
      "140.5\n",
      "('Find answer for doc.', 760)\n",
      "12.5\n",
      "('Find answer for doc.', 761)\n",
      "133.5\n",
      "('Find answer for doc.', 762)\n",
      "25.0\n",
      "('Find answer for doc.', 763)\n",
      "23.5\n",
      "('Find answer for doc.', 764)\n",
      "2.0\n",
      "('Find answer for doc.', 765)\n",
      "54.0\n",
      "('Find answer for doc.', 766)\n",
      "4.0\n",
      "('Find answer for doc.', 767)\n",
      "21.5\n",
      "('Find answer for doc.', 768)\n",
      "16.0\n",
      "('Find answer for doc.', 769)\n",
      "9.5\n",
      "('Find answer for doc.', 770)\n",
      "2.0\n",
      "('Find answer for doc.', 771)\n",
      "1.0\n",
      "('Find answer for doc.', 772)\n",
      "7.0\n",
      "('Find answer for doc.', 773)\n",
      "8.0\n",
      "('Find answer for doc.', 774)\n",
      "51.0\n",
      "('Find answer for doc.', 775)\n",
      "11.0\n",
      "('Find answer for doc.', 776)\n",
      "235.0\n",
      "('Find answer for doc.', 777)\n",
      "85.5\n",
      "('Find answer for doc.', 778)\n",
      "4.0\n",
      "('Find answer for doc.', 779)\n",
      "13.5\n",
      "('Find answer for doc.', 780)\n",
      "9.5\n",
      "('Find answer for doc.', 781)\n",
      "73.5\n",
      "('Find answer for doc.', 782)\n",
      "59.0\n",
      "('Find answer for doc.', 783)\n",
      "19.0\n",
      "('Find answer for doc.', 784)\n",
      "145.0\n",
      "('Find answer for doc.', 785)\n",
      "19.0\n",
      "('Find answer for doc.', 786)\n",
      "12.0\n",
      "('Find answer for doc.', 787)\n",
      "92.0\n",
      "('Find answer for doc.', 788)\n",
      "152.5\n",
      "('Find answer for doc.', 789)\n",
      "33.5\n",
      "('Find answer for doc.', 790)\n",
      "91.0\n",
      "('Find answer for doc.', 791)\n",
      "156.5\n",
      "('Find answer for doc.', 792)\n",
      "77.5\n",
      "('Find answer for doc.', 793)\n",
      "123.0\n",
      "('Find answer for doc.', 794)\n",
      "30.0\n",
      "('Find answer for doc.', 795)\n",
      "379.5\n",
      "('Find answer for doc.', 796)\n",
      "308.5\n",
      "('Find answer for doc.', 797)\n",
      "171.0\n",
      "('Find answer for doc.', 798)\n",
      "160.0\n",
      "('Find answer for doc.', 799)\n",
      "216.5\n",
      "('Find answer for doc.', 800)\n",
      "67.5\n",
      "('Find answer for doc.', 801)\n",
      "248.5\n",
      "('Find answer for doc.', 802)\n",
      "189.5\n",
      "('Find answer for doc.', 803)\n",
      "377.5\n",
      "('Find answer for doc.', 804)\n",
      "233.5\n",
      "('Find answer for doc.', 805)\n",
      "219.5\n",
      "('Find answer for doc.', 806)\n",
      "306.5\n",
      "('Find answer for doc.', 807)\n",
      "13.0\n",
      "('Find answer for doc.', 808)\n",
      "199.0\n",
      "('Find answer for doc.', 809)\n",
      "67.5\n",
      "('Find answer for doc.', 810)\n",
      "201.5\n",
      "('Find answer for doc.', 811)\n",
      "377.5\n",
      "('Find answer for doc.', 812)\n",
      "379.5\n",
      "('Find answer for doc.', 813)\n",
      "27.0\n",
      "('Find answer for doc.', 814)\n",
      "25.0\n",
      "('Find answer for doc.', 815)\n",
      "4.0\n",
      "('Find answer for doc.', 816)\n",
      "129.5\n",
      "('Find answer for doc.', 817)\n",
      "34.0\n",
      "('Find answer for doc.', 818)\n",
      "16.0\n",
      "('Find answer for doc.', 819)\n",
      "4.0\n",
      "('Find answer for doc.', 820)\n",
      "200.5\n",
      "('Find answer for doc.', 821)\n",
      "140.5\n",
      "('Find answer for doc.', 822)\n",
      "197.5\n",
      "('Find answer for doc.', 823)\n",
      "160.0\n",
      "('Find answer for doc.', 824)\n",
      "205.0\n",
      "('Find answer for doc.', 825)\n",
      "218.5\n",
      "('Find answer for doc.', 826)\n",
      "3.0\n",
      "('Find answer for doc.', 827)\n",
      "199.0\n",
      "('Find answer for doc.', 828)\n",
      "200.0\n",
      "('Find answer for doc.', 829)\n",
      "254.5\n",
      "('Find answer for doc.', 830)\n",
      "5.0\n",
      "('Find answer for doc.', 831)\n",
      "109.0\n",
      "('Find answer for doc.', 832)\n",
      "110.0\n",
      "('Find answer for doc.', 833)\n",
      "18.5\n",
      "('Find answer for doc.', 834)\n",
      "7.0\n",
      "('Find answer for doc.', 835)\n",
      "36.5\n",
      "('Find answer for doc.', 836)\n",
      "109.0\n",
      "('Find answer for doc.', 837)\n",
      "192.0\n",
      "('Find answer for doc.', 838)\n",
      "15.5\n",
      "('Find answer for doc.', 839)\n",
      "34.0\n",
      "('Find answer for doc.', 840)\n",
      "79.0\n",
      "('Find answer for doc.', 841)\n",
      "8.5\n",
      "('Find answer for doc.', 842)\n",
      "96.0\n",
      "('Find answer for doc.', 843)\n",
      "18.5\n",
      "('Find answer for doc.', 844)\n",
      "8.0\n",
      "('Find answer for doc.', 845)\n",
      "9.5\n",
      "('Find answer for doc.', 846)\n",
      "16.0\n",
      "('Find answer for doc.', 847)\n",
      "116.5\n",
      "('Find answer for doc.', 848)\n",
      "10.5\n",
      "('Find answer for doc.', 849)\n",
      "35.0\n",
      "('Find answer for doc.', 850)\n",
      "20.5\n",
      "('Find answer for doc.', 851)\n",
      "34.0\n",
      "('Find answer for doc.', 852)\n",
      "108.0\n",
      "('Find answer for doc.', 853)\n",
      "10.0\n",
      "('Find answer for doc.', 854)\n",
      "7.0\n",
      "('Find answer for doc.', 855)\n",
      "68.0\n",
      "('Find answer for doc.', 856)\n",
      "33.5\n",
      "('Find answer for doc.', 857)\n",
      "22.0\n",
      "('Find answer for doc.', 858)\n",
      "10.5\n",
      "('Find answer for doc.', 859)\n",
      "37.0\n",
      "('Find answer for doc.', 860)\n",
      "18.5\n",
      "('Find answer for doc.', 861)\n",
      "22.0\n",
      "('Find answer for doc.', 862)\n",
      "24.0\n",
      "('Find answer for doc.', 863)\n",
      "156.0\n",
      "('Find answer for doc.', 864)\n",
      "2.0\n",
      "('Find answer for doc.', 865)\n",
      "66.0\n",
      "('Find answer for doc.', 866)\n",
      "21.0\n",
      "('Find answer for doc.', 867)\n",
      "9.0\n",
      "('Find answer for doc.', 868)\n",
      "7.0\n",
      "('Find answer for doc.', 869)\n",
      "48.5\n",
      "('Find answer for doc.', 870)\n",
      "3.0\n",
      "('Find answer for doc.', 871)\n",
      "3.0\n",
      "('Find answer for doc.', 872)\n",
      "58.0\n",
      "('Find answer for doc.', 873)\n",
      "43.0\n",
      "('Find answer for doc.', 874)\n",
      "25.0\n",
      "('Find answer for doc.', 875)\n",
      "10.0\n",
      "('Find answer for doc.', 876)\n",
      "33.5\n",
      "('Find answer for doc.', 877)\n",
      "52.0\n",
      "('Find answer for doc.', 878)\n",
      "61.0\n",
      "('Find answer for doc.', 879)\n",
      "26.0\n",
      "('Find answer for doc.', 880)\n",
      "4.0\n",
      "('Find answer for doc.', 881)\n",
      "81.0\n",
      "('Find answer for doc.', 882)\n",
      "41.5\n",
      "('Find answer for doc.', 883)\n",
      "9.0\n",
      "('Find answer for doc.', 884)\n",
      "119.0\n",
      "('Find answer for doc.', 885)\n",
      "16.0\n",
      "('Find answer for doc.', 886)\n",
      "6.0\n",
      "('Find answer for doc.', 887)\n",
      "121.5\n",
      "('Find answer for doc.', 888)\n",
      "1.0\n",
      "('Find answer for doc.', 889)\n",
      "2.0\n",
      "('Find answer for doc.', 890)\n",
      "71.5\n",
      "('Find answer for doc.', 891)\n",
      "19.5\n",
      "('Find answer for doc.', 892)\n",
      "13.0\n",
      "('Find answer for doc.', 893)\n",
      "12.0\n",
      "('Find answer for doc.', 894)\n",
      "2.0\n",
      "('Find answer for doc.', 895)\n",
      "27.0\n",
      "('Find answer for doc.', 896)\n",
      "21.0\n",
      "('Find answer for doc.', 897)\n",
      "21.5\n",
      "('Find answer for doc.', 898)\n",
      "20.5\n",
      "('Find answer for doc.', 899)\n",
      "9.0\n",
      "('Find answer for doc.', 900)\n",
      "3.5\n",
      "('Find answer for doc.', 901)\n",
      "51.5\n",
      "('Find answer for doc.', 902)\n",
      "1.0\n",
      "('Find answer for doc.', 903)\n",
      "31.5\n",
      "('Find answer for doc.', 904)\n",
      "13.0\n",
      "('Find answer for doc.', 905)\n",
      "43.0\n",
      "('Find answer for doc.', 906)\n",
      "5.0\n",
      "('Find answer for doc.', 907)\n",
      "23.5\n",
      "('Find answer for doc.', 908)\n",
      "29.0\n",
      "('Find answer for doc.', 909)\n",
      "22.5\n",
      "('Find answer for doc.', 910)\n",
      "7.0\n",
      "('Find answer for doc.', 911)\n",
      "50.0\n",
      "('Find answer for doc.', 912)\n",
      "38.5\n",
      "('Find answer for doc.', 913)\n",
      "41.0\n",
      "('Find answer for doc.', 914)\n",
      "2.0\n",
      "('Find answer for doc.', 915)\n",
      "3.0\n",
      "('Find answer for doc.', 916)\n",
      "30.0\n",
      "('Find answer for doc.', 917)\n",
      "2.0\n",
      "('Find answer for doc.', 918)\n",
      "4.5\n",
      "('Find answer for doc.', 919)\n",
      "8.5\n",
      "('Find answer for doc.', 920)\n",
      "199.5\n",
      "('Find answer for doc.', 921)\n",
      "157.0\n",
      "('Find answer for doc.', 922)\n",
      "53.5\n",
      "('Find answer for doc.', 923)\n",
      "115.5\n",
      "('Find answer for doc.', 924)\n",
      "11.0\n",
      "('Find answer for doc.', 925)\n",
      "9.5\n",
      "('Find answer for doc.', 926)\n",
      "6.0\n",
      "('Find answer for doc.', 927)\n",
      "2.0\n",
      "('Find answer for doc.', 928)\n",
      "293.0\n",
      "('Find answer for doc.', 929)\n",
      "2.0\n",
      "('Find answer for doc.', 930)\n",
      "12.0\n",
      "('Find answer for doc.', 931)\n",
      "51.5\n",
      "('Find answer for doc.', 932)\n",
      "11.5\n",
      "('Find answer for doc.', 933)\n",
      "12.0\n",
      "('Find answer for doc.', 934)\n",
      "25.0\n",
      "('Find answer for doc.', 935)\n",
      "10.5\n",
      "('Find answer for doc.', 936)\n",
      "19.0\n",
      "('Find answer for doc.', 937)\n",
      "80.0\n",
      "('Find answer for doc.', 938)\n",
      "22.0\n",
      "('Find answer for doc.', 939)\n",
      "31.0\n",
      "('Find answer for doc.', 940)\n",
      "63.0\n",
      "('Find answer for doc.', 941)\n",
      "134.5\n",
      "('Find answer for doc.', 942)\n",
      "24.0\n",
      "('Find answer for doc.', 943)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0\n",
      "('Find answer for doc.', 944)\n",
      "3.0\n",
      "('Find answer for doc.', 945)\n",
      "27.0\n",
      "('Find answer for doc.', 946)\n",
      "30.0\n",
      "('Find answer for doc.', 947)\n",
      "10.0\n",
      "('Find answer for doc.', 948)\n",
      "60.5\n",
      "('Find answer for doc.', 949)\n",
      "15.0\n",
      "('Find answer for doc.', 950)\n",
      "74.0\n",
      "('Find answer for doc.', 951)\n",
      "103.0\n",
      "('Find answer for doc.', 952)\n",
      "23.5\n",
      "('Find answer for doc.', 953)\n",
      "34.0\n",
      "('Find answer for doc.', 954)\n",
      "49.5\n",
      "('Find answer for doc.', 955)\n",
      "6.0\n",
      "('Find answer for doc.', 956)\n",
      "9.5\n",
      "('Find answer for doc.', 957)\n",
      "60.5\n",
      "('Find answer for doc.', 958)\n",
      "206.5\n",
      "('Find answer for doc.', 959)\n",
      "54.5\n",
      "('Find answer for doc.', 960)\n",
      "22.0\n",
      "('Find answer for doc.', 961)\n",
      "71.0\n",
      "('Find answer for doc.', 962)\n",
      "21.5\n",
      "('Find answer for doc.', 963)\n",
      "41.5\n",
      "('Find answer for doc.', 964)\n",
      "28.0\n",
      "('Find answer for doc.', 965)\n",
      "7.0\n",
      "('Find answer for doc.', 966)\n",
      "5.0\n",
      "('Find answer for doc.', 967)\n",
      "98.5\n",
      "('Find answer for doc.', 968)\n",
      "2.0\n",
      "('Find answer for doc.', 969)\n",
      "47.0\n",
      "('Find answer for doc.', 970)\n",
      "4.0\n",
      "('Find answer for doc.', 971)\n",
      "109.0\n",
      "('Find answer for doc.', 972)\n",
      "4.0\n",
      "('Find answer for doc.', 973)\n",
      "2.0\n",
      "('Find answer for doc.', 974)\n",
      "13.0\n",
      "('Find answer for doc.', 975)\n",
      "34.0\n",
      "('Find answer for doc.', 976)\n",
      "11.5\n",
      "('Find answer for doc.', 977)\n",
      "12.0\n",
      "('Find answer for doc.', 978)\n",
      "2.0\n",
      "('Find answer for doc.', 979)\n",
      "19.0\n",
      "('Find answer for doc.', 980)\n",
      "57.0\n",
      "('Find answer for doc.', 981)\n",
      "20.0\n",
      "('Find answer for doc.', 982)\n",
      "3.0\n",
      "('Find answer for doc.', 983)\n",
      "27.0\n",
      "('Find answer for doc.', 984)\n",
      "37.0\n",
      "('Find answer for doc.', 985)\n",
      "21.0\n",
      "('Find answer for doc.', 986)\n",
      "20.5\n",
      "('Find answer for doc.', 987)\n",
      "5.5\n",
      "('Find answer for doc.', 988)\n",
      "140.0\n",
      "('Find answer for doc.', 989)\n",
      "89.0\n",
      "('Find answer for doc.', 990)\n",
      "5.5\n",
      "('Find answer for doc.', 991)\n",
      "8.0\n",
      "('Find answer for doc.', 992)\n",
      "17.0\n",
      "('Find answer for doc.', 993)\n",
      "3.0\n",
      "('Find answer for doc.', 994)\n",
      "1.5\n",
      "('Find answer for doc.', 995)\n",
      "20.5\n",
      "('Find answer for doc.', 996)\n",
      "21.0\n",
      "('Find answer for doc.', 997)\n",
      "7.5\n",
      "('Find answer for doc.', 998)\n",
      "4.5\n",
      "('Find answer for doc.', 999)\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# 1、 考虑是不是过学习的问题\n",
    "# 2、 考虑在epoch的过程中自动生成文章表示的向量，这样是不是可以更快的计算\n",
    "# 3、 研究使用cosine similarity来计算最后的方程\n",
    "a = find_ranking(X1_test_1[:,:,:], X2_test_1, model_lstm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_results_test, rank_results_test = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1000.000000\n",
      "mean       49.668000\n",
      "std        70.423094\n",
      "min         1.000000\n",
      "25%         9.000000\n",
      "50%        23.000000\n",
      "75%        58.000000\n",
      "max       514.500000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    " print(pd.Series(rank_results_test).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4UAAAG5CAYAAAA595FfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJA2ZRKEmSJEkD9n/8WrW0hb9V0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b9de4ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "# matplotlib.rcParams['figure.figsize'] = (6.0, 2.0)\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 7)\n",
    "plt.plot(rank_results_test,'bo')\n",
    "plt.title('TOP Ranking for test documents (1-1000)')\n",
    "plt.xlabel('Document Number')\n",
    "plt.ylabel('The ranking of the real pair')\n",
    "plt.ylim([1000,0])\n",
    "plt.grid(True)\n",
    "plt.savefig('top-test.eps', format='eps', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n",
      "150\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print sum(np.array(rank_results_test) <= 10)\n",
    "print sum(np.array(rank_results_test) <= 5)\n",
    "print sum(np.array(rank_results_test) <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 目前的结果基本上到达了google翻译成通种语言以后的水平！非常精彩，在top1的范围还有一倍的差距，但是在top10的范围内已经非常接近真是水平了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   7. ,    1. ,    1. ,   58. ,   84.5,   13. ,  195. ,    6. ,\n",
       "          6. ,   34.5,    3. ,   37. ,   25. ,    1. ,   25.5,   53. ,\n",
       "         29.5,   73. ,   13. ,   15.5,   30. ,   19. ,   73. ,    1. ,\n",
       "         24. ,    8.5,   62. ,   35.5,    1. ,    5. ,    5. ,    6. ,\n",
       "         19. ,   82.5,    6. ,    7. ,    3.5,   62. ,   18. ,  110. ,\n",
       "         10. ,   18.5,   51. ,   14. ,   29. ,  123. ,    4. ,    9. ,\n",
       "         77. ,  199. ,    6. ,    8. ,   32. ,   76. ,   29.5,   28. ,\n",
       "         26. ,   18. ,   29. ,    7. ,   17. ,   16. ,   14. ,    2. ,\n",
       "         38. ,   20. ,   93. ,   16. ,   15. ,   21. ,   80. ,   58. ,\n",
       "          7.5,    2. ,    8. ,    7.5,   18. ,   24.5,  205. ,    1. ,\n",
       "         82.5,    2.5,    5.5,   65. ,   19. ,    2. ,   13.5,   41. ,\n",
       "         21.5,   34.5,    3. ,    1. ,    8. ,  117. ,    5. ,   26. ,\n",
       "         19. ,   79. ,   28. ,  119. ,    8.5,   30. ,   23. ,   30. ,\n",
       "          7.5,   37. ,    2.5,   22.5,   82. ,   15.5,    2. ,   88.5,\n",
       "         46. ,   16. ,   13. ,   82.5,   24. ,   11. ,   78. ,   32. ,\n",
       "         29.5,   15.5,   44. ,    2. ,   12. ,   98. ,   12. ,    7.5,\n",
       "          6.5,   13. ,    2. ,    3. ,   12. ,   18. ,   47. ,    4. ,\n",
       "         24. ,  347. ,   77. ,  115. ,  165. ,   21.5,    2. ,   14. ,\n",
       "        254. ,    8. ,  469. ,   46.5,   14. ,    9. ,  236.5,    4.5,\n",
       "         42. ,   91.5,    1.5,  104.5,   23. ,  283. ,    9.5,  246. ,\n",
       "         25.5,   25. ,    2. ,    6. ,    4. ,   13. ,  106. ,  273.5,\n",
       "         77.5,   14.5,   25. ,   32. ,   58.5,   10. ,   17. ,    3. ,\n",
       "         17. ,    7. ,   47.5,   20. ,    1.5,   25. ,    5. ,   33. ,\n",
       "        139. ,    3. ,   35. ,    2. ,   54. ,   67.5,   25.5,   17. ,\n",
       "         23. ,  317. ,  111. ,    3. ,   18.5,  251. ,   91.5,   12.5,\n",
       "        242. ,    6. ,   46. ,   14.5,   14. ,   16.5,    5. ,   47. ,\n",
       "         24. ,  123. ,  104.5,   59. ,  289. ,    4. ,   37. ,  146. ,\n",
       "        279. ,  301.5,   91.5,   22. ,    1. ,   54. ,  249. ,   29. ,\n",
       "          3. ,   91.5,    4. ,   39. ,   79. ,   23. ,    8. ,  134. ,\n",
       "         21. ,   17. ,  444. ,   20. ,  101.5,    7.5,    3. ,  214. ,\n",
       "         30. ,   36. ,   25. ,  108.5,    8. ,   14.5,  242. ,   10.5,\n",
       "          5.5,   49. ,   82. ,   14. ,   56. ,  108.5,   25. ,  172. ,\n",
       "         16. ,   85.5,    3. ,   15.5,    8. ,  213. ,   20. ,   22. ,\n",
       "         10.5,  242. ,  159. ,   49.5,   94. ,    5. ,   81. ,    9. ,\n",
       "        273.5,    2. ,   49.5,   89. ,   20.5,    2. ,   10.5,  165. ,\n",
       "         38. ,  111. ,   62.5,   14.5,   91.5,   46.5,    7.5,    3. ,\n",
       "        111. ,   12. ,    1. ,   25.5,    7. ,  397. ,   16. ,   14. ,\n",
       "          1. ,    4.5,    3. ,   28.5,   14. ,    7.5,   11. ,  137. ,\n",
       "         60. ,    5.5,   29. ,   20. ,   12. ,   23. ,   53. ,   23.5,\n",
       "         91.5,    9. ,   88. ,   25. ,   77. ,   25. ,    2. ,   51. ,\n",
       "         75. ,   40. ,   48. ,   23.5,   11. ,    5.5,   23. ,    9. ,\n",
       "          3.5,   91.5,    5. ,    5.5,   87. ,   10.5,   15. ,   20. ,\n",
       "         12.5,   39. ,   14. ,   22. ,    1. ,   50.5,   28.5,  301.5,\n",
       "         21.5,  105.5,   43. ,    7. ,  111. ,   17. ,   33. ,   41. ,\n",
       "         56.5,    7. ,   12. ,   92. ,    5. ,   39. ,   16. ,    1.5,\n",
       "         93. ,  342.5,    8.5,  156. ,   14. ,   21.5,   19. ,   70. ,\n",
       "         35.5,   55.5,   19. ,   12. ,   55. ,   37.5,  185. ,   20. ,\n",
       "         27. ,   31. ,   21.5,  231. ,    6. ,  118. ,    2. ,   28. ,\n",
       "          1. ,   21. ,  155.5,    7. ,   12. ,   44. ,    9. ,   35. ,\n",
       "          7. ,   23. ,   43.5,   24. ,  242.5,    2. ,   63. ,   12. ,\n",
       "          3. ,    7. ,   16. ,   37.5,    5.5,    4.5,   13. ,   10.5,\n",
       "         17.5,   70.5,   24. ,   20. ,   15.5,    2. ,   23. ,   21.5,\n",
       "          6. ,   45.5,   20. ,   45.5,   17.5,  105. ,    4. ,    8. ,\n",
       "        335.5,    5. ,   41. ,   40.5,   24.5,   35.5,   39.5,   11. ,\n",
       "          2. ,    4.5,   37. ,   12. ,    9. ,  104. ,   41.5,   13. ,\n",
       "         35. ,   55. ,   54.5,   19. ,   26. ,   19.5,    8.5,    5. ,\n",
       "         17. ,   10. ,   19. ,   67. ,  147. ,   72.5,    8. ,    2. ,\n",
       "         23. ,    1.5,   28. ,   17. ,    7. ,   46. ,   52. ,   24. ,\n",
       "          3. ,   19.5,   12. ,   32. ,  238.5,    8.5,   18. ,   32. ,\n",
       "         34. ,    2. ,   22. ,   55. ,    7. ,   12. ,   92. ,    1. ,\n",
       "         12. ,  104.5,   12. ,   18. ,    3. ,   23.5,   11. ,   46. ,\n",
       "          5.5,   32. ,    8. ,  156.5,   14. ,   70.5,   10.5,   37. ,\n",
       "          5.5,   25.5,    4. ,    7. ,   49.5,    8.5,   69. ,    1. ,\n",
       "         13. ,   26. ,    2. ,    1. ,    6.5,   13. ,   14. ,   30. ,\n",
       "         18. ,    5.5,    8. ,   17.5,   43.5,   60. ,  136. ,    2. ,\n",
       "         99. ,    2. ,   59.5,   32.5,  144. ,   25. ,   14. ,   16. ,\n",
       "         19. ,  150. ,   23.5,   52. ,    2. ,   21. ,    6. ,    7. ,\n",
       "         56.5,   35. ,   41.5,   31. ,   13. ,   69.5,  196.5,   81. ,\n",
       "         35. ,    5. ,   42. ,   21.5,   37.5,   36. ,   30. ,   18. ,\n",
       "         70. ,   31.5,    1.5,    1. ,    1.5,   15. ,  108. ,  196.5,\n",
       "         36. ,   10. ,    1.5,    9. ,   24.5,   83. ,   83. ,    9. ,\n",
       "         16. ,    8. ,   25.5,    9. ,    4. ,   58. ,   17.5,   59. ,\n",
       "         40.5,    9. ,   23. ,   34. ,    5. ,   19. ,   28. ,    2. ,\n",
       "         49. ,    1.5,   17. ,   32. ,  327. ,   17. ,    4. ,  514.5,\n",
       "         16. ,  502.5,   61.5,   85. ,    3. ,   28.5,    2. ,   23.5,\n",
       "         28.5,   50. ,    6. ,   19. ,   19. ,   75.5,   14. ,   37. ,\n",
       "         29. ,   37. ,   18. ,   57. ,   12. ,   28.5,   60.5,    3. ,\n",
       "         91. ,   27.5,   23. ,    2. ,    6. ,   55. ,   85. ,    4. ,\n",
       "         12. ,   70. ,    1.5,   13.5,    8.5,   27. ,  137. ,  148. ,\n",
       "         45.5,    5.5,   11. ,   47. ,  235. ,   30.5,    1. ,    2. ,\n",
       "          3. ,   32. ,    1. ,   84.5,   93. ,   39.5,   30. ,   21.5,\n",
       "         27. ,   29.5,   12. ,    5.5,   15. ,   85.5,   52. ,    9.5,\n",
       "         35. ,   14. ,    3. ,    7. ,  153. ,   22. ,   73. ,   77.5,\n",
       "         32. ,   88. ,  211.5,   50.5,  117. ,    1. ,   84. ,    4. ,\n",
       "          1. ,  197. ,    2. ,   14. ,   11. ,   69.5,   21.5,   44. ,\n",
       "         13.5,  106. ,    5. ,   31. ,   34. ,   41. ,   54.5,   36.5,\n",
       "         21.5,   46. ,   35. ,   11. ,    7. ,   10.5,  111.5,    9.5,\n",
       "          9. ,   72. ,   52.5,   20. ,  223.5,   15. ,   15. ,   83.5,\n",
       "         77.5,    6. ,   88. ,   27. ,   16.5,   37.5,   73. ,   11. ,\n",
       "          1.5,   39.5,   83.5,    8. ,   36. ,   37. ,    5. ,   76.5,\n",
       "         28.5,   17. ,   17. ,   11. ,   35. ,   85.5,   65.5,   59. ,\n",
       "         44. ,   47. ,    3. ,   30. ,   15.5,    6.5,    8. ,   32. ,\n",
       "         10. ,  103. ,    9. ,   12.5,    5. ,    8. ,  107.5,  143.5,\n",
       "         29.5,   92.5,    2. ,   11.5,   15.5,   67. ,  213.5,   19. ,\n",
       "          2. ,   28.5,   13.5,    4. ,   60.5,   51. ,   20. ,  140.5,\n",
       "         12.5,  133.5,   25. ,   23.5,    2. ,   54. ,    4. ,   21.5,\n",
       "         16. ,    9.5,    2. ,    1. ,    7. ,    8. ,   51. ,   11. ,\n",
       "        235. ,   85.5,    4. ,   13.5,    9.5,   73.5,   59. ,   19. ,\n",
       "        145. ,   19. ,   12. ,   92. ,  152.5,   33.5,   91. ,  156.5,\n",
       "         77.5,  123. ,   30. ,  379.5,  308.5,  171. ,  160. ,  216.5,\n",
       "         67.5,  248.5,  189.5,  377.5,  233.5,  219.5,  306.5,   13. ,\n",
       "        199. ,   67.5,  201.5,  377.5,  379.5,   27. ,   25. ,    4. ,\n",
       "        129.5,   34. ,   16. ,    4. ,  200.5,  140.5,  197.5,  160. ,\n",
       "        205. ,  218.5,    3. ,  199. ,  200. ,  254.5,    5. ,  109. ,\n",
       "        110. ,   18.5,    7. ,   36.5,  109. ,  192. ,   15.5,   34. ,\n",
       "         79. ,    8.5,   96. ,   18.5,    8. ,    9.5,   16. ,  116.5,\n",
       "         10.5,   35. ,   20.5,   34. ,  108. ,   10. ,    7. ,   68. ,\n",
       "         33.5,   22. ,   10.5,   37. ,   18.5,   22. ,   24. ,  156. ,\n",
       "          2. ,   66. ,   21. ,    9. ,    7. ,   48.5,    3. ,    3. ,\n",
       "         58. ,   43. ,   25. ,   10. ,   33.5,   52. ,   61. ,   26. ,\n",
       "          4. ,   81. ,   41.5,    9. ,  119. ,   16. ,    6. ,  121.5,\n",
       "          1. ,    2. ,   71.5,   19.5,   13. ,   12. ,    2. ,   27. ,\n",
       "         21. ,   21.5,   20.5,    9. ,    3.5,   51.5,    1. ,   31.5,\n",
       "         13. ,   43. ,    5. ,   23.5,   29. ,   22.5,    7. ,   50. ,\n",
       "         38.5,   41. ,    2. ,    3. ,   30. ,    2. ,    4.5,    8.5,\n",
       "        199.5,  157. ,   53.5,  115.5,   11. ,    9.5,    6. ,    2. ,\n",
       "        293. ,    2. ,   12. ,   51.5,   11.5,   12. ,   25. ,   10.5,\n",
       "         19. ,   80. ,   22. ,   31. ,   63. ,  134.5,   24. ,   24. ,\n",
       "          3. ,   27. ,   30. ,   10. ,   60.5,   15. ,   74. ,  103. ,\n",
       "         23.5,   34. ,   49.5,    6. ,    9.5,   60.5,  206.5,   54.5,\n",
       "         22. ,   71. ,   21.5,   41.5,   28. ,    7. ,    5. ,   98.5,\n",
       "          2. ,   47. ,    4. ,  109. ,    4. ,    2. ,   13. ,   34. ,\n",
       "         11.5,   12. ,    2. ,   19. ,   57. ,   20. ,    3. ,   27. ,\n",
       "         37. ,   21. ,   20.5,    5.5,  140. ,   89. ,    5.5,    8. ,\n",
       "         17. ,    3. ,    1.5,   20.5,   21. ,    7.5,    4.5,    4. ])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rank_results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Reading english Data:', 63386)\n",
      "('Reading english Data:', 63386)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    63340\n",
      "True         3\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main_keras.py:206: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_en'] = df_pairs_sample['en_article'].apply(doc2vec_en)\n",
      "main_keras.py:207: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_jp'] = df_pairs_sample['jp_article'].apply(doc2vec_jp)\n",
      "main_keras.py:211: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_en'] = df_pairs_sample['word2vec_en'].apply(padding)\n",
      "main_keras.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_jp'] = df_pairs_sample['word2vec_jp'].apply(padding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 1 position: [2580]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/home/liuenda/Workspace/cas-keras/main_keras.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# --- Generate balanced test data --- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX1_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_test_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1_test_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mX2_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2_test_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_test_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_test_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_test_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run main_keras.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tX1_test = np.concatenate((X1_test_1, X1_test_0), axis=0)\n",
    "\tX2_test = np.concatenate((X2_test_1, X2_test_0), axis=0)\n",
    "\ty_test = np.concatenate((np.ones(len(X1_test_1)), np.zeros(len(X1_test_0))), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.models.load_model(\"model_lstm2_b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_training = model1.predict([X1_train, X2_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.45      0.54      4000\n",
      "        1.0       0.59      0.80      0.68      4000\n",
      "\n",
      "avg / total       0.64      0.62      0.61      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_training>.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_training = model1.predict([X1_test, X2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.47      0.36      0.41      1000\n",
      "        1.0       0.48      0.59      0.53      1000\n",
      "\n",
      "avg / total       0.47      0.47      0.47      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_training>.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ma..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 259s - loss: 0.6565 - acc: 0.6345 - val_loss: 0.6320 - val_acc: 0.6430\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 302s - loss: 0.4402 - acc: 0.8023 - val_loss: 0.4839 - val_acc: 0.7650\n",
      "Epoch 3/10\n",
      "1280/8000 [===>..........................] - ETA: 150s - loss: 0.3563 - acc: 0.8492"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6ba6216544cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Fit the training model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m hist = model_lstm2.fit([X1_train, X2_train], [y_train],\n\u001b[0;32m---> 30\u001b[0;31m                        validation_data=([X1_test, X2_test], y_test), epochs=10, batch_size=256)\n\u001b[0m",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m/home/liuenda/miniconda3/envs/py2k/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\t# Input layer\n",
    "\tinput_1 = Input(shape=(maxlen,200), dtype='float32', name='main_input_1')\n",
    "\tinput_2 = Input(shape=(maxlen,200), dtype='float32', name='main_input_2')\n",
    "\n",
    "\t# LSTM layer\n",
    "\t# lstm_out_1 = LSTM(50)(input_1)\n",
    "\t# lstm_out_2 = LSTM(50)(input_2)\n",
    "\tlstm_out_1 = LSTM(50, go_backwards = True)(input_1)\n",
    "\tlstm_out_2 = LSTM(50, go_backwards = True)(input_2)\n",
    "\n",
    "\t# Merge layer\n",
    "\tmerged_vector = keras.layers.concatenate([lstm_out_1, lstm_out_2], axis=-1)\n",
    "\n",
    "\t# (Dense 1) * 3\n",
    "\tx1 = Dense(64, activation='relu')(merged_vector)\n",
    "\tx1 = Dense(64, activation='relu')(x1)\n",
    "\tx1 = Dense(64, activation='relu')(x1)\n",
    "\tmain_output = Dense(1, activation='sigmoid', name='main_output')(x1)\n",
    "\n",
    "\t# Model definition\n",
    "\tmodel_lstm2 = Model(input=[input_1, input_2], output=main_output)\n",
    "\n",
    "\t# Compile the model\n",
    "\tmodel_lstm2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\t# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\t# Fit the training model\n",
    "\thist = model_lstm2.fit([X1_train, X2_train], [y_train],\n",
    "\t                       validation_data=([X1_test, X2_test], y_test), epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "r = np.array([   7. ,    1. ,    1. ,   58. ,   84.5,   13. ,  195. ,    6. ,\n",
    "          6. ,   34.5,    3. ,   37. ,   25. ,    1. ,   25.5,   53. ,\n",
    "         29.5,   73. ,   13. ,   15.5,   30. ,   19. ,   73. ,    1. ,\n",
    "         24. ,    8.5,   62. ,   35.5,    1. ,    5. ,    5. ,    6. ,\n",
    "         19. ,   82.5,    6. ,    7. ,    3.5,   62. ,   18. ,  110. ,\n",
    "         10. ,   18.5,   51. ,   14. ,   29. ,  123. ,    4. ,    9. ,\n",
    "         77. ,  199. ,    6. ,    8. ,   32. ,   76. ,   29.5,   28. ,\n",
    "         26. ,   18. ,   29. ,    7. ,   17. ,   16. ,   14. ,    2. ,\n",
    "         38. ,   20. ,   93. ,   16. ,   15. ,   21. ,   80. ,   58. ,\n",
    "          7.5,    2. ,    8. ,    7.5,   18. ,   24.5,  205. ,    1. ,\n",
    "         82.5,    2.5,    5.5,   65. ,   19. ,    2. ,   13.5,   41. ,\n",
    "         21.5,   34.5,    3. ,    1. ,    8. ,  117. ,    5. ,   26. ,\n",
    "         19. ,   79. ,   28. ,  119. ,    8.5,   30. ,   23. ,   30. ,\n",
    "          7.5,   37. ,    2.5,   22.5,   82. ,   15.5,    2. ,   88.5,\n",
    "         46. ,   16. ,   13. ,   82.5,   24. ,   11. ,   78. ,   32. ,\n",
    "         29.5,   15.5,   44. ,    2. ,   12. ,   98. ,   12. ,    7.5,\n",
    "          6.5,   13. ,    2. ,    3. ,   12. ,   18. ,   47. ,    4. ,\n",
    "         24. ,  347. ,   77. ,  115. ,  165. ,   21.5,    2. ,   14. ,\n",
    "        254. ,    8. ,  469. ,   46.5,   14. ,    9. ,  236.5,    4.5,\n",
    "         42. ,   91.5,    1.5,  104.5,   23. ,  283. ,    9.5,  246. ,\n",
    "         25.5,   25. ,    2. ,    6. ,    4. ,   13. ,  106. ,  273.5,\n",
    "         77.5,   14.5,   25. ,   32. ,   58.5,   10. ,   17. ,    3. ,\n",
    "         17. ,    7. ,   47.5,   20. ,    1.5,   25. ,    5. ,   33. ,\n",
    "        139. ,    3. ,   35. ,    2. ,   54. ,   67.5,   25.5,   17. ,\n",
    "         23. ,  317. ,  111. ,    3. ,   18.5,  251. ,   91.5,   12.5,\n",
    "        242. ,    6. ,   46. ,   14.5,   14. ,   16.5,    5. ,   47. ,\n",
    "         24. ,  123. ,  104.5,   59. ,  289. ,    4. ,   37. ,  146. ,\n",
    "        279. ,  301.5,   91.5,   22. ,    1. ,   54. ,  249. ,   29. ,\n",
    "          3. ,   91.5,    4. ,   39. ,   79. ,   23. ,    8. ,  134. ,\n",
    "         21. ,   17. ,  444. ,   20. ,  101.5,    7.5,    3. ,  214. ,\n",
    "         30. ,   36. ,   25. ,  108.5,    8. ,   14.5,  242. ,   10.5,\n",
    "          5.5,   49. ,   82. ,   14. ,   56. ,  108.5,   25. ,  172. ,\n",
    "         16. ,   85.5,    3. ,   15.5,    8. ,  213. ,   20. ,   22. ,\n",
    "         10.5,  242. ,  159. ,   49.5,   94. ,    5. ,   81. ,    9. ,\n",
    "        273.5,    2. ,   49.5,   89. ,   20.5,    2. ,   10.5,  165. ,\n",
    "         38. ,  111. ,   62.5,   14.5,   91.5,   46.5,    7.5,    3. ,\n",
    "        111. ,   12. ,    1. ,   25.5,    7. ,  397. ,   16. ,   14. ,\n",
    "          1. ,    4.5,    3. ,   28.5,   14. ,    7.5,   11. ,  137. ,\n",
    "         60. ,    5.5,   29. ,   20. ,   12. ,   23. ,   53. ,   23.5,\n",
    "         91.5,    9. ,   88. ,   25. ,   77. ,   25. ,    2. ,   51. ,\n",
    "         75. ,   40. ,   48. ,   23.5,   11. ,    5.5,   23. ,    9. ,\n",
    "          3.5,   91.5,    5. ,    5.5,   87. ,   10.5,   15. ,   20. ,\n",
    "         12.5,   39. ,   14. ,   22. ,    1. ,   50.5,   28.5,  301.5,\n",
    "         21.5,  105.5,   43. ,    7. ,  111. ,   17. ,   33. ,   41. ,\n",
    "         56.5,    7. ,   12. ,   92. ,    5. ,   39. ,   16. ,    1.5,\n",
    "         93. ,  342.5,    8.5,  156. ,   14. ,   21.5,   19. ,   70. ,\n",
    "         35.5,   55.5,   19. ,   12. ,   55. ,   37.5,  185. ,   20. ,\n",
    "         27. ,   31. ,   21.5,  231. ,    6. ,  118. ,    2. ,   28. ,\n",
    "          1. ,   21. ,  155.5,    7. ,   12. ,   44. ,    9. ,   35. ,\n",
    "          7. ,   23. ,   43.5,   24. ,  242.5,    2. ,   63. ,   12. ,\n",
    "          3. ,    7. ,   16. ,   37.5,    5.5,    4.5,   13. ,   10.5,\n",
    "         17.5,   70.5,   24. ,   20. ,   15.5,    2. ,   23. ,   21.5,\n",
    "          6. ,   45.5,   20. ,   45.5,   17.5,  105. ,    4. ,    8. ,\n",
    "        335.5,    5. ,   41. ,   40.5,   24.5,   35.5,   39.5,   11. ,\n",
    "          2. ,    4.5,   37. ,   12. ,    9. ,  104. ,   41.5,   13. ,\n",
    "         35. ,   55. ,   54.5,   19. ,   26. ,   19.5,    8.5,    5. ,\n",
    "         17. ,   10. ,   19. ,   67. ,  147. ,   72.5,    8. ,    2. ,\n",
    "         23. ,    1.5,   28. ,   17. ,    7. ,   46. ,   52. ,   24. ,\n",
    "          3. ,   19.5,   12. ,   32. ,  238.5,    8.5,   18. ,   32. ,\n",
    "         34. ,    2. ,   22. ,   55. ,    7. ,   12. ,   92. ,    1. ,\n",
    "         12. ,  104.5,   12. ,   18. ,    3. ,   23.5,   11. ,   46. ,\n",
    "          5.5,   32. ,    8. ,  156.5,   14. ,   70.5,   10.5,   37. ,\n",
    "          5.5,   25.5,    4. ,    7. ,   49.5,    8.5,   69. ,    1. ,\n",
    "         13. ,   26. ,    2. ,    1. ,    6.5,   13. ,   14. ,   30. ,\n",
    "         18. ,    5.5,    8. ,   17.5,   43.5,   60. ,  136. ,    2. ,\n",
    "         99. ,    2. ,   59.5,   32.5,  144. ,   25. ,   14. ,   16. ,\n",
    "         19. ,  150. ,   23.5,   52. ,    2. ,   21. ,    6. ,    7. ,\n",
    "         56.5,   35. ,   41.5,   31. ,   13. ,   69.5,  196.5,   81. ,\n",
    "         35. ,    5. ,   42. ,   21.5,   37.5,   36. ,   30. ,   18. ,\n",
    "         70. ,   31.5,    1.5,    1. ,    1.5,   15. ,  108. ,  196.5,\n",
    "         36. ,   10. ,    1.5,    9. ,   24.5,   83. ,   83. ,    9. ,\n",
    "         16. ,    8. ,   25.5,    9. ,    4. ,   58. ,   17.5,   59. ,\n",
    "         40.5,    9. ,   23. ,   34. ,    5. ,   19. ,   28. ,    2. ,\n",
    "         49. ,    1.5,   17. ,   32. ,  327. ,   17. ,    4. ,  514.5,\n",
    "         16. ,  502.5,   61.5,   85. ,    3. ,   28.5,    2. ,   23.5,\n",
    "         28.5,   50. ,    6. ,   19. ,   19. ,   75.5,   14. ,   37. ,\n",
    "         29. ,   37. ,   18. ,   57. ,   12. ,   28.5,   60.5,    3. ,\n",
    "         91. ,   27.5,   23. ,    2. ,    6. ,   55. ,   85. ,    4. ,\n",
    "         12. ,   70. ,    1.5,   13.5,    8.5,   27. ,  137. ,  148. ,\n",
    "         45.5,    5.5,   11. ,   47. ,  235. ,   30.5,    1. ,    2. ,\n",
    "          3. ,   32. ,    1. ,   84.5,   93. ,   39.5,   30. ,   21.5,\n",
    "         27. ,   29.5,   12. ,    5.5,   15. ,   85.5,   52. ,    9.5,\n",
    "         35. ,   14. ,    3. ,    7. ,  153. ,   22. ,   73. ,   77.5,\n",
    "         32. ,   88. ,  211.5,   50.5,  117. ,    1. ,   84. ,    4. ,\n",
    "          1. ,  197. ,    2. ,   14. ,   11. ,   69.5,   21.5,   44. ,\n",
    "         13.5,  106. ,    5. ,   31. ,   34. ,   41. ,   54.5,   36.5,\n",
    "         21.5,   46. ,   35. ,   11. ,    7. ,   10.5,  111.5,    9.5,\n",
    "          9. ,   72. ,   52.5,   20. ,  223.5,   15. ,   15. ,   83.5,\n",
    "         77.5,    6. ,   88. ,   27. ,   16.5,   37.5,   73. ,   11. ,\n",
    "          1.5,   39.5,   83.5,    8. ,   36. ,   37. ,    5. ,   76.5,\n",
    "         28.5,   17. ,   17. ,   11. ,   35. ,   85.5,   65.5,   59. ,\n",
    "         44. ,   47. ,    3. ,   30. ,   15.5,    6.5,    8. ,   32. ,\n",
    "         10. ,  103. ,    9. ,   12.5,    5. ,    8. ,  107.5,  143.5,\n",
    "         29.5,   92.5,    2. ,   11.5,   15.5,   67. ,  213.5,   19. ,\n",
    "          2. ,   28.5,   13.5,    4. ,   60.5,   51. ,   20. ,  140.5,\n",
    "         12.5,  133.5,   25. ,   23.5,    2. ,   54. ,    4. ,   21.5,\n",
    "         16. ,    9.5,    2. ,    1. ,    7. ,    8. ,   51. ,   11. ,\n",
    "        235. ,   85.5,    4. ,   13.5,    9.5,   73.5,   59. ,   19. ,\n",
    "        145. ,   19. ,   12. ,   92. ,  152.5,   33.5,   91. ,  156.5,\n",
    "         77.5,  123. ,   30. ,  379.5,  308.5,  171. ,  160. ,  216.5,\n",
    "         67.5,  248.5,  189.5,  377.5,  233.5,  219.5,  306.5,   13. ,\n",
    "        199. ,   67.5,  201.5,  377.5,  379.5,   27. ,   25. ,    4. ,\n",
    "        129.5,   34. ,   16. ,    4. ,  200.5,  140.5,  197.5,  160. ,\n",
    "        205. ,  218.5,    3. ,  199. ,  200. ,  254.5,    5. ,  109. ,\n",
    "        110. ,   18.5,    7. ,   36.5,  109. ,  192. ,   15.5,   34. ,\n",
    "         79. ,    8.5,   96. ,   18.5,    8. ,    9.5,   16. ,  116.5,\n",
    "         10.5,   35. ,   20.5,   34. ,  108. ,   10. ,    7. ,   68. ,\n",
    "         33.5,   22. ,   10.5,   37. ,   18.5,   22. ,   24. ,  156. ,\n",
    "          2. ,   66. ,   21. ,    9. ,    7. ,   48.5,    3. ,    3. ,\n",
    "         58. ,   43. ,   25. ,   10. ,   33.5,   52. ,   61. ,   26. ,\n",
    "          4. ,   81. ,   41.5,    9. ,  119. ,   16. ,    6. ,  121.5,\n",
    "          1. ,    2. ,   71.5,   19.5,   13. ,   12. ,    2. ,   27. ,\n",
    "         21. ,   21.5,   20.5,    9. ,    3.5,   51.5,    1. ,   31.5,\n",
    "         13. ,   43. ,    5. ,   23.5,   29. ,   22.5,    7. ,   50. ,\n",
    "         38.5,   41. ,    2. ,    3. ,   30. ,    2. ,    4.5,    8.5,\n",
    "        199.5,  157. ,   53.5,  115.5,   11. ,    9.5,    6. ,    2. ,\n",
    "        293. ,    2. ,   12. ,   51.5,   11.5,   12. ,   25. ,   10.5,\n",
    "         19. ,   80. ,   22. ,   31. ,   63. ,  134.5,   24. ,   24. ,\n",
    "          3. ,   27. ,   30. ,   10. ,   60.5,   15. ,   74. ,  103. ,\n",
    "         23.5,   34. ,   49.5,    6. ,    9.5,   60.5,  206.5,   54.5,\n",
    "         22. ,   71. ,   21.5,   41.5,   28. ,    7. ,    5. ,   98.5,\n",
    "          2. ,   47. ,    4. ,  109. ,    4. ,    2. ,   13. ,   34. ,\n",
    "         11.5,   12. ,    2. ,   19. ,   57. ,   20. ,    3. ,   27. ,\n",
    "         37. ,   21. ,   20.5,    5.5,  140. ,   89. ,    5.5,    8. ,\n",
    "         17. ,    3. ,    1.5,   20.5,   21. ,    7.5,    4.5,    4. ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       49.668000\n",
       "std        70.423094\n",
       "min         1.000000\n",
       "25%         9.000000\n",
       "50%        23.000000\n",
       "75%        58.000000\n",
       "max       514.500000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(r).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
